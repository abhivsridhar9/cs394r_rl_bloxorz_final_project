{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6eOmmt_VC4M"
      },
      "source": [
        "## Configurations for Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "svqqkxUyVC4O",
        "outputId": "bf723d7b-40df-42f2-bb7d-5fa885b07db6"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    !apt install python-opengl\n",
        "    !apt install ffmpeg\n",
        "    !apt install xvfb\n",
        "    !pip install PyVirtualDisplay==3.0\n",
        "    !pip install gym\n",
        "    from pyvirtualdisplay import Display\n",
        "\n",
        "    # Start virtual display\n",
        "    dis = Display(visible=0, size=(400, 400))\n",
        "    dis.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuhgItfjVC4P"
      },
      "source": [
        "# 03. Prioritized Experience Replay (PER)\n",
        "\n",
        "[T. Schaul et al., \"Prioritized Experience Replay.\" arXiv preprint arXiv:1511.05952, 2015.](https://arxiv.org/pdf/1511.05952.pdf)\n",
        "\n",
        "Using a replay memory leads to design choices at two levels: which experiences to store, and which experiences to replay (and how to do so). This paper addresses only the latter: making the most effective use of the replay memory for learning, assuming that its contents are outside of our control.\n",
        "\n",
        "The central component of prioritized replay is the criterion by which the importance of each transition is measured. A reasonable approach is to use the magnitude of a transition’s TD error $\\delta$, which indicates how ‘surprising’\n",
        "or unexpected the transition is. This algorithm stores the last encountered TD error along with each transition in the replay memory. The transition with the largest absolute TD error is replayed from the memory. A Q-learning update\n",
        "is applied to this transition, which updates the weights in proportion to the TD error. One thing to note that new transitions arrive without a known TD-error, so it puts them at maximal priority in order to guarantee that all experience is seen at least once. (see *store* method)\n",
        "\n",
        "We might use 2 ideas to deal with TD-error: 1. greedy TD-error prioritization, 2. stochastic prioritization. However, greedy TD-error prioritization has a severe drawback. Greedy prioritization focuses on a small subset of the experience: errors shrink slowly, especially when using function approximation, meaning that the initially high error transitions get replayed frequently. This lack of diversity that makes the system prone to over-fitting. To overcome this issue, we will use a stochastic sampling method that interpolates between pure greedy prioritization and uniform random sampling.\n",
        "\n",
        "$$\n",
        "P(i) = \\frac{p_i^{\\alpha}}{\\sum_k p_k^{\\alpha}}\n",
        "$$\n",
        "\n",
        "where $p_i > 0$ is the priority of transition $i$. The exponent $\\alpha$ determines how much prioritization is used, with $\\alpha = 0$ corresponding to the uniform case. In practice, we use additional term $\\epsilon$ in order to guarantee all transactions can be possibly sampled: $p_i = |\\delta_i| + \\epsilon$, where $\\epsilon$ is a small positive constant.\n",
        "\n",
        "One more. Let's recall one of the main ideas of DQN. To remove correlation of observations, it uses uniformly random sampling from the replay buffer. Prioritized replay introduces bias because it doesn't sample experiences uniformly at random due to the sampling proportion correspoding to TD-error. We can correct this bias by using importance-sampling (IS) weights\n",
        "\n",
        "$$\n",
        "w_i = \\big( \\frac{1}{N} \\cdot \\frac{1}{P(i)} \\big)^\\beta\n",
        "$$\n",
        "\n",
        "that fully compensates for the non-uniform probabilities $P(i)$ if $\\beta = 1$. These weights can be folded into the Q-learning update by using $w_i\\delta_i$ instead of $\\delta_i$. In typical reinforcement learning scenarios, the unbiased nature of the updates is most important near convergence at the end of training, We therefore exploit the flexibility of annealing the amount of importance-sampling correction over time, by defining a schedule on the exponent $\\beta$ that reaches 1 only at the end of learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "puS8qt-fVC4P",
        "outputId": "b484d0ed-1a69-4d84-833c-b3d775626aa2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from IPython.display import clear_output\n",
        "\n",
        "if IN_COLAB and not os.path.exists(\"segment_tree.py\"):\n",
        "    # download segment tree module\n",
        "    !wget https://raw.githubusercontent.com/curt-park/rainbow-is-all-you-need/master/segment_tree.py\n",
        "\n",
        "from segment_tree import MinSegmentTree, SumSegmentTree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN_ITfpSVC4Q"
      },
      "source": [
        "## Replay buffer\n",
        "\n",
        "Please see *01.dqn.ipynb* for detailed description."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lAW_-jJnVC4Q",
        "outputId": "e89bce02-bd0a-471d-e0cb-678c795d9175"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer:\n",
        "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
        "\n",
        "    def __init__(self, obs_dim: int, size: int, batch_size: int = 32):\n",
        "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
        "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
        "        self.acts_buf = np.zeros([size], dtype=np.float32)\n",
        "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
        "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
        "        self.max_size, self.batch_size = size, batch_size\n",
        "        self.ptr, self.size, = 0, 0\n",
        "\n",
        "    def store(\n",
        "        self,\n",
        "        obs: np.ndarray,\n",
        "        act: np.ndarray,\n",
        "        rew: float,\n",
        "        next_obs: np.ndarray,\n",
        "        done: bool,\n",
        "    ):\n",
        "        self.obs_buf[self.ptr] = obs\n",
        "        self.next_obs_buf[self.ptr] = next_obs\n",
        "        self.acts_buf[self.ptr] = act\n",
        "        self.rews_buf[self.ptr] = rew\n",
        "        self.done_buf[self.ptr] = done\n",
        "        self.ptr = (self.ptr + 1) % self.max_size\n",
        "        self.size = min(self.size + 1, self.max_size)\n",
        "\n",
        "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
        "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
        "        return dict(obs=self.obs_buf[idxs],\n",
        "                    next_obs=self.next_obs_buf[idxs],\n",
        "                    acts=self.acts_buf[idxs],\n",
        "                    rews=self.rews_buf[idxs],\n",
        "                    done=self.done_buf[idxs])\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLGcEWI5VC4Q"
      },
      "source": [
        "## Prioritized replay Buffer\n",
        "\n",
        "The key concept of PER's implementation is *Segment Tree*. It efficiently stores and samples transitions while managing the priorities of them. We recommend you understand how it works before you move on. Here are references for you:\n",
        "\n",
        "- In Korean: https://mrsyee.github.io/rl/2019/01/25/PER-sumtree/\n",
        "- In English: https://www.geeksforgeeks.org/segment-tree-set-1-sum-of-given-range/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "K6gAr0g2VC4R"
      },
      "outputs": [],
      "source": [
        "class PrioritizedReplayBuffer(ReplayBuffer):\n",
        "    \"\"\"Prioritized Replay buffer.\n",
        "\n",
        "    Attributes:\n",
        "        max_priority (float): max priority\n",
        "        tree_ptr (int): next index of tree\n",
        "        alpha (float): alpha parameter for prioritized replay buffer\n",
        "        sum_tree (SumSegmentTree): sum tree for prior\n",
        "        min_tree (MinSegmentTree): min tree for min prior to get max weight\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        obs_dim: int,\n",
        "        size: int,\n",
        "        batch_size: int = 32,\n",
        "        alpha: float = 0.6\n",
        "    ):\n",
        "        \"\"\"Initialization.\"\"\"\n",
        "        assert alpha >= 0\n",
        "\n",
        "        super(PrioritizedReplayBuffer, self).__init__(obs_dim, size, batch_size)\n",
        "        self.max_priority, self.tree_ptr = 1.0, 0\n",
        "        self.alpha = alpha\n",
        "\n",
        "        # capacity must be positive and a power of 2.\n",
        "        tree_capacity = 1\n",
        "        while tree_capacity < self.max_size:\n",
        "            tree_capacity *= 2\n",
        "\n",
        "        self.sum_tree = SumSegmentTree(tree_capacity)\n",
        "        self.min_tree = MinSegmentTree(tree_capacity)\n",
        "\n",
        "    def store(\n",
        "        self,\n",
        "        obs: np.ndarray,\n",
        "        act: int,\n",
        "        rew: float,\n",
        "        next_obs: np.ndarray,\n",
        "        done: bool\n",
        "    ):\n",
        "        \"\"\"Store experience and priority.\"\"\"\n",
        "        super().store(obs, act, rew, next_obs, done)\n",
        "\n",
        "        self.sum_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
        "        self.min_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
        "        self.tree_ptr = (self.tree_ptr + 1) % self.max_size\n",
        "\n",
        "    def sample_batch(self, beta: float = 0.4) -> Dict[str, np.ndarray]:\n",
        "        \"\"\"Sample a batch of experiences.\"\"\"\n",
        "        assert len(self) >= self.batch_size\n",
        "        assert beta > 0\n",
        "\n",
        "        indices = self._sample_proportional()\n",
        "\n",
        "        obs = self.obs_buf[indices]\n",
        "        next_obs = self.next_obs_buf[indices]\n",
        "        acts = self.acts_buf[indices]\n",
        "        rews = self.rews_buf[indices]\n",
        "        done = self.done_buf[indices]\n",
        "        weights = np.array([self._calculate_weight(i, beta) for i in indices])\n",
        "\n",
        "        return dict(\n",
        "            obs=obs,\n",
        "            next_obs=next_obs,\n",
        "            acts=acts,\n",
        "            rews=rews,\n",
        "            done=done,\n",
        "            weights=weights,\n",
        "            indices=indices,\n",
        "        )\n",
        "\n",
        "    def update_priorities(self, indices: List[int], priorities: np.ndarray):\n",
        "        \"\"\"Update priorities of sampled transitions.\"\"\"\n",
        "        assert len(indices) == len(priorities)\n",
        "\n",
        "        for idx, priority in zip(indices, priorities):\n",
        "            assert priority > 0\n",
        "            assert 0 <= idx < len(self)\n",
        "\n",
        "            self.sum_tree[idx] = priority ** self.alpha\n",
        "            self.min_tree[idx] = priority ** self.alpha\n",
        "\n",
        "            self.max_priority = max(self.max_priority, priority)\n",
        "\n",
        "    def _sample_proportional(self) -> List[int]:\n",
        "        \"\"\"Sample indices based on proportions.\"\"\"\n",
        "        indices = []\n",
        "        p_total = self.sum_tree.sum(0, len(self) - 1)\n",
        "        segment = p_total / self.batch_size\n",
        "\n",
        "        for i in range(self.batch_size):\n",
        "            a = segment * i\n",
        "            b = segment * (i + 1)\n",
        "            upperbound = random.uniform(a, b)\n",
        "            idx = self.sum_tree.retrieve(upperbound)\n",
        "            indices.append(idx)\n",
        "\n",
        "        return indices\n",
        "\n",
        "    def _calculate_weight(self, idx: int, beta: float):\n",
        "        \"\"\"Calculate the weight of the experience at idx.\"\"\"\n",
        "        # get max weight\n",
        "        p_min = self.min_tree.min() / self.sum_tree.sum()\n",
        "        max_weight = (p_min * len(self)) ** (-beta)\n",
        "\n",
        "        # calculate weights\n",
        "        p_sample = self.sum_tree[idx] / self.sum_tree.sum()\n",
        "        weight = (p_sample * len(self)) ** (-beta)\n",
        "        weight = weight / max_weight\n",
        "\n",
        "        return weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6h4B-kuVC4R"
      },
      "source": [
        "## Network\n",
        "\n",
        "We are going to use a simple network architecture with three fully connected layers and two non-linearity functions (ReLU)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hW7LeRU5VC4R"
      },
      "outputs": [],
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self, in_dim: int, out_dim: int):\n",
        "        \"\"\"Initialization.\"\"\"\n",
        "        super(Network, self).__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(in_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, out_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward method implementation.\"\"\"\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPct4OusVC4R"
      },
      "source": [
        "## DQN + PER Agent\n",
        "\n",
        "Here is a summary of DQNAgent class.\n",
        "\n",
        "| Method           | Note                                                 |\n",
        "| ---              | ---                                                  |\n",
        "|select_action     | select an action from the input state.               |\n",
        "|step              | take an action and return the response of the env.   |\n",
        "|compute_dqn_loss  | return dqn loss.                                     |\n",
        "|update_model      | update the model by gradient descent.                |\n",
        "|target_hard_update| hard update from the local model to the target model.|\n",
        "|train             | train the agent during num_frames.                   |\n",
        "|test              | test the agent (1 episode).                          |\n",
        "|plot              | plot the training progresses.                        |\n",
        "\n",
        "\n",
        "All differences from pure DQN are noted with comments - PER.\n",
        "\n",
        "#### __init__\n",
        "\n",
        "Here, we use PrioritizedReplayBuffer, instead of ReplayBuffer, and use hold 2 more parameters beta and priority epsilon which are used to calculate weights and new priorities respectively.\n",
        "\n",
        "#### compute_dqn_loss & update_model\n",
        "\n",
        "It returns every loss per each sample for importance sampling before average. After updating the nework, it is necessary to update priorities of all sampled experiences.\n",
        "\n",
        "#### train\n",
        "\n",
        "beta linearly increases to 1 at every training step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-6CxsyU5VC4S"
      },
      "outputs": [],
      "source": [
        "class DQNAgent:\n",
        "    \"\"\"DQN Agent interacting with environment.\n",
        "\n",
        "    Attribute:\n",
        "        env (gym.Env): openAI Gym environment\n",
        "        memory (ReplayBuffer): replay memory to store transitions\n",
        "        batch_size (int): batch size for sampling\n",
        "        epsilon (float): parameter for epsilon greedy policy\n",
        "        epsilon_decay (float): step size to decrease epsilon\n",
        "        max_epsilon (float): max value of epsilon\n",
        "        min_epsilon (float): min value of epsilon\n",
        "        target_update (int): period for target model's hard update\n",
        "        gamma (float): discount factor\n",
        "        dqn (Network): model to train and select actions\n",
        "        dqn_target (Network): target model to update\n",
        "        optimizer (torch.optim): optimizer for training dqn\n",
        "        transition (list): transition information including\n",
        "                           state, action, reward, next_state, done\n",
        "        beta (float): determines how much importance sampling is used\n",
        "        prior_eps (float): guarantees every transition can be sampled\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        env: gym.Env,\n",
        "        memory_size: int,\n",
        "        batch_size: int,\n",
        "        target_update: int,\n",
        "        epsilon_decay: float,\n",
        "        seed: int,\n",
        "        max_epsilon: float = 1.0,\n",
        "        min_epsilon: float = 0.1,\n",
        "        gamma: float = 0.99,\n",
        "        # PER parameters\n",
        "        alpha: float = 0.2,\n",
        "        beta: float = 0.6,\n",
        "        prior_eps: float = 1e-6,\n",
        "    ):\n",
        "        \"\"\"Initialization.\n",
        "\n",
        "        Args:\n",
        "            env (gym.Env): openAI Gym environment\n",
        "            memory_size (int): length of memory\n",
        "            batch_size (int): batch size for sampling\n",
        "            target_update (int): period for target model's hard update\n",
        "            epsilon_decay (float): step size to decrease epsilon\n",
        "            lr (float): learning rate\n",
        "            max_epsilon (float): max value of epsilon\n",
        "            min_epsilon (float): min value of epsilon\n",
        "            gamma (float): discount factor\n",
        "            alpha (float): determines how much prioritization is used\n",
        "            beta (float): determines how much importance sampling is used\n",
        "            prior_eps (float): guarantees every transition can be sampled\n",
        "        \"\"\"\n",
        "        obs_dim = env.observation_space.shape[0]\n",
        "        action_dim = env.action_space.n\n",
        "\n",
        "        self.env = env\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.epsilon = max_epsilon\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.seed = seed\n",
        "        self.max_epsilon = max_epsilon\n",
        "        self.min_epsilon = min_epsilon\n",
        "        self.target_update = target_update\n",
        "        self.gamma = gamma\n",
        "\n",
        "        # device: cpu / gpu\n",
        "        self.device = torch.device(\n",
        "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        )\n",
        "        print(self.device)\n",
        "\n",
        "        # PER\n",
        "        # In DQN, We used \"ReplayBuffer(obs_dim, memory_size, batch_size)\"\n",
        "        self.beta = beta\n",
        "        self.prior_eps = prior_eps\n",
        "        self.memory = PrioritizedReplayBuffer(\n",
        "            obs_dim, memory_size, batch_size, alpha\n",
        "        )\n",
        "\n",
        "        # networks: dqn, dqn_target\n",
        "        self.dqn = Network(obs_dim, action_dim).to(self.device)\n",
        "        self.dqn_target = Network(obs_dim, action_dim).to(self.device)\n",
        "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
        "        self.dqn_target.eval()\n",
        "\n",
        "        # optimizer\n",
        "        self.optimizer = optim.Adam(self.dqn.parameters())\n",
        "\n",
        "        # transition to store in memory\n",
        "        self.transition = list()\n",
        "\n",
        "        # mode: train / test\n",
        "        self.is_test = False\n",
        "\n",
        "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Select an action from the input state.\"\"\"\n",
        "        # epsilon greedy policy\n",
        "        if self.epsilon > np.random.random():\n",
        "            selected_action = self.env.action_space.sample()\n",
        "        else:\n",
        "            selected_action = self.dqn(\n",
        "                torch.FloatTensor(state).to(self.device)\n",
        "            ).argmax()\n",
        "            selected_action = selected_action.detach().cpu().numpy()\n",
        "\n",
        "        if not self.is_test:\n",
        "            self.transition = [state, selected_action]\n",
        "\n",
        "        return selected_action\n",
        "\n",
        "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
        "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
        "        next_state, reward, done= self.env.step(action)\n",
        "\n",
        "        if not self.is_test:\n",
        "            self.transition += [reward, next_state, done]\n",
        "            self.memory.store(*self.transition)\n",
        "\n",
        "        return next_state, reward, done\n",
        "\n",
        "    def update_model(self) -> torch.Tensor:\n",
        "        \"\"\"Update the model by gradient descent.\"\"\"\n",
        "        # PER needs beta to calculate weights\n",
        "        samples = self.memory.sample_batch(self.beta)\n",
        "        weights = torch.FloatTensor(\n",
        "            samples[\"weights\"].reshape(-1, 1)\n",
        "        ).to(self.device)\n",
        "        indices = samples[\"indices\"]\n",
        "\n",
        "        # PER: importance sampling before average\n",
        "        elementwise_loss = self._compute_dqn_loss(samples)\n",
        "        loss = torch.mean(elementwise_loss * weights)\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        # PER: update priorities\n",
        "        loss_for_prior = elementwise_loss.detach().cpu().numpy()\n",
        "        new_priorities = loss_for_prior + self.prior_eps\n",
        "        self.memory.update_priorities(indices, new_priorities)\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "    def train(self, num_frames: int, plotting_interval: int = 200):\n",
        "        \"\"\"Train the agent.\"\"\"\n",
        "        self.is_test = False\n",
        "\n",
        "        state, _ = self.env.reset(seed=self.seed)\n",
        "        update_cnt = 0\n",
        "        epsilons = []\n",
        "        losses = []\n",
        "        scores = []\n",
        "        score = 0\n",
        "\n",
        "        for frame_idx in range(1, num_frames + 1):\n",
        "            action = self.select_action(state)\n",
        "            next_state, reward, done = self.step(action)\n",
        "\n",
        "            state = next_state\n",
        "            score += reward\n",
        "\n",
        "            # PER: increase beta\n",
        "            fraction = min(frame_idx / num_frames, 1.0)\n",
        "            self.beta = self.beta + fraction * (1.0 - self.beta)\n",
        "\n",
        "            # if episode ends\n",
        "            if done:\n",
        "                state, _ = self.env.reset(seed=self.seed)\n",
        "                scores.append(score)\n",
        "                score = 0\n",
        "\n",
        "            # if training is ready\n",
        "            if len(self.memory) >= self.batch_size:\n",
        "                loss = self.update_model()\n",
        "                losses.append(loss)\n",
        "                update_cnt += 1\n",
        "\n",
        "                # linearly decrease epsilon\n",
        "                self.epsilon = max(\n",
        "                    self.min_epsilon, self.epsilon - (\n",
        "                        self.max_epsilon - self.min_epsilon\n",
        "                    ) * self.epsilon_decay\n",
        "                )\n",
        "                epsilons.append(self.epsilon)\n",
        "\n",
        "                # if hard update is needed\n",
        "                if update_cnt % self.target_update == 0:\n",
        "                    self._target_hard_update()\n",
        "\n",
        "            # plotting\n",
        "            if frame_idx % plotting_interval == 0:\n",
        "                self._plot(frame_idx, scores, losses, epsilons)\n",
        "\n",
        "        self.env.close()\n",
        "\n",
        "    def test(self, video_folder: str) -> None:\n",
        "        \"\"\"Test the agent.\"\"\"\n",
        "        self.is_test = True\n",
        "\n",
        "        # for recording a video\n",
        "        naive_env = self.env\n",
        "        self.env = gym.wrappers.RecordVideo(self.env, video_folder=video_folder)\n",
        "\n",
        "        state, _ = self.env.reset(seed=self.seed)\n",
        "        done = False\n",
        "        score = 0\n",
        "\n",
        "        while not done:\n",
        "            action = self.select_action(state)\n",
        "            next_state, reward, done = self.step(action)\n",
        "\n",
        "            state = next_state\n",
        "            score += reward\n",
        "\n",
        "        print(\"score: \", score)\n",
        "        self.env.close()\n",
        "\n",
        "        # reset\n",
        "        self.env = naive_env\n",
        "\n",
        "    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray]) -> torch.Tensor:\n",
        "        \"\"\"Return dqn loss.\"\"\"\n",
        "        device = self.device  # for shortening the following lines\n",
        "        state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
        "        next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
        "        action = torch.LongTensor(samples[\"acts\"].reshape(-1, 1)).to(device)\n",
        "        reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
        "        done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
        "\n",
        "        # G_t   = r + gamma * v(s_{t+1})  if state != Terminal\n",
        "        #       = r                       otherwise\n",
        "        curr_q_value = self.dqn(state).gather(1, action)\n",
        "        next_q_value = self.dqn_target(\n",
        "            next_state\n",
        "        ).max(dim=1, keepdim=True)[0].detach()\n",
        "        mask = 1 - done\n",
        "        target = (reward + self.gamma * next_q_value * mask).to(self.device)\n",
        "\n",
        "        # calculate element-wise dqn loss\n",
        "        elementwise_loss = F.smooth_l1_loss(curr_q_value, target, reduction=\"none\")\n",
        "\n",
        "        return elementwise_loss\n",
        "\n",
        "    def _target_hard_update(self):\n",
        "        \"\"\"Hard update: target <- local.\"\"\"\n",
        "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
        "\n",
        "    def _plot(\n",
        "        self,\n",
        "        frame_idx: int,\n",
        "        scores: List[float],\n",
        "        losses: List[float],\n",
        "        epsilons: List[float],\n",
        "    ):\n",
        "        \"\"\"Plot the training progresses.\"\"\"\n",
        "        clear_output(True)\n",
        "        plt.figure(figsize=(20, 5))\n",
        "        plt.subplot(131)\n",
        "        plt.title('frame %s. score: %s' % (frame_idx, np.mean(scores[-10:])))\n",
        "        plt.plot(scores)\n",
        "        plt.subplot(132)\n",
        "        plt.title('loss')\n",
        "        plt.plot(losses)\n",
        "        plt.subplot(133)\n",
        "        plt.title('epsilons')\n",
        "        plt.plot(epsilons)\n",
        "        plt.grid()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBl6CMcHVC4S"
      },
      "source": [
        "## Environment\n",
        "\n",
        "You can see the [code](https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/envs/classic_control/cartpole.py) and [configurations](https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/envs/classic_control/cartpole.py#L91) of CartPole-v1 from Farama Gymnasium's repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bh8c7WDWVC4S"
      },
      "outputs": [],
      "source": [
        "# 0: normal tile\n",
        "# 1: orange tile\n",
        "# 2: soft switch\n",
        "# 3: hard switch\n",
        "# 4: goal\n",
        "# 5: transport switch\n",
        "# 8: block\n",
        "# 9: none\n",
        "\n",
        "# Level 1:\n",
        "level_one_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 4, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Level 2:\n",
        "level_two_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 3, 0, 9, 9, 0, 4, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 2, 0, 9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "level_two_soft_switches = np.array(\n",
        "    [{\"switch_location\": (4, 4), \"toggle_tiles\": [(6, 6), (6, 7)], \"mode\": \"toggle\"}]\n",
        ")\n",
        "\n",
        "\n",
        "level_two_hard_switches = np.array(\n",
        "    [{\"switch_location\": (3, 10), \"toggle_tiles\": [(6, 12), (6, 13)]}]\n",
        ")\n",
        "\n",
        "# Level 3:\n",
        "level_three_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 9, 9, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 4, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Level 4:\n",
        "level_four_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 1, 1, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 1, 1, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 0, 0, 0, 0, 1, 1, 1, 1, 1, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 0, 0, 0, 0, 1, 1, 1, 1, 1, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 4, 0, 9, 9, 1, 1, 0, 1, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 1, 1, 1, 1, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Level 5:\n",
        "level_five_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 2, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 2, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "level_five_soft_switches = np.array(\n",
        "    [\n",
        "        {\n",
        "            \"switch_location\": (2, 10),\n",
        "            \"toggle_tiles\": [(2, 7), (2, 8)],\n",
        "            \"mode\": \"toggle\",\n",
        "        },\n",
        "        {\n",
        "            \"switch_location\": (7, 16),\n",
        "            \"toggle_tiles\": [(9, 7), (9, 8)],\n",
        "            \"mode\": \"toggle\",\n",
        "        },\n",
        "        {\"switch_location\": (6, 8), \"toggle_tiles\": [(9, 7), (9, 8)], \"mode\": \"off\"},\n",
        "        {\"switch_location\": (4, 5), \"toggle_tiles\": [(9, 7), (9, 8)], \"mode\": \"on\"},\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Level 6:\n",
        "level_six_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 0, 0, 0, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 0, 0, 4, 0, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Level 7:\n",
        "level_seven_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 0, 9, 9, 0, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 0, 4, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 0, 0, 3, 9, 9, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 0, 0, 0, 9, 9, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "level_seven_hard_switches = np.array(\n",
        "    [{\"switch_location\": (5, 12), \"toggle_tiles\": [(7, 6)]}]\n",
        ")\n",
        "\n",
        "\n",
        "# Level 8:\n",
        "level_eight_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 5, 0, 9, 9, 9, 0, 0, 0, 0, 4, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "level_eight_teleport_switches = np.array(\n",
        "    [{\"switch_location\": (6, 7), \"split_positions\": [(3, 13), (9, 13)]}]\n",
        ")\n",
        "\n",
        "\n",
        "# Level 9:\n",
        "level_nine_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 0, 9, 9, 9, 0, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 0, 9, 9, 9, 0, 0, 5, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 4, 0, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "level_nine_teleport_switches = np.array(\n",
        "    [{\"switch_location\": (4, 16), \"split_positions\": [(4, 15), (4, 5)]}]\n",
        ")\n",
        "\n",
        "\n",
        "# Level 10:\n",
        "level_ten_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 4, 0, 9, 9, 0, 9, 9, 0, 0, 0, 0, 5, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 9, 9, 0, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 0, 2, 9, 9, 0, 0, 0, 3, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "level_ten_teleport_switches = np.array(\n",
        "    [{\"switch_location\": (2, 15), \"split_positions\": [(2, 15), (2, 12)]}]\n",
        ")\n",
        "\n",
        "level_ten_hard_switches = np.array(\n",
        "    [{\"switch_location\": (10, 14), \"toggle_tiles\": [(2, 9), (2, 10),(3, 15), (4, 15)]}]\n",
        ")\n",
        "\n",
        "level_ten_soft_switches = np.array(\n",
        "    [{\"switch_location\": (10, 8), \"toggle_tiles\": [(2, 6), (2, 7)], \"mode\":\"toggle\"}]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6TuNlvRRVdpY"
      },
      "outputs": [],
      "source": [
        "class Block:\n",
        "\n",
        "    def __init__(self, r1, c1, r2, c2):\n",
        "        self._r1 = r1\n",
        "        self._r2 = r2\n",
        "        self._c1 = c1\n",
        "        self._c2 = c2\n",
        "\n",
        "        self._focus_block = 0\n",
        "\n",
        "    def set_coords(self, r1, c1, r2, c2):\n",
        "        self._r1 = r1\n",
        "        self._r2 = r2\n",
        "        self._c1 = c1\n",
        "        self._c2 = c2\n",
        "\n",
        "    def get_coords(self):\n",
        "        return self._r1, self._c1, self._r2, self._c2\n",
        "\n",
        "    def is_upright(self):\n",
        "        return self._r1 == self._r2 and self._c1 == self._c2\n",
        "\n",
        "    def is_wide(self):\n",
        "        return self._r1 == self._r2 and self._c1 != self._c2\n",
        "\n",
        "    def move_up(self):\n",
        "        match self._focus_block:\n",
        "            case 0:\n",
        "                # vertical\n",
        "                if self.is_upright():\n",
        "                    self._r1 -= 1\n",
        "                    self._r2 -= 2\n",
        "\n",
        "                # flat and wide\n",
        "                elif self.is_wide():\n",
        "                    self._r1 -= 1\n",
        "                    self._r2 -= 1\n",
        "\n",
        "                # flat and long\n",
        "                else:\n",
        "                    min_r = min(self._r1, self._r2)\n",
        "                    self._r1 = min_r - 1\n",
        "                    self._r2 = min_r - 1\n",
        "\n",
        "            case 1:\n",
        "                self._r1 -= 1\n",
        "\n",
        "            case 2:\n",
        "                self._r2 -= 1\n",
        "\n",
        "    def move_down(self):\n",
        "        match self._focus_block:\n",
        "            case 0:\n",
        "                # vertical\n",
        "                if self.is_upright():\n",
        "                    self._r1 += 1\n",
        "                    self._r2 += 2\n",
        "\n",
        "                # flat and wide\n",
        "                elif self.is_wide():\n",
        "                    self._r1 += 1\n",
        "                    self._r2 += 1\n",
        "\n",
        "                # flat and long\n",
        "                else:\n",
        "                    max_r = max(self._r1, self._r2)\n",
        "                    self._r1 = max_r + 1\n",
        "                    self._r2 = max_r + 1\n",
        "\n",
        "            case 1:\n",
        "                self._r1 += 1\n",
        "            case 2:\n",
        "                self._r2 += 1\n",
        "\n",
        "    # edited\n",
        "    def move_right(self):\n",
        "        match self._focus_block:\n",
        "            case 0:\n",
        "                # vertical\n",
        "                if self.is_upright():\n",
        "                    self._c1 += 1\n",
        "                    self._c2 += 2\n",
        "\n",
        "                # flat and wide\n",
        "                elif self.is_wide():\n",
        "                    max_c = max(self._c1, self._c2)\n",
        "                    self._c1 = max_c + 1\n",
        "                    self._c2 = max_c + 1\n",
        "\n",
        "                # flat and long\n",
        "                else:\n",
        "                    self._c1 += 1\n",
        "                    self._c2 += 1\n",
        "\n",
        "            case 1:\n",
        "                self._c1 += 1\n",
        "            case 2:\n",
        "                self._c2 += 1\n",
        "\n",
        "    # edited\n",
        "    def move_left(self):\n",
        "        match self._focus_block:\n",
        "            case 0:\n",
        "                # vertical\n",
        "                if self.is_upright():\n",
        "                    self._c1 -= 1\n",
        "                    self._c2 -= 2\n",
        "\n",
        "                # flat and wide\n",
        "                elif self.is_wide():\n",
        "                    min_c = min(self._c1, self._c2)\n",
        "                    self._c1 = min_c - 1\n",
        "                    self._c2 = min_c - 1\n",
        "\n",
        "                # flat and long\n",
        "                else:\n",
        "                    self._c1 -= 1\n",
        "                    self._c2 -= 1\n",
        "            case 1:\n",
        "                self._c1 -= 1\n",
        "            case 2:\n",
        "                self._c2 -= 1\n",
        "\n",
        "    def toggle_focus(self):\n",
        "        if self._focus_block == 0:\n",
        "            self._focus_block = 0\n",
        "        elif self._focus_block == 1:\n",
        "            self._focus_block = 2\n",
        "        else:\n",
        "            self._focus_block = 1\n",
        "\n",
        "    def set_focus(self, focus):\n",
        "        self._focus_block = focus\n",
        "\n",
        "    def get_focus(self):\n",
        "        return self._focus_block\n",
        "\n",
        "    def join_single_blocks(self):\n",
        "        if self._focus_block == 1 or self._focus_block == 2:\n",
        "            if abs(self._r1 - self._r2) == 1 and (self._c1 == self._c2):\n",
        "                self.set_focus(0)\n",
        "            elif abs(self._c1 - self._c2) == 1 and (self._r1 == self._r2):\n",
        "                self.set_focus(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "w4krS0-4VfU2"
      },
      "outputs": [],
      "source": [
        "class Level(gym.Env):\n",
        "    metadata = {\"render_modes\": [], \"render_fps\": 0}\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        start_pos: tuple,\n",
        "        base_env: np.array([]),\n",
        "        soft_switches=np.array([]),\n",
        "        hard_switches=np.array([]),\n",
        "        teleport_switches=np.array([]),\n",
        "        render_mode=None,\n",
        "    ):\n",
        "        self._r_start = start_pos[0]\n",
        "        self._c_start = start_pos[1]\n",
        "\n",
        "        self._block = Block(self._r_start, self._c_start, self._r_start, self._c_start)\n",
        "\n",
        "        self._base_env = base_env\n",
        "\n",
        "        self._soft_switches = soft_switches\n",
        "        self._hard_switches = hard_switches\n",
        "        self._teleport_switches = teleport_switches\n",
        "\n",
        "        self._actions = {\n",
        "            0: self._block.move_right,\n",
        "            1: self._block.move_up,\n",
        "            2: self._block.move_left,\n",
        "            3: self._block.move_down,\n",
        "            4: self._block.toggle_focus,\n",
        "        }\n",
        "\n",
        "        self.observation_space = np.append(base_env.ravel(), 0)\n",
        "        self.action_space = gym.spaces.Discrete(5)\n",
        "\n",
        "    def step(self, action):\n",
        "        # if the block is split, check if single blocks are adjacent, and join together\n",
        "        self._block.join_single_blocks()\n",
        "\n",
        "        # update the agent's coords by passing it the action\n",
        "        self._perform_action(action)\n",
        "\n",
        "        # check if the agent is out of bounds -> reset to the start\n",
        "        r1, c1, r2, c2 = self._block.get_coords()\n",
        "\n",
        "        reward, done = self._is_done(r1, c1, r2, c2)\n",
        "\n",
        "        # only check for environment changes if the action is not \"Switch Focus\"\n",
        "        if action != 4:\n",
        "            self._move_to_start(r1, c1, r2, c2)\n",
        "            self._activate_teleport_switch(r1, c1, r2, c2)\n",
        "            self._toggle_soft_switches(r1, c1, r2, c2)\n",
        "            self._toggle_hard_switches(r1, c1, r2, c2)\n",
        "\n",
        "\n",
        "\n",
        "        state = self._format_environment()\n",
        "\n",
        "        return state, reward, done\n",
        "\n",
        "    def reset(self, seed):\n",
        "        # set both of the agent's coords to (self._r_start,self._c_start) and (self._r_start,self._c_start)\n",
        "        self._block.set_coords(\n",
        "            self._r_start, self._c_start, self._r_start, self._c_start\n",
        "        )\n",
        "        self._block.set_focus(0)\n",
        "\n",
        "        # reset the environment (important to undo any obstacle interactions)\n",
        "        self._current_env = np.copy(self._base_env)\n",
        "\n",
        "        # place the agent in the environment using its position\n",
        "        state = np.copy(self._current_env)\n",
        "        state[self._r_start, self._c_start] = 8\n",
        "        state = state.ravel()\n",
        "        state = np.append(state, self._block.get_focus())\n",
        "        # state = np.array2string(state, separator=\"\") + str(self._block.get_focus())\n",
        "\n",
        "        return state, False\n",
        "\n",
        "    def _move_to_start(self, r1, c1, r2, c2):\n",
        "        if self._current_env[r1, c1] == 9 or self._current_env[r2, c2] == 9:\n",
        "            self.reset(42)\n",
        "\n",
        "    def _is_done(self, r1, c1, r2, c2):\n",
        "        # check if the agent is on the goal -> set done to True and reward to 0\n",
        "\n",
        "        # reward is -1 and done is False unless the agent hit the goal\n",
        "        reward = -1\n",
        "        done = False\n",
        "\n",
        "        if self._current_env[r1, c1] == 4 and self._current_env[r2, c2] == 4:\n",
        "            reward = 0\n",
        "            done = True\n",
        "        # elif self._current_env[r1, c1] == 9 or self._current_env[r2, c2] == 9:\n",
        "        #   reward = -1000\n",
        "        #   done = True\n",
        "\n",
        "        return reward, done\n",
        "\n",
        "    def _format_environment(self):\n",
        "        # place the agent in the environment using its position\n",
        "        r1, c1, r2, c2 = self._block.get_coords()\n",
        "        state = np.copy(self._current_env)\n",
        "        state[r1, c1] = 8\n",
        "        state[r2, c2] = 8\n",
        "\n",
        "        state = state.ravel()\n",
        "        state = np.append(state, self._block.get_focus())\n",
        "        # state = np.array2string(state, separator=\"\") + str(self._block.get_focus())\n",
        "\n",
        "        return state\n",
        "\n",
        "    def _toggle_soft_switches(self, r1, c1, r2, c2):\n",
        "        # check if the agent is on a circle switch -> activate bridge\n",
        "        for c in self._soft_switches:\n",
        "            switch_location = c[\"switch_location\"]\n",
        "            toggle_tiles = c[\"toggle_tiles\"]\n",
        "            mode = c[\"mode\"]\n",
        "\n",
        "            if (r1 == switch_location[0] and c1 == switch_location[1]) or (\n",
        "                r2 == switch_location[0] and c2 == switch_location[1]\n",
        "            ):\n",
        "                if mode == \"toggle\":\n",
        "                    if self._current_env[toggle_tiles[0][0], toggle_tiles[0][1]] == 0:\n",
        "                        for t in toggle_tiles:\n",
        "                            self._current_env[t[0], t[1]] = 9\n",
        "                            self._current_env[t[0], t[1]] = 9\n",
        "\n",
        "                    else:\n",
        "                        for t in toggle_tiles:\n",
        "                            self._current_env[t[0], t[1]] = 0\n",
        "                            self._current_env[t[0], t[1]] = 0\n",
        "                elif mode == \"on\":\n",
        "                    for t in toggle_tiles:\n",
        "                        self._current_env[t[0], t[1]] = 0\n",
        "                        self._current_env[t[0], t[1]] = 0\n",
        "                elif mode == \"off\":\n",
        "                    for t in toggle_tiles:\n",
        "                        self._current_env[t[0], t[1]] = 9\n",
        "                        self._current_env[t[0], t[1]] = 9\n",
        "\n",
        "    def _toggle_hard_switches(self, r1, c1, r2, c2):\n",
        "        # check if the agent is on an x switch -> activate bridge\n",
        "        for c in self._hard_switches:\n",
        "            switch_location = c[\"switch_location\"]\n",
        "            toggle_tiles = c[\"toggle_tiles\"]\n",
        "\n",
        "            if (r1 == switch_location[0] and c1 == switch_location[1]) and (\n",
        "                r2 == switch_location[0] and c2 == switch_location[1]\n",
        "            ):\n",
        "                if self._current_env[toggle_tiles[0][0], toggle_tiles[0][1]] == 0:\n",
        "                    for t in toggle_tiles:\n",
        "                        self._current_env[t[0], t[1]] = 9\n",
        "                        self._current_env[t[0], t[1]] = 9\n",
        "\n",
        "                else:\n",
        "                    for t in toggle_tiles:\n",
        "                        self._current_env[t[0], t[1]] = 0\n",
        "                        self._current_env[t[0], t[1]] = 0\n",
        "\n",
        "    def _activate_teleport_switch(self, r1, c1, r2, c2):\n",
        "        # check if block is on teleport switch -> split block into two single blocks\n",
        "        for t in self._teleport_switches:\n",
        "            switch_location = t[\"switch_location\"]\n",
        "            split_positions = t[\"split_positions\"]\n",
        "\n",
        "\n",
        "            if (r1 == switch_location[0] and c1 == switch_location[1]) and (\n",
        "                r2 == switch_location[0] and c2 == switch_location[1]\n",
        "            ):\n",
        "\n",
        "                single_block_one = split_positions[0]\n",
        "                single_block_two = split_positions[1]\n",
        "\n",
        "                r1 = single_block_one[0]\n",
        "                c1 = single_block_one[1]\n",
        "\n",
        "                r2 = single_block_two[0]\n",
        "                c2 = single_block_two[1]\n",
        "\n",
        "                self._block.set_focus(1)\n",
        "                self._block.set_coords(r1, c1, r2, c2)\n",
        "\n",
        "    def _handle_orange_tile(self, r1, c1, r2, c2):\n",
        "        # check if block is vertical\n",
        "        if (r1, c1) == (r2, c2):\n",
        "            # check if tile is orange tile\n",
        "            if self._current_env[r1, c1] == 1:\n",
        "                # tile disappears/block falls through grid\n",
        "\n",
        "                self._block.set_coords(\n",
        "                    self._r_start, self._c_start, self._r_start, self._c_start\n",
        "                )\n",
        "\n",
        "        # nothing happens if block is not vertical on an orange tile\n",
        "\n",
        "    def _perform_action(self, action):\n",
        "        # Get the corresponding method from 'actions' and call it\n",
        "        action_method = self._actions.get(int(action))\n",
        "        if action_method:\n",
        "            action_method()\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid action\")\n",
        "\n",
        "    def get_state(self):\n",
        "        r1, c1, r2, c2 = self._block.get_coords()\n",
        "        print(r1, c1, r2, c2)\n",
        "        state = np.copy(self._current_env)\n",
        "        state[r1, c1] = 8\n",
        "        state[r2, c2] = 8\n",
        "\n",
        "        return state\n",
        "\n",
        "    def get_block(self):\n",
        "        return self._block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mID_Wvk_Vgw3"
      },
      "outputs": [],
      "source": [
        "level = 1\n",
        "\n",
        "if level == 1:\n",
        "        env = Level(start_pos=(3, 6), base_env=level_one_env)\n",
        "\n",
        "elif level == 2:\n",
        "    env = Level(\n",
        "        start_pos=(6, 3),\n",
        "        base_env=level_two_env,\n",
        "        soft_switches=level_two_soft_switches,\n",
        "        hard_switches=level_two_hard_switches,\n",
        "    )\n",
        "\n",
        "elif level == 3:\n",
        "    env = Level(start_pos=(4, 3), base_env=level_three_env)\n",
        "\n",
        "elif level == 4:\n",
        "    env = Level(start_pos=(6, 4), base_env=level_four_env)\n",
        "\n",
        "elif level == 5:\n",
        "    env = Level(\n",
        "        start_pos=(2, 15),\n",
        "        base_env=level_five_env,\n",
        "        soft_switches=level_five_soft_switches,\n",
        "    )\n",
        "elif level == 6:\n",
        "    env = Level(\n",
        "        start_pos=(4, 3),\n",
        "        base_env=level_six_env,\n",
        "    )\n",
        "\n",
        "elif level == 7:\n",
        "    env = Level(\n",
        "        start_pos=(4, 4),\n",
        "        base_env=level_seven_env,\n",
        "        hard_switches=level_seven_hard_switches,\n",
        "    )\n",
        "\n",
        "elif level == 8:\n",
        "    env = Level(\n",
        "        start_pos=(6, 4),\n",
        "        base_env=level_eight_env,\n",
        "        teleport_switches=level_eight_teleport_switches,\n",
        "    )\n",
        "elif level == 9:\n",
        "    env = Level(\n",
        "        start_pos=(4, 4),\n",
        "        base_env=level_nine_env,\n",
        "        teleport_switches=level_nine_teleport_switches\n",
        "    )\n",
        "\n",
        "elif level == 10:\n",
        "    env = Level(\n",
        "        start_pos=(2, 12),\n",
        "        base_env=level_ten_env,\n",
        "        soft_switches=level_ten_soft_switches,\n",
        "        hard_switches=level_ten_hard_switches,\n",
        "        teleport_switches=level_ten_teleport_switches,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJubQ-4lVC4S"
      },
      "source": [
        "## Set random seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ffMlXivKVC4S"
      },
      "outputs": [],
      "source": [
        "seed = 777\n",
        "\n",
        "def seed_torch(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.backends.cudnn.enabled:\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "seed_torch(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbTKQgkUVC4T"
      },
      "source": [
        "## Initialize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WffzQMgBVC4T",
        "outputId": "2cf86db0-8d00-4b24-8757-1395125fdcb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# parameters\n",
        "num_frames = 500000\n",
        "memory_size = 1000\n",
        "batch_size = 128\n",
        "target_update = 150\n",
        "epsilon_decay = 1 / 100\n",
        "\n",
        "# train\n",
        "agent = DQNAgent(env, memory_size, batch_size, target_update, epsilon_decay, seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbpG22FqVC4T"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "KWaFcIOzVC4T",
        "outputId": "56d733c8-f19c-4e77-c35e-554b5876f615"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x500 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[23], line 178\u001b[0m, in \u001b[0;36mDQNAgent.train\u001b[0;34m(self, num_frames, plotting_interval)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m# if training is ready\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size:\n\u001b[0;32m--> 178\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m    180\u001b[0m     update_cnt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "Cell \u001b[0;32mIn[23], line 127\u001b[0m, in \u001b[0;36mDQNAgent.update_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Update the model by gradient descent.\"\"\"\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# PER needs beta to calculate weights\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(\n\u001b[1;32m    129\u001b[0m     samples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    130\u001b[0m )\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    131\u001b[0m indices \u001b[38;5;241m=\u001b[39m samples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "Cell \u001b[0;32mIn[21], line 62\u001b[0m, in \u001b[0;36mPrioritizedReplayBuffer.sample_batch\u001b[0;34m(self, beta)\u001b[0m\n\u001b[1;32m     60\u001b[0m rews \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrews_buf[indices]\n\u001b[1;32m     61\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone_buf[indices]\n\u001b[0;32m---> 62\u001b[0m weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_weight(i, beta) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices])\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m     65\u001b[0m     obs\u001b[38;5;241m=\u001b[39mobs,\n\u001b[1;32m     66\u001b[0m     next_obs\u001b[38;5;241m=\u001b[39mnext_obs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m     indices\u001b[38;5;241m=\u001b[39mindices,\n\u001b[1;32m     72\u001b[0m )\n",
            "Cell \u001b[0;32mIn[21], line 62\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     60\u001b[0m rews \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrews_buf[indices]\n\u001b[1;32m     61\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone_buf[indices]\n\u001b[0;32m---> 62\u001b[0m weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calculate_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices])\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m     65\u001b[0m     obs\u001b[38;5;241m=\u001b[39mobs,\n\u001b[1;32m     66\u001b[0m     next_obs\u001b[38;5;241m=\u001b[39mnext_obs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m     indices\u001b[38;5;241m=\u001b[39mindices,\n\u001b[1;32m     72\u001b[0m )\n",
            "Cell \u001b[0;32mIn[21], line 109\u001b[0m, in \u001b[0;36mPrioritizedReplayBuffer._calculate_weight\u001b[0;34m(self, idx, beta)\u001b[0m\n\u001b[1;32m    106\u001b[0m max_weight \u001b[38;5;241m=\u001b[39m (p_min \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m-\u001b[39mbeta)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# calculate weights\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m p_sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum_tree\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msum_tree\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m    110\u001b[0m weight \u001b[38;5;241m=\u001b[39m (p_sample \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m-\u001b[39mbeta)\n\u001b[1;32m    111\u001b[0m weight \u001b[38;5;241m=\u001b[39m weight \u001b[38;5;241m/\u001b[39m max_weight\n",
            "File \u001b[0;32m~/Documents/cs394r_rl_bloxorz_final_project/DQN/segment_tree.py:73\u001b[0m, in \u001b[0;36mSegmentTree.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree[idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperation(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree[\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree[\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     71\u001b[0m         idx \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m     74\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get real value in leaf node of tree.\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcapacity\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "agent.train(num_frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78nYixAyWsYc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
