{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6eOmmt_VC4M"
      },
      "source": [
        "## Configurations for Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "svqqkxUyVC4O",
        "outputId": "bf723d7b-40df-42f2-bb7d-5fa885b07db6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "\u001b[1;31mE: \u001b[0mUnable to locate package python-opengl\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common\n",
            "The following NEW packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common xvfb\n",
            "0 upgraded, 9 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 7,813 kB of archives.\n",
            "After this operation, 11.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.10 [28.5 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.10 [863 kB]\n",
            "Fetched 7,813 kB in 4s (2,037 kB/s)\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "(Reading database ... 121752 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../1-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../2-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../3-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../4-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../5-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../6-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../7-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.10_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../8-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.10_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "Collecting PyVirtualDisplay==3.0\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: PyVirtualDisplay\n",
            "Successfully installed PyVirtualDisplay-3.0\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    !apt install python-opengl\n",
        "    !apt install ffmpeg\n",
        "    !apt install xvfb\n",
        "    !pip install PyVirtualDisplay==3.0\n",
        "    !pip install gym\n",
        "    from pyvirtualdisplay import Display\n",
        "\n",
        "    # Start virtual display\n",
        "    dis = Display(visible=0, size=(400, 400))\n",
        "    dis.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuhgItfjVC4P"
      },
      "source": [
        "# 03. Prioritized Experience Replay (PER)\n",
        "\n",
        "[T. Schaul et al., \"Prioritized Experience Replay.\" arXiv preprint arXiv:1511.05952, 2015.](https://arxiv.org/pdf/1511.05952.pdf)\n",
        "\n",
        "Using a replay memory leads to design choices at two levels: which experiences to store, and which experiences to replay (and how to do so). This paper addresses only the latter: making the most effective use of the replay memory for learning, assuming that its contents are outside of our control.\n",
        "\n",
        "The central component of prioritized replay is the criterion by which the importance of each transition is measured. A reasonable approach is to use the magnitude of a transition’s TD error $\\delta$, which indicates how ‘surprising’\n",
        "or unexpected the transition is. This algorithm stores the last encountered TD error along with each transition in the replay memory. The transition with the largest absolute TD error is replayed from the memory. A Q-learning update\n",
        "is applied to this transition, which updates the weights in proportion to the TD error. One thing to note that new transitions arrive without a known TD-error, so it puts them at maximal priority in order to guarantee that all experience is seen at least once. (see *store* method)\n",
        "\n",
        "We might use 2 ideas to deal with TD-error: 1. greedy TD-error prioritization, 2. stochastic prioritization. However, greedy TD-error prioritization has a severe drawback. Greedy prioritization focuses on a small subset of the experience: errors shrink slowly, especially when using function approximation, meaning that the initially high error transitions get replayed frequently. This lack of diversity that makes the system prone to over-fitting. To overcome this issue, we will use a stochastic sampling method that interpolates between pure greedy prioritization and uniform random sampling.\n",
        "\n",
        "$$\n",
        "P(i) = \\frac{p_i^{\\alpha}}{\\sum_k p_k^{\\alpha}}\n",
        "$$\n",
        "\n",
        "where $p_i > 0$ is the priority of transition $i$. The exponent $\\alpha$ determines how much prioritization is used, with $\\alpha = 0$ corresponding to the uniform case. In practice, we use additional term $\\epsilon$ in order to guarantee all transactions can be possibly sampled: $p_i = |\\delta_i| + \\epsilon$, where $\\epsilon$ is a small positive constant.\n",
        "\n",
        "One more. Let's recall one of the main ideas of DQN. To remove correlation of observations, it uses uniformly random sampling from the replay buffer. Prioritized replay introduces bias because it doesn't sample experiences uniformly at random due to the sampling proportion correspoding to TD-error. We can correct this bias by using importance-sampling (IS) weights\n",
        "\n",
        "$$\n",
        "w_i = \\big( \\frac{1}{N} \\cdot \\frac{1}{P(i)} \\big)^\\beta\n",
        "$$\n",
        "\n",
        "that fully compensates for the non-uniform probabilities $P(i)$ if $\\beta = 1$. These weights can be folded into the Q-learning update by using $w_i\\delta_i$ instead of $\\delta_i$. In typical reinforcement learning scenarios, the unbiased nature of the updates is most important near convergence at the end of training, We therefore exploit the flexibility of annealing the amount of importance-sampling correction over time, by defining a schedule on the exponent $\\beta$ that reaches 1 only at the end of learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "puS8qt-fVC4P",
        "outputId": "b484d0ed-1a69-4d84-833c-b3d775626aa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-04-22 17:23:50--  https://raw.githubusercontent.com/curt-park/rainbow-is-all-you-need/master/segment_tree.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4283 (4.2K) [text/plain]\n",
            "Saving to: ‘segment_tree.py’\n",
            "\n",
            "segment_tree.py     100%[===================>]   4.18K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-04-22 17:23:51 (54.3 MB/s) - ‘segment_tree.py’ saved [4283/4283]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from IPython.display import clear_output\n",
        "\n",
        "if IN_COLAB and not os.path.exists(\"segment_tree.py\"):\n",
        "    # download segment tree module\n",
        "    !wget https://raw.githubusercontent.com/curt-park/rainbow-is-all-you-need/master/segment_tree.py\n",
        "\n",
        "from segment_tree import MinSegmentTree, SumSegmentTree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN_ITfpSVC4Q"
      },
      "source": [
        "## Replay buffer\n",
        "\n",
        "Please see *01.dqn.ipynb* for detailed description."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lAW_-jJnVC4Q",
        "outputId": "e89bce02-bd0a-471d-e0cb-678c795d9175"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "class ReplayBuffer:\n",
        "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
        "\n",
        "    def __init__(self, obs_dim: int, size: int, batch_size: int = 32):\n",
        "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
        "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
        "        self.acts_buf = np.zeros([size], dtype=np.float32)\n",
        "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
        "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
        "        self.max_size, self.batch_size = size, batch_size\n",
        "        self.ptr, self.size, = 0, 0\n",
        "\n",
        "    def store(\n",
        "        self,\n",
        "        obs: np.ndarray,\n",
        "        act: np.ndarray,\n",
        "        rew: float,\n",
        "        next_obs: np.ndarray,\n",
        "        done: bool,\n",
        "    ):\n",
        "        self.obs_buf[self.ptr] = obs\n",
        "        self.next_obs_buf[self.ptr] = next_obs\n",
        "        self.acts_buf[self.ptr] = act\n",
        "        self.rews_buf[self.ptr] = rew\n",
        "        self.done_buf[self.ptr] = done\n",
        "        self.ptr = (self.ptr + 1) % self.max_size\n",
        "        self.size = min(self.size + 1, self.max_size)\n",
        "\n",
        "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
        "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
        "        return dict(obs=self.obs_buf[idxs],\n",
        "                    next_obs=self.next_obs_buf[idxs],\n",
        "                    acts=self.acts_buf[idxs],\n",
        "                    rews=self.rews_buf[idxs],\n",
        "                    done=self.done_buf[idxs])\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLGcEWI5VC4Q"
      },
      "source": [
        "## Prioritized replay Buffer\n",
        "\n",
        "The key concept of PER's implementation is *Segment Tree*. It efficiently stores and samples transitions while managing the priorities of them. We recommend you understand how it works before you move on. Here are references for you:\n",
        "\n",
        "- In Korean: https://mrsyee.github.io/rl/2019/01/25/PER-sumtree/\n",
        "- In English: https://www.geeksforgeeks.org/segment-tree-set-1-sum-of-given-range/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "K6gAr0g2VC4R"
      },
      "outputs": [],
      "source": [
        "class PrioritizedReplayBuffer(ReplayBuffer):\n",
        "    \"\"\"Prioritized Replay buffer.\n",
        "\n",
        "    Attributes:\n",
        "        max_priority (float): max priority\n",
        "        tree_ptr (int): next index of tree\n",
        "        alpha (float): alpha parameter for prioritized replay buffer\n",
        "        sum_tree (SumSegmentTree): sum tree for prior\n",
        "        min_tree (MinSegmentTree): min tree for min prior to get max weight\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        obs_dim: int,\n",
        "        size: int,\n",
        "        batch_size: int = 32,\n",
        "        alpha: float = 0.6\n",
        "    ):\n",
        "        \"\"\"Initialization.\"\"\"\n",
        "        assert alpha >= 0\n",
        "\n",
        "        super(PrioritizedReplayBuffer, self).__init__(obs_dim, size, batch_size)\n",
        "        self.max_priority, self.tree_ptr = 1.0, 0\n",
        "        self.alpha = alpha\n",
        "\n",
        "        # capacity must be positive and a power of 2.\n",
        "        tree_capacity = 1\n",
        "        while tree_capacity < self.max_size:\n",
        "            tree_capacity *= 2\n",
        "\n",
        "        self.sum_tree = SumSegmentTree(tree_capacity)\n",
        "        self.min_tree = MinSegmentTree(tree_capacity)\n",
        "\n",
        "    def store(\n",
        "        self,\n",
        "        obs: np.ndarray,\n",
        "        act: int,\n",
        "        rew: float,\n",
        "        next_obs: np.ndarray,\n",
        "        done: bool\n",
        "    ):\n",
        "        \"\"\"Store experience and priority.\"\"\"\n",
        "        super().store(obs, act, rew, next_obs, done)\n",
        "\n",
        "        self.sum_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
        "        self.min_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
        "        self.tree_ptr = (self.tree_ptr + 1) % self.max_size\n",
        "\n",
        "    def sample_batch(self, beta: float = 0.4) -> Dict[str, np.ndarray]:\n",
        "        \"\"\"Sample a batch of experiences.\"\"\"\n",
        "        assert len(self) >= self.batch_size\n",
        "        assert beta > 0\n",
        "\n",
        "        indices = self._sample_proportional()\n",
        "\n",
        "        obs = self.obs_buf[indices]\n",
        "        next_obs = self.next_obs_buf[indices]\n",
        "        acts = self.acts_buf[indices]\n",
        "        rews = self.rews_buf[indices]\n",
        "        done = self.done_buf[indices]\n",
        "        weights = np.array([self._calculate_weight(i, beta) for i in indices])\n",
        "\n",
        "        return dict(\n",
        "            obs=obs,\n",
        "            next_obs=next_obs,\n",
        "            acts=acts,\n",
        "            rews=rews,\n",
        "            done=done,\n",
        "            weights=weights,\n",
        "            indices=indices,\n",
        "        )\n",
        "\n",
        "    def update_priorities(self, indices: List[int], priorities: np.ndarray):\n",
        "        \"\"\"Update priorities of sampled transitions.\"\"\"\n",
        "        assert len(indices) == len(priorities)\n",
        "\n",
        "        for idx, priority in zip(indices, priorities):\n",
        "            assert priority > 0\n",
        "            assert 0 <= idx < len(self)\n",
        "\n",
        "            self.sum_tree[idx] = priority ** self.alpha\n",
        "            self.min_tree[idx] = priority ** self.alpha\n",
        "\n",
        "            self.max_priority = max(self.max_priority, priority)\n",
        "\n",
        "    def _sample_proportional(self) -> List[int]:\n",
        "        \"\"\"Sample indices based on proportions.\"\"\"\n",
        "        indices = []\n",
        "        p_total = self.sum_tree.sum(0, len(self) - 1)\n",
        "        segment = p_total / self.batch_size\n",
        "\n",
        "        for i in range(self.batch_size):\n",
        "            a = segment * i\n",
        "            b = segment * (i + 1)\n",
        "            upperbound = random.uniform(a, b)\n",
        "            idx = self.sum_tree.retrieve(upperbound)\n",
        "            indices.append(idx)\n",
        "\n",
        "        return indices\n",
        "\n",
        "    def _calculate_weight(self, idx: int, beta: float):\n",
        "        \"\"\"Calculate the weight of the experience at idx.\"\"\"\n",
        "        # get max weight\n",
        "        p_min = self.min_tree.min() / self.sum_tree.sum()\n",
        "        max_weight = (p_min * len(self)) ** (-beta)\n",
        "\n",
        "        # calculate weights\n",
        "        p_sample = self.sum_tree[idx] / self.sum_tree.sum()\n",
        "        weight = (p_sample * len(self)) ** (-beta)\n",
        "        weight = weight / max_weight\n",
        "\n",
        "        return weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6h4B-kuVC4R"
      },
      "source": [
        "## Network\n",
        "\n",
        "We are going to use a simple network architecture with three fully connected layers and two non-linearity functions (ReLU)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hW7LeRU5VC4R"
      },
      "outputs": [],
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self, in_dim: int, out_dim: int):\n",
        "        \"\"\"Initialization.\"\"\"\n",
        "        super(Network, self).__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(in_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, out_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward method implementation.\"\"\"\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPct4OusVC4R"
      },
      "source": [
        "## DQN + PER Agent\n",
        "\n",
        "Here is a summary of DQNAgent class.\n",
        "\n",
        "| Method           | Note                                                 |\n",
        "| ---              | ---                                                  |\n",
        "|select_action     | select an action from the input state.               |\n",
        "|step              | take an action and return the response of the env.   |\n",
        "|compute_dqn_loss  | return dqn loss.                                     |\n",
        "|update_model      | update the model by gradient descent.                |\n",
        "|target_hard_update| hard update from the local model to the target model.|\n",
        "|train             | train the agent during num_frames.                   |\n",
        "|test              | test the agent (1 episode).                          |\n",
        "|plot              | plot the training progresses.                        |\n",
        "\n",
        "\n",
        "All differences from pure DQN are noted with comments - PER.\n",
        "\n",
        "#### __init__\n",
        "\n",
        "Here, we use PrioritizedReplayBuffer, instead of ReplayBuffer, and use hold 2 more parameters beta and priority epsilon which are used to calculate weights and new priorities respectively.\n",
        "\n",
        "#### compute_dqn_loss & update_model\n",
        "\n",
        "It returns every loss per each sample for importance sampling before average. After updating the nework, it is necessary to update priorities of all sampled experiences.\n",
        "\n",
        "#### train\n",
        "\n",
        "beta linearly increases to 1 at every training step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-6CxsyU5VC4S"
      },
      "outputs": [],
      "source": [
        "class DQNAgent:\n",
        "    \"\"\"DQN Agent interacting with environment.\n",
        "\n",
        "    Attribute:\n",
        "        env (gym.Env): openAI Gym environment\n",
        "        memory (ReplayBuffer): replay memory to store transitions\n",
        "        batch_size (int): batch size for sampling\n",
        "        epsilon (float): parameter for epsilon greedy policy\n",
        "        epsilon_decay (float): step size to decrease epsilon\n",
        "        max_epsilon (float): max value of epsilon\n",
        "        min_epsilon (float): min value of epsilon\n",
        "        target_update (int): period for target model's hard update\n",
        "        gamma (float): discount factor\n",
        "        dqn (Network): model to train and select actions\n",
        "        dqn_target (Network): target model to update\n",
        "        optimizer (torch.optim): optimizer for training dqn\n",
        "        transition (list): transition information including\n",
        "                           state, action, reward, next_state, done\n",
        "        beta (float): determines how much importance sampling is used\n",
        "        prior_eps (float): guarantees every transition can be sampled\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        env: gym.Env,\n",
        "        memory_size: int,\n",
        "        batch_size: int,\n",
        "        target_update: int,\n",
        "        epsilon_decay: float,\n",
        "        seed: int,\n",
        "        max_epsilon: float = 1.0,\n",
        "        min_epsilon: float = 0.1,\n",
        "        gamma: float = 0.99,\n",
        "        # PER parameters\n",
        "        alpha: float = 0.2,\n",
        "        beta: float = 0.6,\n",
        "        prior_eps: float = 1e-6,\n",
        "    ):\n",
        "        \"\"\"Initialization.\n",
        "\n",
        "        Args:\n",
        "            env (gym.Env): openAI Gym environment\n",
        "            memory_size (int): length of memory\n",
        "            batch_size (int): batch size for sampling\n",
        "            target_update (int): period for target model's hard update\n",
        "            epsilon_decay (float): step size to decrease epsilon\n",
        "            lr (float): learning rate\n",
        "            max_epsilon (float): max value of epsilon\n",
        "            min_epsilon (float): min value of epsilon\n",
        "            gamma (float): discount factor\n",
        "            alpha (float): determines how much prioritization is used\n",
        "            beta (float): determines how much importance sampling is used\n",
        "            prior_eps (float): guarantees every transition can be sampled\n",
        "        \"\"\"\n",
        "        obs_dim = env.observation_space.shape[0]\n",
        "        action_dim = env.action_space.n\n",
        "\n",
        "        self.env = env\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.epsilon = max_epsilon\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.seed = seed\n",
        "        self.max_epsilon = max_epsilon\n",
        "        self.min_epsilon = min_epsilon\n",
        "        self.target_update = target_update\n",
        "        self.gamma = gamma\n",
        "\n",
        "        # device: cpu / gpu\n",
        "        self.device = torch.device(\n",
        "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        )\n",
        "        print(self.device)\n",
        "\n",
        "        # PER\n",
        "        # In DQN, We used \"ReplayBuffer(obs_dim, memory_size, batch_size)\"\n",
        "        self.beta = beta\n",
        "        self.prior_eps = prior_eps\n",
        "        self.memory = PrioritizedReplayBuffer(\n",
        "            obs_dim, memory_size, batch_size, alpha\n",
        "        )\n",
        "\n",
        "        # networks: dqn, dqn_target\n",
        "        self.dqn = Network(obs_dim, action_dim).to(self.device)\n",
        "        self.dqn_target = Network(obs_dim, action_dim).to(self.device)\n",
        "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
        "        self.dqn_target.eval()\n",
        "\n",
        "        # optimizer\n",
        "        self.optimizer = optim.Adam(self.dqn.parameters())\n",
        "\n",
        "        # transition to store in memory\n",
        "        self.transition = list()\n",
        "\n",
        "        # mode: train / test\n",
        "        self.is_test = False\n",
        "\n",
        "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Select an action from the input state.\"\"\"\n",
        "        # epsilon greedy policy\n",
        "        if self.epsilon > np.random.random():\n",
        "            selected_action = self.env.action_space.sample()\n",
        "        else:\n",
        "            selected_action = self.dqn(\n",
        "                torch.FloatTensor(state).to(self.device)\n",
        "            ).argmax()\n",
        "            selected_action = selected_action.detach().cpu().numpy()\n",
        "\n",
        "        if not self.is_test:\n",
        "            self.transition = [state, selected_action]\n",
        "\n",
        "        return selected_action\n",
        "\n",
        "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
        "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
        "        next_state, reward, done= self.env.step(action)\n",
        "\n",
        "        if not self.is_test:\n",
        "            self.transition += [reward, next_state, done]\n",
        "            self.memory.store(*self.transition)\n",
        "\n",
        "        return next_state, reward, done\n",
        "\n",
        "    def update_model(self) -> torch.Tensor:\n",
        "        \"\"\"Update the model by gradient descent.\"\"\"\n",
        "        # PER needs beta to calculate weights\n",
        "        samples = self.memory.sample_batch(self.beta)\n",
        "        weights = torch.FloatTensor(\n",
        "            samples[\"weights\"].reshape(-1, 1)\n",
        "        ).to(self.device)\n",
        "        indices = samples[\"indices\"]\n",
        "\n",
        "        # PER: importance sampling before average\n",
        "        elementwise_loss = self._compute_dqn_loss(samples)\n",
        "        loss = torch.mean(elementwise_loss * weights)\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        # PER: update priorities\n",
        "        loss_for_prior = elementwise_loss.detach().cpu().numpy()\n",
        "        new_priorities = loss_for_prior + self.prior_eps\n",
        "        self.memory.update_priorities(indices, new_priorities)\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "    def train(self, num_frames: int, plotting_interval: int = 200):\n",
        "        \"\"\"Train the agent.\"\"\"\n",
        "        self.is_test = False\n",
        "\n",
        "        state, _ = self.env.reset(seed=self.seed)\n",
        "        update_cnt = 0\n",
        "        epsilons = []\n",
        "        losses = []\n",
        "        scores = []\n",
        "        score = 0\n",
        "\n",
        "        for frame_idx in range(1, num_frames + 1):\n",
        "            action = self.select_action(state)\n",
        "            next_state, reward, done = self.step(action)\n",
        "\n",
        "            state = next_state\n",
        "            score += reward\n",
        "\n",
        "            # PER: increase beta\n",
        "            fraction = min(frame_idx / num_frames, 1.0)\n",
        "            self.beta = self.beta + fraction * (1.0 - self.beta)\n",
        "\n",
        "            # if episode ends\n",
        "            if done:\n",
        "                state, _ = self.env.reset(seed=self.seed)\n",
        "                scores.append(score)\n",
        "                score = 0\n",
        "\n",
        "            # if training is ready\n",
        "            if len(self.memory) >= self.batch_size:\n",
        "                loss = self.update_model()\n",
        "                losses.append(loss)\n",
        "                update_cnt += 1\n",
        "\n",
        "                # linearly decrease epsilon\n",
        "                self.epsilon = max(\n",
        "                    self.min_epsilon, self.epsilon - (\n",
        "                        self.max_epsilon - self.min_epsilon\n",
        "                    ) * self.epsilon_decay\n",
        "                )\n",
        "                epsilons.append(self.epsilon)\n",
        "\n",
        "                # if hard update is needed\n",
        "                if update_cnt % self.target_update == 0:\n",
        "                    self._target_hard_update()\n",
        "\n",
        "            # plotting\n",
        "            if frame_idx % plotting_interval == 0:\n",
        "                self._plot(frame_idx, scores, losses, epsilons)\n",
        "\n",
        "        self.env.close()\n",
        "\n",
        "    def test(self, video_folder: str) -> None:\n",
        "        \"\"\"Test the agent.\"\"\"\n",
        "        self.is_test = True\n",
        "\n",
        "        # for recording a video\n",
        "        naive_env = self.env\n",
        "        self.env = gym.wrappers.RecordVideo(self.env, video_folder=video_folder)\n",
        "\n",
        "        state, _ = self.env.reset(seed=self.seed)\n",
        "        done = False\n",
        "        score = 0\n",
        "\n",
        "        while not done:\n",
        "            action = self.select_action(state)\n",
        "            next_state, reward, done = self.step(action)\n",
        "\n",
        "            state = next_state\n",
        "            score += reward\n",
        "\n",
        "        print(\"score: \", score)\n",
        "        self.env.close()\n",
        "\n",
        "        # reset\n",
        "        self.env = naive_env\n",
        "\n",
        "    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray]) -> torch.Tensor:\n",
        "        \"\"\"Return dqn loss.\"\"\"\n",
        "        device = self.device  # for shortening the following lines\n",
        "        state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
        "        next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
        "        action = torch.LongTensor(samples[\"acts\"].reshape(-1, 1)).to(device)\n",
        "        reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
        "        done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
        "\n",
        "        # G_t   = r + gamma * v(s_{t+1})  if state != Terminal\n",
        "        #       = r                       otherwise\n",
        "        curr_q_value = self.dqn(state).gather(1, action)\n",
        "        next_q_value = self.dqn_target(\n",
        "            next_state\n",
        "        ).max(dim=1, keepdim=True)[0].detach()\n",
        "        mask = 1 - done\n",
        "        target = (reward + self.gamma * next_q_value * mask).to(self.device)\n",
        "\n",
        "        # calculate element-wise dqn loss\n",
        "        elementwise_loss = F.smooth_l1_loss(curr_q_value, target, reduction=\"none\")\n",
        "\n",
        "        return elementwise_loss\n",
        "\n",
        "    def _target_hard_update(self):\n",
        "        \"\"\"Hard update: target <- local.\"\"\"\n",
        "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
        "\n",
        "    def _plot(\n",
        "        self,\n",
        "        frame_idx: int,\n",
        "        scores: List[float],\n",
        "        losses: List[float],\n",
        "        epsilons: List[float],\n",
        "    ):\n",
        "        \"\"\"Plot the training progresses.\"\"\"\n",
        "        clear_output(True)\n",
        "        plt.figure(figsize=(20, 5))\n",
        "        plt.subplot(131)\n",
        "        plt.title('frame %s. score: %s' % (frame_idx, np.mean(scores[-10:])))\n",
        "        plt.plot(scores)\n",
        "        plt.subplot(132)\n",
        "        plt.title('loss')\n",
        "        plt.plot(losses)\n",
        "        plt.subplot(133)\n",
        "        plt.title('epsilons')\n",
        "        plt.plot(epsilons)\n",
        "        plt.grid()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBl6CMcHVC4S"
      },
      "source": [
        "## Environment\n",
        "\n",
        "You can see the [code](https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/envs/classic_control/cartpole.py) and [configurations](https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/envs/classic_control/cartpole.py#L91) of CartPole-v1 from Farama Gymnasium's repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bh8c7WDWVC4S"
      },
      "outputs": [],
      "source": [
        "# 0: normal tile\n",
        "# 1: orange tile\n",
        "# 2: soft switch\n",
        "# 3: hard switch\n",
        "# 4: goal\n",
        "# 5: transport switch\n",
        "# 8: block\n",
        "# 9: none\n",
        "\n",
        "# Level 1:\n",
        "level_one_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 4, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Level 2:\n",
        "level_two_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 3, 0, 9, 9, 0, 4, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 2, 0, 9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "level_two_soft_switches = np.array(\n",
        "    [{\"switch_location\": (4, 4), \"toggle_tiles\": [(6, 6), (6, 7)], \"mode\": \"toggle\"}]\n",
        ")\n",
        "\n",
        "\n",
        "level_two_hard_switches = np.array(\n",
        "    [{\"switch_location\": (3, 10), \"toggle_tiles\": [(6, 12), (6, 13)]}]\n",
        ")\n",
        "\n",
        "# Level 3:\n",
        "level_three_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 9, 9, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 4, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Level 4:\n",
        "level_four_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 1, 1, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 1, 1, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 0, 0, 0, 0, 1, 1, 1, 1, 1, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 0, 0, 0, 0, 1, 1, 1, 1, 1, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 4, 0, 9, 9, 1, 1, 0, 1, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 1, 1, 1, 1, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Level 5:\n",
        "level_five_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 2, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 2, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "level_five_soft_switches = np.array(\n",
        "    [\n",
        "        {\n",
        "            \"switch_location\": (2, 10),\n",
        "            \"toggle_tiles\": [(2, 7), (2, 8)],\n",
        "            \"mode\": \"toggle\",\n",
        "        },\n",
        "        {\n",
        "            \"switch_location\": (7, 16),\n",
        "            \"toggle_tiles\": [(9, 7), (9, 8)],\n",
        "            \"mode\": \"toggle\",\n",
        "        },\n",
        "        {\"switch_location\": (6, 8), \"toggle_tiles\": [(9, 7), (9, 8)], \"mode\": \"off\"},\n",
        "        {\"switch_location\": (4, 5), \"toggle_tiles\": [(9, 7), (9, 8)], \"mode\": \"on\"},\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Level 6:\n",
        "level_six_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 0, 0, 0, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 0, 0, 4, 0, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Level 7:\n",
        "level_seven_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 0, 9, 9, 0, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 0, 4, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 0, 0, 3, 9, 9, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 0, 0, 0, 9, 9, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "level_seven_hard_switches = np.array(\n",
        "    [{\"switch_location\": (5, 12), \"toggle_tiles\": [(7, 6)]}]\n",
        ")\n",
        "\n",
        "\n",
        "# Level 8:\n",
        "level_eight_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 5, 0, 9, 9, 9, 0, 0, 0, 0, 4, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "level_eight_teleport_switches = np.array(\n",
        "    [{\"switch_location\": (6, 7), \"split_positions\": [(3, 13), (9, 13)]}]\n",
        ")\n",
        "\n",
        "\n",
        "# Level 9:\n",
        "level_nine_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 0, 9, 9, 9, 0, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 0, 9, 9, 9, 0, 0, 5, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 4, 0, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "level_nine_teleport_switches = np.array(\n",
        "    [{\"switch_location\": (4, 16), \"split_positions\": [(4, 15), (4, 5)]}]\n",
        ")\n",
        "\n",
        "\n",
        "# Level 10:\n",
        "level_ten_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 4, 0, 9, 9, 0, 9, 9, 0, 0, 0, 0, 5, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 9, 9, 0, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 0, 2, 9, 9, 0, 0, 0, 3, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "level_ten_teleport_switches = np.array(\n",
        "    [{\"switch_location\": (2, 15), \"split_positions\": [(2, 15), (2, 12)]}]\n",
        ")\n",
        "\n",
        "level_ten_hard_switches = np.array(\n",
        "    [{\"switch_location\": (10, 14), \"toggle_tiles\": [(2, 9), (2, 10),(3, 15), (4, 15)]}]\n",
        ")\n",
        "\n",
        "level_ten_soft_switches = np.array(\n",
        "    [{\"switch_location\": (10, 8), \"toggle_tiles\": [(2, 6), (2, 7)], \"mode\":\"toggle\"}]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6TuNlvRRVdpY"
      },
      "outputs": [],
      "source": [
        "class Block:\n",
        "\n",
        "    def __init__(self, r1, c1, r2, c2):\n",
        "        self._r1 = r1\n",
        "        self._r2 = r2\n",
        "        self._c1 = c1\n",
        "        self._c2 = c2\n",
        "\n",
        "        self._focus_block = 0\n",
        "\n",
        "    def set_coords(self, r1, c1, r2, c2):\n",
        "        self._r1 = r1\n",
        "        self._r2 = r2\n",
        "        self._c1 = c1\n",
        "        self._c2 = c2\n",
        "\n",
        "    def get_coords(self):\n",
        "        return self._r1, self._c1, self._r2, self._c2\n",
        "\n",
        "    def is_upright(self):\n",
        "        return self._r1 == self._r2 and self._c1 == self._c2\n",
        "\n",
        "    def is_wide(self):\n",
        "        return self._r1 == self._r2 and self._c1 != self._c2\n",
        "\n",
        "    def move_up(self):\n",
        "        match self._focus_block:\n",
        "            case 0:\n",
        "                # vertical\n",
        "                if self.is_upright():\n",
        "                    self._r1 -= 1\n",
        "                    self._r2 -= 2\n",
        "\n",
        "                # flat and wide\n",
        "                elif self.is_wide():\n",
        "                    self._r1 -= 1\n",
        "                    self._r2 -= 1\n",
        "\n",
        "                # flat and long\n",
        "                else:\n",
        "                    min_r = min(self._r1, self._r2)\n",
        "                    self._r1 = min_r - 1\n",
        "                    self._r2 = min_r - 1\n",
        "\n",
        "            case 1:\n",
        "                self._r1 -= 1\n",
        "\n",
        "            case 2:\n",
        "                self._r2 -= 1\n",
        "\n",
        "    def move_down(self):\n",
        "        match self._focus_block:\n",
        "            case 0:\n",
        "                # vertical\n",
        "                if self.is_upright():\n",
        "                    self._r1 += 1\n",
        "                    self._r2 += 2\n",
        "\n",
        "                # flat and wide\n",
        "                elif self.is_wide():\n",
        "                    self._r1 += 1\n",
        "                    self._r2 += 1\n",
        "\n",
        "                # flat and long\n",
        "                else:\n",
        "                    max_r = max(self._r1, self._r2)\n",
        "                    self._r1 = max_r + 1\n",
        "                    self._r2 = max_r + 1\n",
        "\n",
        "            case 1:\n",
        "                self._r1 += 1\n",
        "            case 2:\n",
        "                self._r2 += 1\n",
        "\n",
        "    # edited\n",
        "    def move_right(self):\n",
        "        match self._focus_block:\n",
        "            case 0:\n",
        "                # vertical\n",
        "                if self.is_upright():\n",
        "                    self._c1 += 1\n",
        "                    self._c2 += 2\n",
        "\n",
        "                # flat and wide\n",
        "                elif self.is_wide():\n",
        "                    max_c = max(self._c1, self._c2)\n",
        "                    self._c1 = max_c + 1\n",
        "                    self._c2 = max_c + 1\n",
        "\n",
        "                # flat and long\n",
        "                else:\n",
        "                    self._c1 += 1\n",
        "                    self._c2 += 1\n",
        "\n",
        "            case 1:\n",
        "                self._c1 += 1\n",
        "            case 2:\n",
        "                self._c2 += 1\n",
        "\n",
        "    # edited\n",
        "    def move_left(self):\n",
        "        match self._focus_block:\n",
        "            case 0:\n",
        "                # vertical\n",
        "                if self.is_upright():\n",
        "                    self._c1 -= 1\n",
        "                    self._c2 -= 2\n",
        "\n",
        "                # flat and wide\n",
        "                elif self.is_wide():\n",
        "                    min_c = min(self._c1, self._c2)\n",
        "                    self._c1 = min_c - 1\n",
        "                    self._c2 = min_c - 1\n",
        "\n",
        "                # flat and long\n",
        "                else:\n",
        "                    self._c1 -= 1\n",
        "                    self._c2 -= 1\n",
        "            case 1:\n",
        "                self._c1 -= 1\n",
        "            case 2:\n",
        "                self._c2 -= 1\n",
        "\n",
        "    def toggle_focus(self):\n",
        "        if self._focus_block == 0:\n",
        "            self._focus_block = 0\n",
        "        elif self._focus_block == 1:\n",
        "            self._focus_block = 2\n",
        "        else:\n",
        "            self._focus_block = 1\n",
        "\n",
        "    def set_focus(self, focus):\n",
        "        self._focus_block = focus\n",
        "\n",
        "    def get_focus(self):\n",
        "        return self._focus_block\n",
        "\n",
        "    def join_single_blocks(self):\n",
        "        if self._focus_block == 1 or self._focus_block == 2:\n",
        "            if abs(self._r1 - self._r2) == 1 and (self._c1 == self._c2):\n",
        "                self.set_focus(0)\n",
        "            elif abs(self._c1 - self._c2) == 1 and (self._r1 == self._r2):\n",
        "                self.set_focus(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "w4krS0-4VfU2"
      },
      "outputs": [],
      "source": [
        "class Level(gym.Env):\n",
        "    metadata = {\"render_modes\": [], \"render_fps\": 0}\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        start_pos: tuple,\n",
        "        base_env: np.array([]),\n",
        "        soft_switches=np.array([]),\n",
        "        hard_switches=np.array([]),\n",
        "        teleport_switches=np.array([]),\n",
        "        render_mode=None,\n",
        "    ):\n",
        "        self._r_start = start_pos[0]\n",
        "        self._c_start = start_pos[1]\n",
        "\n",
        "        self._block = Block(self._r_start, self._c_start, self._r_start, self._c_start)\n",
        "\n",
        "        self._base_env = base_env\n",
        "\n",
        "        self._soft_switches = soft_switches\n",
        "        self._hard_switches = hard_switches\n",
        "        self._teleport_switches = teleport_switches\n",
        "\n",
        "        self._actions = {\n",
        "            0: self._block.move_right,\n",
        "            1: self._block.move_up,\n",
        "            2: self._block.move_left,\n",
        "            3: self._block.move_down,\n",
        "            4: self._block.toggle_focus,\n",
        "        }\n",
        "\n",
        "        self.observation_space = np.append(base_env.ravel(), 0)\n",
        "        self.action_space = gym.spaces.Discrete(5)\n",
        "\n",
        "    def step(self, action):\n",
        "        # if the block is split, check if single blocks are adjacent, and join together\n",
        "        self._block.join_single_blocks()\n",
        "\n",
        "        # update the agent's coords by passing it the action\n",
        "        self._perform_action(action)\n",
        "\n",
        "        # check if the agent is out of bounds -> reset to the start\n",
        "        r1, c1, r2, c2 = self._block.get_coords()\n",
        "\n",
        "        reward, done = self._is_done(r1, c1, r2, c2)\n",
        "\n",
        "        # only check for environment changes if the action is not \"Switch Focus\"\n",
        "        if action != 4:\n",
        "            self._move_to_start(r1, c1, r2, c2)\n",
        "            self._activate_teleport_switch(r1, c1, r2, c2)\n",
        "            self._toggle_soft_switches(r1, c1, r2, c2)\n",
        "            self._toggle_hard_switches(r1, c1, r2, c2)\n",
        "\n",
        "\n",
        "\n",
        "        state = self._format_environment()\n",
        "\n",
        "        return state, reward, done\n",
        "\n",
        "    def reset(self, seed):\n",
        "        # set both of the agent's coords to (self._r_start,self._c_start) and (self._r_start,self._c_start)\n",
        "        self._block.set_coords(\n",
        "            self._r_start, self._c_start, self._r_start, self._c_start\n",
        "        )\n",
        "        self._block.set_focus(0)\n",
        "\n",
        "        # reset the environment (important to undo any obstacle interactions)\n",
        "        self._current_env = np.copy(self._base_env)\n",
        "\n",
        "        # place the agent in the environment using its position\n",
        "        state = np.copy(self._current_env)\n",
        "        state[self._r_start, self._c_start] = 8\n",
        "        state = state.ravel()\n",
        "        state = np.append(state, self._block.get_focus())\n",
        "        # state = np.array2string(state, separator=\"\") + str(self._block.get_focus())\n",
        "\n",
        "        return state, False\n",
        "\n",
        "    def _move_to_start(self, r1, c1, r2, c2):\n",
        "        if self._current_env[r1, c1] == 9 or self._current_env[r2, c2] == 9:\n",
        "            self.reset(42)\n",
        "\n",
        "    def _is_done(self, r1, c1, r2, c2):\n",
        "        # check if the agent is on the goal -> set done to True and reward to 0\n",
        "\n",
        "        # reward is -1 and done is False unless the agent hit the goal\n",
        "        reward = -1\n",
        "        done = False\n",
        "\n",
        "        if self._current_env[r1, c1] == 4 and self._current_env[r2, c2] == 4:\n",
        "            reward = 0\n",
        "            done = True\n",
        "        # elif self._current_env[r1, c1] == 9 or self._current_env[r2, c2] == 9:\n",
        "        #   reward = -1000\n",
        "        #   done = True\n",
        "\n",
        "        return reward, done\n",
        "\n",
        "    def _format_environment(self):\n",
        "        # place the agent in the environment using its position\n",
        "        r1, c1, r2, c2 = self._block.get_coords()\n",
        "        state = np.copy(self._current_env)\n",
        "        state[r1, c1] = 8\n",
        "        state[r2, c2] = 8\n",
        "\n",
        "        state = state.ravel()\n",
        "        state = np.append(state, self._block.get_focus())\n",
        "        # state = np.array2string(state, separator=\"\") + str(self._block.get_focus())\n",
        "\n",
        "        return state\n",
        "\n",
        "    def _toggle_soft_switches(self, r1, c1, r2, c2):\n",
        "        # check if the agent is on a circle switch -> activate bridge\n",
        "        for c in self._soft_switches:\n",
        "            switch_location = c[\"switch_location\"]\n",
        "            toggle_tiles = c[\"toggle_tiles\"]\n",
        "            mode = c[\"mode\"]\n",
        "\n",
        "            if (r1 == switch_location[0] and c1 == switch_location[1]) or (\n",
        "                r2 == switch_location[0] and c2 == switch_location[1]\n",
        "            ):\n",
        "                if mode == \"toggle\":\n",
        "                    if self._current_env[toggle_tiles[0][0], toggle_tiles[0][1]] == 0:\n",
        "                        for t in toggle_tiles:\n",
        "                            self._current_env[t[0], t[1]] = 9\n",
        "                            self._current_env[t[0], t[1]] = 9\n",
        "\n",
        "                    else:\n",
        "                        for t in toggle_tiles:\n",
        "                            self._current_env[t[0], t[1]] = 0\n",
        "                            self._current_env[t[0], t[1]] = 0\n",
        "                elif mode == \"on\":\n",
        "                    for t in toggle_tiles:\n",
        "                        self._current_env[t[0], t[1]] = 0\n",
        "                        self._current_env[t[0], t[1]] = 0\n",
        "                elif mode == \"off\":\n",
        "                    for t in toggle_tiles:\n",
        "                        self._current_env[t[0], t[1]] = 9\n",
        "                        self._current_env[t[0], t[1]] = 9\n",
        "\n",
        "    def _toggle_hard_switches(self, r1, c1, r2, c2):\n",
        "        # check if the agent is on an x switch -> activate bridge\n",
        "        for c in self._hard_switches:\n",
        "            switch_location = c[\"switch_location\"]\n",
        "            toggle_tiles = c[\"toggle_tiles\"]\n",
        "\n",
        "            if (r1 == switch_location[0] and c1 == switch_location[1]) and (\n",
        "                r2 == switch_location[0] and c2 == switch_location[1]\n",
        "            ):\n",
        "                if self._current_env[toggle_tiles[0][0], toggle_tiles[0][1]] == 0:\n",
        "                    for t in toggle_tiles:\n",
        "                        self._current_env[t[0], t[1]] = 9\n",
        "                        self._current_env[t[0], t[1]] = 9\n",
        "\n",
        "                else:\n",
        "                    for t in toggle_tiles:\n",
        "                        self._current_env[t[0], t[1]] = 0\n",
        "                        self._current_env[t[0], t[1]] = 0\n",
        "\n",
        "    def _activate_teleport_switch(self, r1, c1, r2, c2):\n",
        "        # check if block is on teleport switch -> split block into two single blocks\n",
        "        for t in self._teleport_switches:\n",
        "            switch_location = t[\"switch_location\"]\n",
        "            split_positions = t[\"split_positions\"]\n",
        "\n",
        "\n",
        "            if (r1 == switch_location[0] and c1 == switch_location[1]) and (\n",
        "                r2 == switch_location[0] and c2 == switch_location[1]\n",
        "            ):\n",
        "\n",
        "                single_block_one = split_positions[0]\n",
        "                single_block_two = split_positions[1]\n",
        "\n",
        "                r1 = single_block_one[0]\n",
        "                c1 = single_block_one[1]\n",
        "\n",
        "                r2 = single_block_two[0]\n",
        "                c2 = single_block_two[1]\n",
        "\n",
        "                self._block.set_focus(1)\n",
        "                self._block.set_coords(r1, c1, r2, c2)\n",
        "\n",
        "    def _handle_orange_tile(self, r1, c1, r2, c2):\n",
        "        # check if block is vertical\n",
        "        if (r1, c1) == (r2, c2):\n",
        "            # check if tile is orange tile\n",
        "            if self._current_env[r1, c1] == 1:\n",
        "                # tile disappears/block falls through grid\n",
        "\n",
        "                self._block.set_coords(\n",
        "                    self._r_start, self._c_start, self._r_start, self._c_start\n",
        "                )\n",
        "\n",
        "        # nothing happens if block is not vertical on an orange tile\n",
        "\n",
        "    def _perform_action(self, action):\n",
        "        # Get the corresponding method from 'actions' and call it\n",
        "        action_method = self._actions.get(int(action))\n",
        "        if action_method:\n",
        "            action_method()\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid action\")\n",
        "\n",
        "    def get_state(self):\n",
        "        r1, c1, r2, c2 = self._block.get_coords()\n",
        "        print(r1, c1, r2, c2)\n",
        "        state = np.copy(self._current_env)\n",
        "        state[r1, c1] = 8\n",
        "        state[r2, c2] = 8\n",
        "\n",
        "        return state\n",
        "\n",
        "    def get_block(self):\n",
        "        return self._block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mID_Wvk_Vgw3"
      },
      "outputs": [],
      "source": [
        "level = 3\n",
        "\n",
        "if level == 1:\n",
        "        env = Level(start_pos=(3, 6), base_env=level_one_env)\n",
        "\n",
        "elif level == 2:\n",
        "    env = Level(\n",
        "        start_pos=(6, 3),\n",
        "        base_env=level_two_env,\n",
        "        soft_switches=level_two_soft_switches,\n",
        "        hard_switches=level_two_hard_switches,\n",
        "    )\n",
        "\n",
        "elif level == 3:\n",
        "    env = Level(start_pos=(4, 3), base_env=level_three_env)\n",
        "\n",
        "elif level == 4:\n",
        "    env = Level(start_pos=(6, 4), base_env=level_four_env)\n",
        "\n",
        "elif level == 5:\n",
        "    env = Level(\n",
        "        start_pos=(2, 15),\n",
        "        base_env=level_five_env,\n",
        "        soft_switches=level_five_soft_switches,\n",
        "    )\n",
        "elif level == 6:\n",
        "    env = Level(\n",
        "        start_pos=(4, 3),\n",
        "        base_env=level_six_env,\n",
        "    )\n",
        "\n",
        "elif level == 7:\n",
        "    env = Level(\n",
        "        start_pos=(4, 4),\n",
        "        base_env=level_seven_env,\n",
        "        hard_switches=level_seven_hard_switches,\n",
        "    )\n",
        "\n",
        "elif level == 8:\n",
        "    env = Level(\n",
        "        start_pos=(6, 4),\n",
        "        base_env=level_eight_env,\n",
        "        teleport_switches=level_eight_teleport_switches,\n",
        "    )\n",
        "elif level == 9:\n",
        "    env = Level(\n",
        "        start_pos=(4, 4),\n",
        "        base_env=level_nine_env,\n",
        "        teleport_switches=level_nine_teleport_switches\n",
        "    )\n",
        "\n",
        "elif level == 10:\n",
        "    env = Level(\n",
        "        start_pos=(2, 12),\n",
        "        base_env=level_ten_env,\n",
        "        soft_switches=level_ten_soft_switches,\n",
        "        hard_switches=level_ten_hard_switches,\n",
        "        teleport_switches=level_ten_teleport_switches,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJubQ-4lVC4S"
      },
      "source": [
        "## Set random seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ffMlXivKVC4S"
      },
      "outputs": [],
      "source": [
        "seed = 777\n",
        "\n",
        "def seed_torch(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.backends.cudnn.enabled:\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "seed_torch(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbTKQgkUVC4T"
      },
      "source": [
        "## Initialize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WffzQMgBVC4T",
        "outputId": "2cf86db0-8d00-4b24-8757-1395125fdcb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# parameters\n",
        "num_frames = 500000\n",
        "memory_size = 1000\n",
        "batch_size = 128\n",
        "target_update = 150\n",
        "epsilon_decay = 1 / 100\n",
        "\n",
        "# train\n",
        "agent = DQNAgent(env, memory_size, batch_size, target_update, epsilon_decay, seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbpG22FqVC4T"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWaFcIOzVC4T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "56d733c8-f19c-4e77-c35e-554b5876f615"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x500 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "agent.train(num_frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78nYixAyWsYc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "rainbow-is-all-you-need",
      "language": "python",
      "name": "rainbow-is-all-you-need"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}