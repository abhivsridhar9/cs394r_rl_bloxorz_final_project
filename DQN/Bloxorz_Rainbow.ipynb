{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id-HBP3V-A_m"
      },
      "source": [
        "## Configurations for Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFUTdV3B-A_o",
        "outputId": "758f5023-35bc-4429-dae9-18f25ecec94b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "\u001b[1;31mE: \u001b[0mUnable to locate package python-opengl\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.10).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Requirement already satisfied: PyVirtualDisplay==3.0 in /usr/local/lib/python3.10/dist-packages (3.0)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    !apt install python-opengl\n",
        "    !apt install ffmpeg\n",
        "    !apt install xvfb\n",
        "    !pip install PyVirtualDisplay==3.0\n",
        "    !pip install gym\n",
        "    from pyvirtualdisplay import Display\n",
        "\n",
        "    # Start virtual display\n",
        "    dis = Display(visible=0, size=(400, 400))\n",
        "    dis.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1c7fdjf-A_p"
      },
      "source": [
        "# 08. Rainbow\n",
        "\n",
        "[M. Hessel et al., \"Rainbow: Combining Improvements in Deep Reinforcement Learning.\" arXiv preprint arXiv:1710.02298, 2017.](https://arxiv.org/pdf/1710.02298.pdf)\n",
        "\n",
        "We will integrate all the following seven components into a single integrated agent, which is called Rainbow!\n",
        "\n",
        "1. DQN\n",
        "2. Double DQN\n",
        "3. Prioritized Experience Replay\n",
        "4. Dueling Network\n",
        "5. Noisy Network\n",
        "6. Categorical DQN\n",
        "7. N-step Learning\n",
        "\n",
        "This method shows an impressive performance on the Atari 2600 benchmark, both in terms of data efficiency and final performance.\n",
        "\n",
        "![rainbow](https://user-images.githubusercontent.com/14961526/60591412-61748100-9dd9-11e9-84fb-076c7a61fbab.png)\n",
        "\n",
        "However, the integration is not so simple because some of components are not independent each other, so we will look into a number of points that people especailly feel confused.\n",
        "\n",
        "1. Noisy Network <-> Dueling Network\n",
        "2. Dueling Network <-> Categorical DQN\n",
        "3. Categorical DQN <-> Double DQN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w87zNSaG-A_q",
        "outputId": "24a6b572-0a52-477f-e7d1-040c6840c1b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-04-21 22:12:06--  https://raw.githubusercontent.com/curt-park/rainbow-is-all-you-need/master/segment_tree.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4283 (4.2K) [text/plain]\n",
            "Saving to: ‘segment_tree.py.1’\n",
            "\n",
            "\rsegment_tree.py.1     0%[                    ]       0  --.-KB/s               \rsegment_tree.py.1   100%[===================>]   4.18K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-04-21 22:12:06 (38.6 MB/s) - ‘segment_tree.py.1’ saved [4283/4283]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import os\n",
        "import random\n",
        "from collections import deque\n",
        "from typing import Deque, Dict, List, Tuple\n",
        "\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from IPython.display import clear_output\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "# download segment tree module\n",
        "if IN_COLAB:\n",
        "    !wget https://raw.githubusercontent.com/curt-park/rainbow-is-all-you-need/master/segment_tree.py\n",
        "\n",
        "from segment_tree import MinSegmentTree, SumSegmentTree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcqBuH4y-A_q"
      },
      "source": [
        "## Replay buffer\n",
        "\n",
        "Same as the basic N-step buffer.\n",
        "\n",
        "(Please see *01.dqn.ipynb*, *07.n_step_learning.ipynb* for detailed description about the basic (n-step) replay buffer.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxwY9dIa-A_q",
        "outputId": "949a3b6a-6158-4e46-fd94-5bc5801fad41"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "class ReplayBuffer:\n",
        "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        obs_dim: int,\n",
        "        size: int,\n",
        "        batch_size: int = 32,\n",
        "        n_step: int = 1,\n",
        "        gamma: float = 0.99\n",
        "    ):\n",
        "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
        "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
        "        self.acts_buf = np.zeros([size], dtype=np.float32)\n",
        "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
        "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
        "        self.max_size, self.batch_size = size, batch_size\n",
        "        self.ptr, self.size, = 0, 0\n",
        "\n",
        "        # for N-step Learning\n",
        "        self.n_step_buffer = deque(maxlen=n_step)\n",
        "        self.n_step = n_step\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def store(\n",
        "        self,\n",
        "        obs: np.ndarray,\n",
        "        act: np.ndarray,\n",
        "        rew: float,\n",
        "        next_obs: np.ndarray,\n",
        "        done: bool,\n",
        "    ) -> Tuple[np.ndarray, np.ndarray, float, np.ndarray, bool]:\n",
        "        transition = (obs, act, rew, next_obs, done)\n",
        "        self.n_step_buffer.append(transition)\n",
        "\n",
        "        # single step transition is not ready\n",
        "        if len(self.n_step_buffer) < self.n_step:\n",
        "            return ()\n",
        "\n",
        "        # make a n-step transition\n",
        "        rew, next_obs, done = self._get_n_step_info(\n",
        "            self.n_step_buffer, self.gamma\n",
        "        )\n",
        "        obs, act = self.n_step_buffer[0][:2]\n",
        "\n",
        "        self.obs_buf[self.ptr] = obs\n",
        "        self.next_obs_buf[self.ptr] = next_obs\n",
        "        self.acts_buf[self.ptr] = act\n",
        "        self.rews_buf[self.ptr] = rew\n",
        "        self.done_buf[self.ptr] = done\n",
        "        self.ptr = (self.ptr + 1) % self.max_size\n",
        "        self.size = min(self.size + 1, self.max_size)\n",
        "\n",
        "        return self.n_step_buffer[0]\n",
        "\n",
        "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
        "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
        "\n",
        "        return dict(\n",
        "            obs=self.obs_buf[idxs],\n",
        "            next_obs=self.next_obs_buf[idxs],\n",
        "            acts=self.acts_buf[idxs],\n",
        "            rews=self.rews_buf[idxs],\n",
        "            done=self.done_buf[idxs],\n",
        "            # for N-step Learning\n",
        "            indices=idxs,\n",
        "        )\n",
        "\n",
        "    def sample_batch_from_idxs(\n",
        "        self, idxs: np.ndarray\n",
        "    ) -> Dict[str, np.ndarray]:\n",
        "        # for N-step Learning\n",
        "        return dict(\n",
        "            obs=self.obs_buf[idxs],\n",
        "            next_obs=self.next_obs_buf[idxs],\n",
        "            acts=self.acts_buf[idxs],\n",
        "            rews=self.rews_buf[idxs],\n",
        "            done=self.done_buf[idxs],\n",
        "        )\n",
        "\n",
        "    def _get_n_step_info(\n",
        "        self, n_step_buffer: Deque, gamma: float\n",
        "    ) -> Tuple[np.int64, np.ndarray, bool]:\n",
        "        \"\"\"Return n step rew, next_obs, and done.\"\"\"\n",
        "        # info of the last transition\n",
        "        rew, next_obs, done = n_step_buffer[-1][-3:]\n",
        "\n",
        "        for transition in reversed(list(n_step_buffer)[:-1]):\n",
        "            r, n_o, d = transition[-3:]\n",
        "\n",
        "            rew = r + gamma * rew * (1 - d)\n",
        "            next_obs, done = (n_o, d) if d else (next_obs, done)\n",
        "\n",
        "        return rew, next_obs, done\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzOgjQZ5-A_r"
      },
      "source": [
        "## Prioritized replay Buffer\n",
        "\n",
        "`store` method returns boolean in order to inform if a N-step transition has been generated.\n",
        "\n",
        "(Please see *02.per.ipynb* for detailed description about PER.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msBSsjJE-A_r"
      },
      "outputs": [],
      "source": [
        "class PrioritizedReplayBuffer(ReplayBuffer):\n",
        "    \"\"\"Prioritized Replay buffer.\n",
        "\n",
        "    Attributes:\n",
        "        max_priority (float): max priority\n",
        "        tree_ptr (int): next index of tree\n",
        "        alpha (float): alpha parameter for prioritized replay buffer\n",
        "        sum_tree (SumSegmentTree): sum tree for prior\n",
        "        min_tree (MinSegmentTree): min tree for min prior to get max weight\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        obs_dim: int,\n",
        "        size: int,\n",
        "        batch_size: int = 32,\n",
        "        alpha: float = 0.6,\n",
        "        n_step: int = 1,\n",
        "        gamma: float = 0.99,\n",
        "    ):\n",
        "        \"\"\"Initialization.\"\"\"\n",
        "        assert alpha >= 0\n",
        "\n",
        "        super(PrioritizedReplayBuffer, self).__init__(\n",
        "            obs_dim, size, batch_size, n_step, gamma\n",
        "        )\n",
        "        self.max_priority, self.tree_ptr = 1.0, 0\n",
        "        self.alpha = alpha\n",
        "\n",
        "        # capacity must be positive and a power of 2.\n",
        "        tree_capacity = 1\n",
        "        while tree_capacity < self.max_size:\n",
        "            tree_capacity *= 2\n",
        "\n",
        "        self.sum_tree = SumSegmentTree(tree_capacity)\n",
        "        self.min_tree = MinSegmentTree(tree_capacity)\n",
        "\n",
        "    def store(\n",
        "        self,\n",
        "        obs: np.ndarray,\n",
        "        act: int,\n",
        "        rew: float,\n",
        "        next_obs: np.ndarray,\n",
        "        done: bool,\n",
        "    ) -> Tuple[np.ndarray, np.ndarray, float, np.ndarray, bool]:\n",
        "        \"\"\"Store experience and priority.\"\"\"\n",
        "        transition = super().store(obs, act, rew, next_obs, done)\n",
        "\n",
        "        if transition:\n",
        "            self.sum_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
        "            self.min_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
        "            self.tree_ptr = (self.tree_ptr + 1) % self.max_size\n",
        "\n",
        "        return transition\n",
        "\n",
        "    def sample_batch(self, beta: float = 0.4) -> Dict[str, np.ndarray]:\n",
        "        \"\"\"Sample a batch of experiences.\"\"\"\n",
        "        assert len(self) >= self.batch_size\n",
        "        assert beta > 0\n",
        "\n",
        "        indices = self._sample_proportional()\n",
        "\n",
        "        obs = self.obs_buf[indices]\n",
        "        next_obs = self.next_obs_buf[indices]\n",
        "        acts = self.acts_buf[indices]\n",
        "        rews = self.rews_buf[indices]\n",
        "        done = self.done_buf[indices]\n",
        "        weights = np.array([self._calculate_weight(i, beta) for i in indices])\n",
        "\n",
        "        return dict(\n",
        "            obs=obs,\n",
        "            next_obs=next_obs,\n",
        "            acts=acts,\n",
        "            rews=rews,\n",
        "            done=done,\n",
        "            weights=weights,\n",
        "            indices=indices,\n",
        "        )\n",
        "\n",
        "    def update_priorities(self, indices: List[int], priorities: np.ndarray):\n",
        "        \"\"\"Update priorities of sampled transitions.\"\"\"\n",
        "        assert len(indices) == len(priorities)\n",
        "\n",
        "        for idx, priority in zip(indices, priorities):\n",
        "            assert priority > 0\n",
        "            assert 0 <= idx < len(self)\n",
        "\n",
        "            self.sum_tree[idx] = priority ** self.alpha\n",
        "            self.min_tree[idx] = priority ** self.alpha\n",
        "\n",
        "            self.max_priority = max(self.max_priority, priority)\n",
        "\n",
        "    def _sample_proportional(self) -> List[int]:\n",
        "        \"\"\"Sample indices based on proportions.\"\"\"\n",
        "        indices = []\n",
        "        p_total = self.sum_tree.sum(0, len(self) - 1)\n",
        "        segment = p_total / self.batch_size\n",
        "\n",
        "        for i in range(self.batch_size):\n",
        "            a = segment * i\n",
        "            b = segment * (i + 1)\n",
        "            upperbound = random.uniform(a, b)\n",
        "            idx = self.sum_tree.retrieve(upperbound)\n",
        "            indices.append(idx)\n",
        "\n",
        "        return indices\n",
        "\n",
        "    def _calculate_weight(self, idx: int, beta: float):\n",
        "        \"\"\"Calculate the weight of the experience at idx.\"\"\"\n",
        "        # get max weight\n",
        "        p_min = self.min_tree.min() / self.sum_tree.sum()\n",
        "        max_weight = (p_min * len(self)) ** (-beta)\n",
        "\n",
        "        # calculate weights\n",
        "        p_sample = self.sum_tree[idx] / self.sum_tree.sum()\n",
        "        weight = (p_sample * len(self)) ** (-beta)\n",
        "        weight = weight / max_weight\n",
        "\n",
        "        return weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osrsHcBR-A_s"
      },
      "source": [
        "## Noisy Layer\n",
        "\n",
        "Please see *05.noisy_net.ipynb* for detailed description.\n",
        "\n",
        "**References:**\n",
        "\n",
        "- https://github.com/higgsfield/RL-Adventure/blob/master/5.noisy%20dqn.ipynb\n",
        "- https://github.com/Kaixhin/Rainbow/blob/master/model.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4yuMvf2-A_s"
      },
      "outputs": [],
      "source": [
        "class NoisyLinear(nn.Module):\n",
        "    \"\"\"Noisy linear module for NoisyNet.\n",
        "\n",
        "\n",
        "\n",
        "    Attributes:\n",
        "        in_features (int): input size of linear module\n",
        "        out_features (int): output size of linear module\n",
        "        std_init (float): initial std value\n",
        "        weight_mu (nn.Parameter): mean value weight parameter\n",
        "        weight_sigma (nn.Parameter): std value weight parameter\n",
        "        bias_mu (nn.Parameter): mean value bias parameter\n",
        "        bias_sigma (nn.Parameter): std value bias parameter\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features: int,\n",
        "        out_features: int,\n",
        "        std_init: float = 0.5,\n",
        "    ):\n",
        "        \"\"\"Initialization.\"\"\"\n",
        "        super(NoisyLinear, self).__init__()\n",
        "\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.std_init = std_init\n",
        "\n",
        "        self.weight_mu = nn.Parameter(torch.Tensor(out_features, in_features))\n",
        "        self.weight_sigma = nn.Parameter(\n",
        "            torch.Tensor(out_features, in_features)\n",
        "        )\n",
        "        self.register_buffer(\n",
        "            \"weight_epsilon\", torch.Tensor(out_features, in_features)\n",
        "        )\n",
        "\n",
        "        self.bias_mu = nn.Parameter(torch.Tensor(out_features))\n",
        "        self.bias_sigma = nn.Parameter(torch.Tensor(out_features))\n",
        "        self.register_buffer(\"bias_epsilon\", torch.Tensor(out_features))\n",
        "\n",
        "        self.reset_parameters()\n",
        "        self.reset_noise()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        \"\"\"Reset trainable network parameters (factorized gaussian noise).\"\"\"\n",
        "        mu_range = 1 / math.sqrt(self.in_features)\n",
        "        self.weight_mu.data.uniform_(-mu_range, mu_range)\n",
        "        self.weight_sigma.data.fill_(\n",
        "            self.std_init / math.sqrt(self.in_features)\n",
        "        )\n",
        "        self.bias_mu.data.uniform_(-mu_range, mu_range)\n",
        "        self.bias_sigma.data.fill_(\n",
        "            self.std_init / math.sqrt(self.out_features)\n",
        "        )\n",
        "\n",
        "    def reset_noise(self):\n",
        "        \"\"\"Make new noise.\"\"\"\n",
        "        epsilon_in = self.scale_noise(self.in_features)\n",
        "        epsilon_out = self.scale_noise(self.out_features)\n",
        "\n",
        "        # outer product\n",
        "        self.weight_epsilon.copy_(epsilon_out.ger(epsilon_in))\n",
        "        self.bias_epsilon.copy_(epsilon_out)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward method implementation.\n",
        "\n",
        "        We don't use separate statements on train / eval mode.\n",
        "        It doesn't show remarkable difference of performance.\n",
        "        \"\"\"\n",
        "        return F.linear(\n",
        "            x,\n",
        "            self.weight_mu + self.weight_sigma * self.weight_epsilon,\n",
        "            self.bias_mu + self.bias_sigma * self.bias_epsilon,\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def scale_noise(size: int) -> torch.Tensor:\n",
        "        \"\"\"Set scale to make noise (factorized gaussian noise).\"\"\"\n",
        "        x = torch.randn(size)\n",
        "\n",
        "        return x.sign().mul(x.abs().sqrt())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HqN9gaW-A_s"
      },
      "source": [
        "## NoisyNet + DuelingNet + Categorical DQN\n",
        "\n",
        "#### NoisyNet + DuelingNet\n",
        "\n",
        "NoisyLinear is employed for the last two layers of advantage and value layers. The noise should be reset at evey update step.\n",
        "\n",
        "#### DuelingNet + Categorical DQN\n",
        "\n",
        "The dueling network architecture is adapted for use with return distributions. The network has a shared representation, which is then fed into a value stream with atom_size outputs, and into an advantage stream with atom_size × out_dim outputs. For each atom, the value and advantage streams are aggregated, as in dueling DQN, and then passed through a softmax layer to obtain the normalized parametric distributions used to estimate the returns’ distributions.\n",
        "\n",
        "```\n",
        "        advantage = self.advantage_layer(adv_hid).view(-1, self.out_dim, self.atom_size)\n",
        "        value = self.value_layer(val_hid).view(-1, 1, self.atom_size)\n",
        "        q_atoms = value + advantage - advantage.mean(dim=1, keepdim=True)\n",
        "        \n",
        "        dist = F.softmax(q_atoms, dim=-1)\n",
        "```\n",
        "\n",
        "(Please see *04.dueling.ipynb*, *05.noisy_net.ipynb*, *06.categorical_dqn.ipynb* for detailed description of each component's network architecture.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2sm2vmk-A_t"
      },
      "outputs": [],
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_dim: int,\n",
        "        out_dim: int,\n",
        "        atom_size: int,\n",
        "        support: torch.Tensor\n",
        "    ):\n",
        "        \"\"\"Initialization.\"\"\"\n",
        "        super(Network, self).__init__()\n",
        "\n",
        "        self.support = support\n",
        "        self.out_dim = out_dim\n",
        "        self.atom_size = atom_size\n",
        "\n",
        "        print(f'Network Settings:')\n",
        "        print(f'In Dim  : {in_dim}')\n",
        "        print(f'Out Dim : {out_dim}')\n",
        "\n",
        "        # set common feature layer\n",
        "        self.feature_layer = nn.Sequential(\n",
        "            nn.Linear(in_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        # set advantage layer\n",
        "        self.advantage_hidden_layer = NoisyLinear(512, 512)\n",
        "        self.advantage_layer = NoisyLinear(512, out_dim * atom_size)\n",
        "\n",
        "        # set value layer\n",
        "        self.value_hidden_layer = NoisyLinear(512, 512)\n",
        "        self.value_layer = NoisyLinear(512, atom_size)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward method implementation.\"\"\"\n",
        "        dist = self.dist(x)\n",
        "        q = torch.sum(dist * self.support, dim=2)\n",
        "\n",
        "        return q\n",
        "\n",
        "    def dist(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Get distribution for atoms.\"\"\"\n",
        "        feature = self.feature_layer(x)\n",
        "        adv_hid = F.relu(self.advantage_hidden_layer(feature))\n",
        "        val_hid = F.relu(self.value_hidden_layer(feature))\n",
        "\n",
        "        advantage = self.advantage_layer(adv_hid).view(\n",
        "            -1, self.out_dim, self.atom_size\n",
        "        )\n",
        "        value = self.value_layer(val_hid).view(-1, 1, self.atom_size)\n",
        "        q_atoms = value + advantage - advantage.mean(dim=1, keepdim=True)\n",
        "\n",
        "        dist = F.softmax(q_atoms, dim=-1)\n",
        "        dist = dist.clamp(min=1e-3)  # for avoiding nans\n",
        "\n",
        "        return dist\n",
        "\n",
        "    def reset_noise(self):\n",
        "        \"\"\"Reset all noisy layers.\"\"\"\n",
        "        self.advantage_hidden_layer.reset_noise()\n",
        "        self.advantage_layer.reset_noise()\n",
        "        self.value_hidden_layer.reset_noise()\n",
        "        self.value_layer.reset_noise()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXOojgy4-A_t"
      },
      "source": [
        "## Rainbow Agent\n",
        "\n",
        "Here is a summary of DQNAgent class.\n",
        "\n",
        "| Method           | Note                                                 |\n",
        "| ---              | ---                                                  |\n",
        "|select_action     | select an action from the input state.               |\n",
        "|step              | take an action and return the response of the env.   |\n",
        "|compute_dqn_loss  | return dqn loss.                                     |\n",
        "|update_model      | update the model by gradient descent.                |\n",
        "|target_hard_update| hard update from the local model to the target model.|\n",
        "|train             | train the agent during num_frames.                   |\n",
        "|test              | test the agent (1 episode).                          |\n",
        "|plot              | plot the training progresses.                        |\n",
        "\n",
        "#### Categorical DQN + Double DQN\n",
        "\n",
        "The idea of Double Q-learning is to reduce overestimations by decomposing the max operation in the target into action selection and action evaluation. Here, we use `self.dqn` instead of `self.dqn_target` to obtain the target actions.\n",
        "\n",
        "```\n",
        "        # Categorical DQN + Double DQN\n",
        "        # target_dqn is used when we don't employ double DQN\n",
        "        next_action = self.dqn(next_state).argmax(1)\n",
        "        next_dist = self.dqn_target.dist(next_state)\n",
        "        next_dist = next_dist[range(self.batch_size), next_action]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPvWXRSP-A_t"
      },
      "outputs": [],
      "source": [
        "class DQNAgent:\n",
        "    \"\"\"DQN Agent interacting with environment.\n",
        "\n",
        "    Attribute:\n",
        "        env (gym.Env): openAI Gym environment\n",
        "        memory (PrioritizedReplayBuffer): replay memory to store transitions\n",
        "        batch_size (int): batch size for sampling\n",
        "        target_update (int): period for target model's hard update\n",
        "        gamma (float): discount factor\n",
        "        dqn (Network): model to train and select actions\n",
        "        dqn_target (Network): target model to update\n",
        "        optimizer (torch.optim): optimizer for training dqn\n",
        "        transition (list): transition information including\n",
        "                           state, action, reward, next_state, done\n",
        "        v_min (float): min value of support\n",
        "        v_max (float): max value of support\n",
        "        atom_size (int): the unit number of support\n",
        "        support (torch.Tensor): support for categorical dqn\n",
        "        use_n_step (bool): whether to use n_step memory\n",
        "        n_step (int): step number to calculate n-step td error\n",
        "        memory_n (ReplayBuffer): n-step replay buffer\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        env: gym.Env,\n",
        "        memory_size: int,\n",
        "        batch_size: int,\n",
        "        target_update: int,\n",
        "        seed: int,\n",
        "        gamma: float = 0.99,\n",
        "        # PER parameters\n",
        "        alpha: float = 0.2,\n",
        "        beta: float = 0.6,\n",
        "        prior_eps: float = 1e-6,\n",
        "        # Categorical DQN parameters\n",
        "        v_min: float = 0.0,\n",
        "        v_max: float = 200.0,\n",
        "        atom_size: int = 51,\n",
        "        # N-step Learning\n",
        "        n_step: int = 3,\n",
        "    ):\n",
        "        \"\"\"Initialization.\n",
        "\n",
        "        Args:\n",
        "            env (gym.Env): openAI Gym environment\n",
        "            memory_size (int): length of memory\n",
        "            batch_size (int): batch size for sampling\n",
        "            target_update (int): period for target model's hard update\n",
        "            lr (float): learning rate\n",
        "            gamma (float): discount factor\n",
        "            alpha (float): determines how much prioritization is used\n",
        "            beta (float): determines how much importance sampling is used\n",
        "            prior_eps (float): guarantees every transition can be sampled\n",
        "            v_min (float): min value of support\n",
        "            v_max (float): max value of support\n",
        "            atom_size (int): the unit number of support\n",
        "            n_step (int): step number to calculate n-step td error\n",
        "        \"\"\"\n",
        "        obs_dim = env.observation_space.shape[0]\n",
        "        action_dim = env.action_space.n\n",
        "\n",
        "        self.env = env\n",
        "        self.batch_size = batch_size\n",
        "        self.target_update = target_update\n",
        "        self.seed = seed\n",
        "        self.gamma = gamma\n",
        "        # NoisyNet: All attributes related to epsilon are removed\n",
        "\n",
        "        # device: cpu / gpu\n",
        "        self.device = torch.device(\n",
        "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        )\n",
        "        print(self.device)\n",
        "\n",
        "        # PER\n",
        "        # memory for 1-step Learning\n",
        "        self.beta = beta\n",
        "        self.prior_eps = prior_eps\n",
        "        self.memory = PrioritizedReplayBuffer(\n",
        "            obs_dim, memory_size, batch_size, alpha=alpha, gamma=gamma\n",
        "        )\n",
        "\n",
        "        # memory for N-step Learning\n",
        "        self.use_n_step = True if n_step > 1 else False\n",
        "        if self.use_n_step:\n",
        "            self.n_step = n_step\n",
        "            self.memory_n = ReplayBuffer(\n",
        "                obs_dim, memory_size, batch_size, n_step=n_step, gamma=gamma\n",
        "            )\n",
        "\n",
        "        # Categorical DQN parameters\n",
        "        self.v_min = v_min\n",
        "        self.v_max = v_max\n",
        "        self.atom_size = atom_size\n",
        "        self.support = torch.linspace(\n",
        "            self.v_min, self.v_max, self.atom_size\n",
        "        ).to(self.device)\n",
        "\n",
        "        # networks: dqn, dqn_target\n",
        "        self.dqn = Network(\n",
        "            obs_dim, action_dim, self.atom_size, self.support\n",
        "        ).to(self.device)\n",
        "        self.dqn_target = Network(\n",
        "            obs_dim, action_dim, self.atom_size, self.support\n",
        "        ).to(self.device)\n",
        "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
        "        self.dqn_target.eval()\n",
        "\n",
        "        # optimizer\n",
        "        self.optimizer = optim.Adam(self.dqn.parameters())\n",
        "\n",
        "        # transition to store in memory\n",
        "        self.transition = list()\n",
        "\n",
        "        # mode: train / test\n",
        "        self.is_test = False\n",
        "\n",
        "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Select an action from the input state.\"\"\"\n",
        "        # NoisyNet: no epsilon greedy action selection\n",
        "        selected_action = self.dqn(\n",
        "            torch.FloatTensor(state).to(self.device)\n",
        "        ).argmax()\n",
        "        selected_action = selected_action.detach().cpu().numpy()\n",
        "\n",
        "        if not self.is_test:\n",
        "            self.transition = [state, selected_action]\n",
        "\n",
        "        return selected_action\n",
        "\n",
        "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
        "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
        "        next_state, reward, done = self.env.step(action)\n",
        "\n",
        "        if not self.is_test:\n",
        "            self.transition += [reward, next_state, done]\n",
        "\n",
        "            # N-step transition\n",
        "            if self.use_n_step:\n",
        "                one_step_transition = self.memory_n.store(*self.transition)\n",
        "            # 1-step transition\n",
        "            else:\n",
        "                one_step_transition = self.transition\n",
        "\n",
        "            # add a single step transition\n",
        "            if one_step_transition:\n",
        "                self.memory.store(*one_step_transition)\n",
        "\n",
        "        return next_state, reward, done\n",
        "\n",
        "    def update_model(self) -> torch.Tensor:\n",
        "        \"\"\"Update the model by gradient descent.\"\"\"\n",
        "        # PER needs beta to calculate weights\n",
        "        samples = self.memory.sample_batch(self.beta)\n",
        "        weights = torch.FloatTensor(\n",
        "            samples[\"weights\"].reshape(-1, 1)\n",
        "        ).to(self.device)\n",
        "        indices = samples[\"indices\"]\n",
        "\n",
        "        # 1-step Learning loss\n",
        "        elementwise_loss = self._compute_dqn_loss(samples, self.gamma)\n",
        "\n",
        "        # PER: importance sampling before average\n",
        "        loss = torch.mean(elementwise_loss * weights)\n",
        "\n",
        "        # N-step Learning loss\n",
        "        # we are gonna combine 1-step loss and n-step loss so as to\n",
        "        # prevent high-variance. The original rainbow employs n-step loss only.\n",
        "        if self.use_n_step:\n",
        "            gamma = self.gamma ** self.n_step\n",
        "            samples = self.memory_n.sample_batch_from_idxs(indices)\n",
        "            elementwise_loss_n_loss = self._compute_dqn_loss(samples, gamma)\n",
        "            elementwise_loss += elementwise_loss_n_loss\n",
        "\n",
        "            # PER: importance sampling before average\n",
        "            loss = torch.mean(elementwise_loss * weights)\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        clip_grad_norm_(self.dqn.parameters(), 10.0)\n",
        "        self.optimizer.step()\n",
        "\n",
        "        # PER: update priorities\n",
        "        loss_for_prior = elementwise_loss.detach().cpu().numpy()\n",
        "        new_priorities = loss_for_prior + self.prior_eps\n",
        "        self.memory.update_priorities(indices, new_priorities)\n",
        "\n",
        "        # NoisyNet: reset noise\n",
        "        self.dqn.reset_noise()\n",
        "        self.dqn_target.reset_noise()\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "    def train(self, num_frames: int, plotting_interval: int = 200):\n",
        "        \"\"\"Train the agent.\"\"\"\n",
        "        self.is_test = False\n",
        "\n",
        "        state, _ = self.env.reset(seed=self.seed)\n",
        "        update_cnt = 0\n",
        "        losses = []\n",
        "        scores = []\n",
        "        score = 0\n",
        "\n",
        "        for frame_idx in range(1, num_frames + 1):\n",
        "            action = self.select_action(state)\n",
        "            next_state, reward, done = self.step(action)\n",
        "\n",
        "            state = next_state\n",
        "            score += reward\n",
        "\n",
        "            # NoisyNet: removed decrease of epsilon\n",
        "\n",
        "            # PER: increase beta\n",
        "            fraction = min(frame_idx / num_frames, 1.0)\n",
        "            self.beta = self.beta + fraction * (1.0 - self.beta)\n",
        "\n",
        "            # if episode ends\n",
        "            if done:\n",
        "                state, _ = self.env.reset(seed=self.seed)\n",
        "                scores.append(score)\n",
        "                print(f'Finished Episode | Score: {score}')\n",
        "                score = 0\n",
        "\n",
        "            # if training is ready\n",
        "            if len(self.memory) >= self.batch_size:\n",
        "                loss = self.update_model()\n",
        "                losses.append(loss)\n",
        "                update_cnt += 1\n",
        "\n",
        "                # if hard update is needed\n",
        "                if update_cnt % self.target_update == 0:\n",
        "                    self._target_hard_update()\n",
        "\n",
        "            # plotting\n",
        "            if frame_idx % plotting_interval == 0:\n",
        "                self._plot(frame_idx, scores, losses)\n",
        "\n",
        "        self.env.close()\n",
        "\n",
        "    def test(self, video_folder: str) -> None:\n",
        "        \"\"\"Test the agent.\"\"\"\n",
        "        self.is_test = True\n",
        "\n",
        "        # for recording a video\n",
        "        naive_env = self.env\n",
        "        self.env = gym.wrappers.RecordVideo(self.env, video_folder=video_folder)\n",
        "\n",
        "        state, _ = self.env.reset(seed=self.seed)\n",
        "        done = False\n",
        "        score = 0\n",
        "\n",
        "        while not done:\n",
        "            action = self.select_action(state)\n",
        "            next_state, reward, done = self.step(action)\n",
        "\n",
        "            state = next_state\n",
        "            score += reward\n",
        "\n",
        "        print(\"score: \", score)\n",
        "        self.env.close()\n",
        "\n",
        "        # reset\n",
        "        self.env = naive_env\n",
        "\n",
        "    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray], gamma: float) -> torch.Tensor:\n",
        "        \"\"\"Return categorical dqn loss.\"\"\"\n",
        "        device = self.device  # for shortening the following lines\n",
        "        state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
        "        next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
        "        action = torch.LongTensor(samples[\"acts\"]).to(device)\n",
        "        reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
        "        done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
        "\n",
        "        # Categorical DQN algorithm\n",
        "        delta_z = float(self.v_max - self.v_min) / (self.atom_size - 1)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Double DQN\n",
        "            next_action = self.dqn(next_state).argmax(1)\n",
        "            next_dist = self.dqn_target.dist(next_state)\n",
        "            next_dist = next_dist[range(self.batch_size), next_action]\n",
        "\n",
        "            t_z = reward + (1 - done) * gamma * self.support\n",
        "            t_z = t_z.clamp(min=self.v_min, max=self.v_max)\n",
        "            b = (t_z - self.v_min) / delta_z\n",
        "            l = b.floor().long()\n",
        "            u = b.ceil().long()\n",
        "\n",
        "            offset = (\n",
        "                torch.linspace(\n",
        "                    0, (self.batch_size - 1) * self.atom_size, self.batch_size\n",
        "                ).long()\n",
        "                .unsqueeze(1)\n",
        "                .expand(self.batch_size, self.atom_size)\n",
        "                .to(self.device)\n",
        "            )\n",
        "\n",
        "            proj_dist = torch.zeros(next_dist.size(), device=self.device)\n",
        "            proj_dist.view(-1).index_add_(\n",
        "                0, (l + offset).view(-1), (next_dist * (u.float() - b)).view(-1)\n",
        "            )\n",
        "            proj_dist.view(-1).index_add_(\n",
        "                0, (u + offset).view(-1), (next_dist * (b - l.float())).view(-1)\n",
        "            )\n",
        "\n",
        "        dist = self.dqn.dist(state)\n",
        "        log_p = torch.log(dist[range(self.batch_size), action])\n",
        "        elementwise_loss = -(proj_dist * log_p).sum(1)\n",
        "\n",
        "        return elementwise_loss\n",
        "\n",
        "    def _target_hard_update(self):\n",
        "        \"\"\"Hard update: target <- local.\"\"\"\n",
        "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
        "\n",
        "    def _plot(\n",
        "        self,\n",
        "        frame_idx: int,\n",
        "        scores: List[float],\n",
        "        losses: List[float],\n",
        "    ):\n",
        "        \"\"\"Plot the training progresses.\"\"\"\n",
        "        clear_output(True)\n",
        "        plt.figure(figsize=(20, 5))\n",
        "        plt.subplot(131)\n",
        "        plt.title('frame %s. score: %s' % (frame_idx, np.mean(scores[-10:])))\n",
        "        plt.plot(scores)\n",
        "        plt.subplot(132)\n",
        "        plt.title('loss')\n",
        "        plt.plot(losses)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pNcvmOI-A_u"
      },
      "source": [
        "## Environment\n",
        "\n",
        "You can see the [code](https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/envs/classic_control/cartpole.py) and [configurations](https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/envs/classic_control/cartpole.py#L91) of CartPole-v1 from Farama Gymnasium's repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kETzOC7-_ChJ"
      },
      "outputs": [],
      "source": [
        "# 0: normal tile\n",
        "# 1: orange tile\n",
        "# 2: soft switch\n",
        "# 3: hard switch\n",
        "# 4: goal\n",
        "# 5: transport switch\n",
        "# 8: block\n",
        "# 9: none\n",
        "\n",
        "# Level 1:\n",
        "level_one_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 4, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Level 2:\n",
        "level_two_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 3, 0, 9, 9, 0, 4, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 2, 0, 9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "level_two_soft_switches = np.array(\n",
        "    [{\"switch_location\": (4, 4), \"toggle_tiles\": [(6, 6), (6, 7)], \"mode\": \"toggle\"}]\n",
        ")\n",
        "\n",
        "\n",
        "level_two_hard_switches = np.array(\n",
        "    [{\"switch_location\": (3, 10), \"toggle_tiles\": [(6, 12), (6, 13)]}]\n",
        ")\n",
        "\n",
        "# Level 3:\n",
        "level_three_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 9, 9, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 4, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Level 4:\n",
        "level_four_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 1, 1, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 1, 1, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 0, 0, 0, 0, 1, 1, 1, 1, 1, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 0, 0, 0, 0, 1, 1, 1, 1, 1, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 4, 0, 9, 9, 1, 1, 0, 1, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 1, 1, 1, 1, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Level 5:\n",
        "level_five_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 2, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 2, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "level_five_soft_switches = np.array(\n",
        "    [\n",
        "        {\n",
        "            \"switch_location\": (2, 10),\n",
        "            \"toggle_tiles\": [(2, 7), (2, 8)],\n",
        "            \"mode\": \"toggle\",\n",
        "        },\n",
        "        {\n",
        "            \"switch_location\": (7, 16),\n",
        "            \"toggle_tiles\": [(9, 7), (9, 8)],\n",
        "            \"mode\": \"toggle\",\n",
        "        },\n",
        "        {\"switch_location\": (6, 8), \"toggle_tiles\": [(9, 7), (9, 8)], \"mode\": \"off\"},\n",
        "        {\"switch_location\": (4, 5), \"toggle_tiles\": [(9, 7), (9, 8)], \"mode\": \"on\"},\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Level 6:\n",
        "level_six_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 0, 0, 0, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 0, 0, 4, 0, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Level 7:\n",
        "level_seven_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 0, 9, 9, 0, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 0, 4, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 0, 0, 3, 9, 9, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 0, 0, 0, 9, 9, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "level_seven_hard_switches = np.array(\n",
        "    [{\"switch_location\": (5, 12), \"toggle_tiles\": [(7, 6)]}]\n",
        ")\n",
        "\n",
        "\n",
        "# Level 8:\n",
        "level_eight_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 5, 0, 9, 9, 9, 0, 0, 0, 0, 4, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "level_eight_teleport_switches = np.array(\n",
        "    [{\"switch_location\": (6, 7), \"split_positions\": [(3, 13), (9, 13)]}]\n",
        ")\n",
        "\n",
        "\n",
        "# Level 9:\n",
        "level_nine_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 0, 9, 9, 9, 0, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 0, 9, 9, 9, 0, 0, 5, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 4, 0, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "level_nine_teleport_switches = np.array(\n",
        "    [{\"switch_location\": (4, 16), \"split_positions\": [(4, 15), (4, 5)]}]\n",
        ")\n",
        "\n",
        "\n",
        "# Level 10:\n",
        "level_ten_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 4, 0, 9, 9, 0, 9, 9, 0, 0, 0, 0, 5, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 9, 9, 0, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 0, 2, 9, 9, 0, 0, 0, 3, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "level_ten_teleport_switches = np.array(\n",
        "    [{\"switch_location\": (2, 15), \"split_positions\": [(2, 15), (2, 12)]}]\n",
        ")\n",
        "\n",
        "level_ten_hard_switches = np.array(\n",
        "    [{\"switch_location\": (10, 14), \"toggle_tiles\": [(2, 9), (2, 10),(3, 15), (4, 15)]}]\n",
        ")\n",
        "\n",
        "level_ten_soft_switches = np.array(\n",
        "    [{\"switch_location\": (10, 8), \"toggle_tiles\": [(2, 6), (2, 7)], \"mode\":\"toggle\"}]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0vKFUuf-2us"
      },
      "outputs": [],
      "source": [
        "class Block:\n",
        "\n",
        "    def __init__(self, r1, c1, r2, c2):\n",
        "        self._r1 = r1\n",
        "        self._r2 = r2\n",
        "        self._c1 = c1\n",
        "        self._c2 = c2\n",
        "\n",
        "        self._focus_block = 0\n",
        "\n",
        "    def set_coords(self, r1, c1, r2, c2):\n",
        "        self._r1 = r1\n",
        "        self._r2 = r2\n",
        "        self._c1 = c1\n",
        "        self._c2 = c2\n",
        "\n",
        "    def get_coords(self):\n",
        "        return self._r1, self._c1, self._r2, self._c2\n",
        "\n",
        "    def is_upright(self):\n",
        "        return self._r1 == self._r2 and self._c1 == self._c2\n",
        "\n",
        "    def is_wide(self):\n",
        "        return self._r1 == self._r2 and self._c1 != self._c2\n",
        "\n",
        "    def move_up(self):\n",
        "        match self._focus_block:\n",
        "            case 0:\n",
        "                # vertical\n",
        "                if self.is_upright():\n",
        "                    self._r1 -= 1\n",
        "                    self._r2 -= 2\n",
        "\n",
        "                # flat and wide\n",
        "                elif self.is_wide():\n",
        "                    self._r1 -= 1\n",
        "                    self._r2 -= 1\n",
        "\n",
        "                # flat and long\n",
        "                else:\n",
        "                    min_r = min(self._r1, self._r2)\n",
        "                    self._r1 = min_r - 1\n",
        "                    self._r2 = min_r - 1\n",
        "\n",
        "            case 1:\n",
        "                self._r1 -= 1\n",
        "\n",
        "            case 2:\n",
        "                self._r2 -= 1\n",
        "\n",
        "    def move_down(self):\n",
        "        match self._focus_block:\n",
        "            case 0:\n",
        "                # vertical\n",
        "                if self.is_upright():\n",
        "                    self._r1 += 1\n",
        "                    self._r2 += 2\n",
        "\n",
        "                # flat and wide\n",
        "                elif self.is_wide():\n",
        "                    self._r1 += 1\n",
        "                    self._r2 += 1\n",
        "\n",
        "                # flat and long\n",
        "                else:\n",
        "                    max_r = max(self._r1, self._r2)\n",
        "                    self._r1 = max_r + 1\n",
        "                    self._r2 = max_r + 1\n",
        "\n",
        "            case 1:\n",
        "                self._r1 += 1\n",
        "            case 2:\n",
        "                self._r2 += 1\n",
        "\n",
        "    # edited\n",
        "    def move_right(self):\n",
        "        match self._focus_block:\n",
        "            case 0:\n",
        "                # vertical\n",
        "                if self.is_upright():\n",
        "                    self._c1 += 1\n",
        "                    self._c2 += 2\n",
        "\n",
        "                # flat and wide\n",
        "                elif self.is_wide():\n",
        "                    max_c = max(self._c1, self._c2)\n",
        "                    self._c1 = max_c + 1\n",
        "                    self._c2 = max_c + 1\n",
        "\n",
        "                # flat and long\n",
        "                else:\n",
        "                    self._c1 += 1\n",
        "                    self._c2 += 1\n",
        "\n",
        "            case 1:\n",
        "                self._c1 += 1\n",
        "            case 2:\n",
        "                self._c2 += 1\n",
        "\n",
        "    # edited\n",
        "    def move_left(self):\n",
        "        match self._focus_block:\n",
        "            case 0:\n",
        "                # vertical\n",
        "                if self.is_upright():\n",
        "                    self._c1 -= 1\n",
        "                    self._c2 -= 2\n",
        "\n",
        "                # flat and wide\n",
        "                elif self.is_wide():\n",
        "                    min_c = min(self._c1, self._c2)\n",
        "                    self._c1 = min_c - 1\n",
        "                    self._c2 = min_c - 1\n",
        "\n",
        "                # flat and long\n",
        "                else:\n",
        "                    self._c1 -= 1\n",
        "                    self._c2 -= 1\n",
        "            case 1:\n",
        "                self._c1 -= 1\n",
        "            case 2:\n",
        "                self._c2 -= 1\n",
        "\n",
        "    def toggle_focus(self):\n",
        "        if self._focus_block == 0:\n",
        "            self._focus_block = 0\n",
        "        elif self._focus_block == 1:\n",
        "            self._focus_block = 2\n",
        "        else:\n",
        "            self._focus_block = 1\n",
        "\n",
        "    def set_focus(self, focus):\n",
        "        self._focus_block = focus\n",
        "\n",
        "    def get_focus(self):\n",
        "        return self._focus_block\n",
        "\n",
        "    def join_single_blocks(self):\n",
        "        if self._focus_block == 1 or self._focus_block == 2:\n",
        "            if abs(self._r1 - self._r2) == 1 and (self._c1 == self._c2):\n",
        "                self.set_focus(0)\n",
        "            elif abs(self._c1 - self._c2) == 1 and (self._r1 == self._r2):\n",
        "                self.set_focus(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4ZxvTcZ-A_u"
      },
      "outputs": [],
      "source": [
        "class Level(gym.Env):\n",
        "    metadata = {\"render_modes\": [], \"render_fps\": 0}\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        start_pos: tuple,\n",
        "        base_env: np.array([]),\n",
        "        soft_switches=np.array([]),\n",
        "        hard_switches=np.array([]),\n",
        "        teleport_switches=np.array([]),\n",
        "        render_mode=None,\n",
        "    ):\n",
        "        self._r_start = start_pos[0]\n",
        "        self._c_start = start_pos[1]\n",
        "\n",
        "        self._block = Block(self._r_start, self._c_start, self._r_start, self._c_start)\n",
        "\n",
        "        self._base_env = base_env\n",
        "\n",
        "        self._soft_switches = soft_switches\n",
        "        self._hard_switches = hard_switches\n",
        "        self._teleport_switches = teleport_switches\n",
        "\n",
        "        self._actions = {\n",
        "            0: self._block.move_right,\n",
        "            1: self._block.move_up,\n",
        "            2: self._block.move_left,\n",
        "            3: self._block.move_down,\n",
        "            4: self._block.toggle_focus,\n",
        "        }\n",
        "\n",
        "        self.observation_space = np.append(base_env.ravel(), 0)\n",
        "        self.action_space = gym.spaces.Discrete(5)\n",
        "\n",
        "    def step(self, action):\n",
        "        # if the block is split, check if single blocks are adjacent, and join together\n",
        "        self._block.join_single_blocks()\n",
        "\n",
        "        # update the agent's coords by passing it the action\n",
        "        self._perform_action(action)\n",
        "\n",
        "        # check if the agent is out of bounds -> reset to the start\n",
        "        r1, c1, r2, c2 = self._block.get_coords()\n",
        "\n",
        "        reward, done = self._is_done(r1, c1, r2, c2)\n",
        "\n",
        "        # only check for environment changes if the action is not \"Switch Focus\"\n",
        "        if action != 4:\n",
        "            self._move_to_start(r1, c1, r2, c2)\n",
        "            self._activate_teleport_switch(r1, c1, r2, c2)\n",
        "            self._toggle_soft_switches(r1, c1, r2, c2)\n",
        "            self._toggle_hard_switches(r1, c1, r2, c2)\n",
        "\n",
        "\n",
        "\n",
        "        state = self._format_environment()\n",
        "\n",
        "        return state, reward, done\n",
        "\n",
        "    def reset(self, seed):\n",
        "        # set both of the agent's coords to (self._r_start,self._c_start) and (self._r_start,self._c_start)\n",
        "        self._block.set_coords(\n",
        "            self._r_start, self._c_start, self._r_start, self._c_start\n",
        "        )\n",
        "        self._block.set_focus(0)\n",
        "\n",
        "        # reset the environment (important to undo any obstacle interactions)\n",
        "        self._current_env = np.copy(self._base_env)\n",
        "\n",
        "        # place the agent in the environment using its position\n",
        "        state = np.copy(self._current_env)\n",
        "        state[self._r_start, self._c_start] = 8\n",
        "        state = state.ravel()\n",
        "        state = np.append(state, self._block.get_focus())\n",
        "        # state = np.array2string(state, separator=\"\") + str(self._block.get_focus())\n",
        "\n",
        "        return state, False\n",
        "\n",
        "    def _move_to_start(self, r1, c1, r2, c2):\n",
        "        if self._current_env[r1, c1] == 9 or self._current_env[r2, c2] == 9:\n",
        "            self.reset(42)\n",
        "\n",
        "    def _is_done(self, r1, c1, r2, c2):\n",
        "        # check if the agent is on the goal -> set done to True and reward to 0\n",
        "\n",
        "        # reward is -1 and done is False unless the agent hit the goal\n",
        "        reward = -1\n",
        "        done = False\n",
        "\n",
        "        if self._current_env[r1, c1] == 4 and self._current_env[r2, c2] == 4:\n",
        "            reward = 0\n",
        "            done = True\n",
        "        # elif self._current_env[r1, c1] == 9 or self._current_env[r2, c2] == 9:\n",
        "        #   reward = -1000\n",
        "        #   done = True\n",
        "\n",
        "        return reward, done\n",
        "\n",
        "    def _format_environment(self):\n",
        "        # place the agent in the environment using its position\n",
        "        r1, c1, r2, c2 = self._block.get_coords()\n",
        "        state = np.copy(self._current_env)\n",
        "        state[r1, c1] = 8\n",
        "        state[r2, c2] = 8\n",
        "\n",
        "        state = state.ravel()\n",
        "        state = np.append(state, self._block.get_focus())\n",
        "        # state = np.array2string(state, separator=\"\") + str(self._block.get_focus())\n",
        "\n",
        "        return state\n",
        "\n",
        "    def _toggle_soft_switches(self, r1, c1, r2, c2):\n",
        "        # check if the agent is on a circle switch -> activate bridge\n",
        "        for c in self._soft_switches:\n",
        "            switch_location = c[\"switch_location\"]\n",
        "            toggle_tiles = c[\"toggle_tiles\"]\n",
        "            mode = c[\"mode\"]\n",
        "\n",
        "            if (r1 == switch_location[0] and c1 == switch_location[1]) or (\n",
        "                r2 == switch_location[0] and c2 == switch_location[1]\n",
        "            ):\n",
        "                if mode == \"toggle\":\n",
        "                    if self._current_env[toggle_tiles[0][0], toggle_tiles[0][1]] == 0:\n",
        "                        for t in toggle_tiles:\n",
        "                            self._current_env[t[0], t[1]] = 9\n",
        "                            self._current_env[t[0], t[1]] = 9\n",
        "\n",
        "                    else:\n",
        "                        for t in toggle_tiles:\n",
        "                            self._current_env[t[0], t[1]] = 0\n",
        "                            self._current_env[t[0], t[1]] = 0\n",
        "                elif mode == \"on\":\n",
        "                    for t in toggle_tiles:\n",
        "                        self._current_env[t[0], t[1]] = 0\n",
        "                        self._current_env[t[0], t[1]] = 0\n",
        "                elif mode == \"off\":\n",
        "                    for t in toggle_tiles:\n",
        "                        self._current_env[t[0], t[1]] = 9\n",
        "                        self._current_env[t[0], t[1]] = 9\n",
        "\n",
        "    def _toggle_hard_switches(self, r1, c1, r2, c2):\n",
        "        # check if the agent is on an x switch -> activate bridge\n",
        "        for c in self._hard_switches:\n",
        "            switch_location = c[\"switch_location\"]\n",
        "            toggle_tiles = c[\"toggle_tiles\"]\n",
        "\n",
        "            if (r1 == switch_location[0] and c1 == switch_location[1]) and (\n",
        "                r2 == switch_location[0] and c2 == switch_location[1]\n",
        "            ):\n",
        "                if self._current_env[toggle_tiles[0][0], toggle_tiles[0][1]] == 0:\n",
        "                    for t in toggle_tiles:\n",
        "                        self._current_env[t[0], t[1]] = 9\n",
        "                        self._current_env[t[0], t[1]] = 9\n",
        "\n",
        "                else:\n",
        "                    for t in toggle_tiles:\n",
        "                        self._current_env[t[0], t[1]] = 0\n",
        "                        self._current_env[t[0], t[1]] = 0\n",
        "\n",
        "    def _activate_teleport_switch(self, r1, c1, r2, c2):\n",
        "        # check if block is on teleport switch -> split block into two single blocks\n",
        "        for t in self._teleport_switches:\n",
        "            switch_location = t[\"switch_location\"]\n",
        "            split_positions = t[\"split_positions\"]\n",
        "\n",
        "\n",
        "            if (r1 == switch_location[0] and c1 == switch_location[1]) and (\n",
        "                r2 == switch_location[0] and c2 == switch_location[1]\n",
        "            ):\n",
        "\n",
        "                single_block_one = split_positions[0]\n",
        "                single_block_two = split_positions[1]\n",
        "\n",
        "                r1 = single_block_one[0]\n",
        "                c1 = single_block_one[1]\n",
        "\n",
        "                r2 = single_block_two[0]\n",
        "                c2 = single_block_two[1]\n",
        "\n",
        "                self._block.set_focus(1)\n",
        "                self._block.set_coords(r1, c1, r2, c2)\n",
        "\n",
        "    def _handle_orange_tile(self, r1, c1, r2, c2):\n",
        "        # check if block is vertical\n",
        "        if (r1, c1) == (r2, c2):\n",
        "            # check if tile is orange tile\n",
        "            if self._current_env[r1, c1] == 1:\n",
        "                # tile disappears/block falls through grid\n",
        "\n",
        "                self._block.set_coords(\n",
        "                    self._r_start, self._c_start, self._r_start, self._c_start\n",
        "                )\n",
        "\n",
        "        # nothing happens if block is not vertical on an orange tile\n",
        "\n",
        "    def _perform_action(self, action):\n",
        "        # Get the corresponding method from 'actions' and call it\n",
        "        action_method = self._actions.get(int(action))\n",
        "        if action_method:\n",
        "            action_method()\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid action\")\n",
        "\n",
        "    def get_state(self):\n",
        "        r1, c1, r2, c2 = self._block.get_coords()\n",
        "        print(r1, c1, r2, c2)\n",
        "        state = np.copy(self._current_env)\n",
        "        state[r1, c1] = 8\n",
        "        state[r2, c2] = 8\n",
        "\n",
        "        return state\n",
        "\n",
        "    def get_block(self):\n",
        "        return self._block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnuJiw23_FNT"
      },
      "outputs": [],
      "source": [
        "level = 1\n",
        "\n",
        "if level == 1:\n",
        "        env = Level(start_pos=(3, 6), base_env=level_one_env)\n",
        "\n",
        "elif level == 2:\n",
        "    env = Level(\n",
        "        start_pos=(6, 3),\n",
        "        base_env=level_two_env,\n",
        "        soft_switches=level_two_soft_switches,\n",
        "        hard_switches=level_two_hard_switches,\n",
        "    )\n",
        "\n",
        "elif level == 3:\n",
        "    env = Level(start_pos=(4, 3), base_env=level_three_env)\n",
        "\n",
        "elif level == 4:\n",
        "    env = Level(start_pos=(6, 4), base_env=level_four_env)\n",
        "\n",
        "elif level == 5:\n",
        "    env = Level(\n",
        "        start_pos=(2, 15),\n",
        "        base_env=level_five_env,\n",
        "        soft_switches=level_five_soft_switches,\n",
        "    )\n",
        "elif level == 6:\n",
        "    env = Level(\n",
        "        start_pos=(4, 3),\n",
        "        base_env=level_six_env,\n",
        "    )\n",
        "\n",
        "elif level == 7:\n",
        "    env = Level(\n",
        "        start_pos=(4, 4),\n",
        "        base_env=level_seven_env,\n",
        "        hard_switches=level_seven_hard_switches,\n",
        "    )\n",
        "\n",
        "elif level == 8:\n",
        "    env = Level(\n",
        "        start_pos=(6, 4),\n",
        "        base_env=level_eight_env,\n",
        "        teleport_switches=level_eight_teleport_switches,\n",
        "    )\n",
        "elif level == 9:\n",
        "    env = Level(\n",
        "        start_pos=(4, 4),\n",
        "        base_env=level_nine_env,\n",
        "        teleport_switches=level_nine_teleport_switches\n",
        "    )\n",
        "\n",
        "elif level == 10:\n",
        "    env = Level(\n",
        "        start_pos=(2, 12),\n",
        "        base_env=level_ten_env,\n",
        "        soft_switches=level_ten_soft_switches,\n",
        "        hard_switches=level_ten_hard_switches,\n",
        "        teleport_switches=level_ten_teleport_switches,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liMDAMk2-A_u"
      },
      "source": [
        "## Set random seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ME9_hQ4s-A_u"
      },
      "outputs": [],
      "source": [
        "seed = 777\n",
        "\n",
        "def seed_torch(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.backends.cudnn.enabled:\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "seed_torch(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDXc1a0F-A_u"
      },
      "source": [
        "## Initialize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xq16PCyO-A_u",
        "outputId": "da958b2b-98d7-45b5-a3b9-37f6c82a1ee9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "Network Settings:\n",
            "In Dim  : 241\n",
            "Out Dim : 5\n",
            "Network Settings:\n",
            "In Dim  : 241\n",
            "Out Dim : 5\n"
          ]
        }
      ],
      "source": [
        "# parameters\n",
        "num_frames = 1000000\n",
        "memory_size = 1000\n",
        "batch_size = 128\n",
        "target_update = 100\n",
        "\n",
        "# train\n",
        "agent = DQNAgent(env, memory_size, batch_size, target_update, seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIZs-T4J-A_u"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "20signEc-A_v",
        "outputId": "90f65d44-48e4-416c-87ab-4e45084faab8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "agent.train(num_frames)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Id-HBP3V-A_m",
        "wcqBuH4y-A_q",
        "AzOgjQZ5-A_r",
        "osrsHcBR-A_s",
        "3pNcvmOI-A_u"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "1870f1194fb5b3d43b6d32e845741389586dbe9c4e1e45e17e0f6602cfe22778"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
