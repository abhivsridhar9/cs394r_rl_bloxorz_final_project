{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfGDyzjlZr5b"
      },
      "source": [
        "## Configurations for Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3GiPgC4Zr5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c25dfe5-6650-4428-e59f-c24209460613"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "\u001b[1;31mE: \u001b[0mUnable to locate package python-opengl\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common\n",
            "The following NEW packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common xvfb\n",
            "0 upgraded, 9 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 7,813 kB of archives.\n",
            "After this operation, 11.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.10 [28.5 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.10 [863 kB]\n",
            "Fetched 7,813 kB in 3s (2,693 kB/s)\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "(Reading database ... 131015 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../1-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../2-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../3-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../4-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../5-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../6-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../7-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.10_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../8-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.10_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "Collecting PyVirtualDisplay==3.0\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: PyVirtualDisplay\n",
            "Successfully installed PyVirtualDisplay-3.0\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    !apt install python-opengl\n",
        "    !apt install ffmpeg\n",
        "    !apt install xvfb\n",
        "    !pip install PyVirtualDisplay==3.0\n",
        "    !pip install gym\n",
        "    from pyvirtualdisplay import Display\n",
        "\n",
        "    # Start virtual display\n",
        "    dis = Display(visible=0, size=(400, 400))\n",
        "    dis.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvpLKW3vZr5e"
      },
      "source": [
        "# 02. Double DQN\n",
        "\n",
        "[van Hasselt et al., \"Deep Reinforcement Learning with Double Q-learning.\" arXiv preprint arXiv:1509.06461, 2015.](https://arxiv.org/pdf/1509.06461.pdf)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Let's take a close look at the difference between DQN and Double-DQN. The max operator in standard Q-learning and DQN uses the same values both to select and to evaluate an action. This makes it more likely to select overestimated values, resulting in overoptimistic value estimates.\n",
        "\n",
        "$$\n",
        "\\theta_{t+1} = \\theta_t + \\alpha \\big(Y_t^Q - Q(S_t, A_t; \\theta_t)\\big) \\cdot \\nabla_{\\theta_t} Q(S_t, A_t; \\theta_t),\\\\\n",
        "\\text{where } \\alpha \\text{ is a scalar step size and the target } Y_t^Q \\text{is defined as }\\\\\n",
        "Y_t^Q = R_{t+1} + \\gamma \\max_a Q(S_{t+1}, a; \\theta_t).\n",
        "$$\n",
        "\n",
        "In Double Q-learning ([van Hasselt 2010](https://papers.nips.cc/paper/3964-double-q-learning.pdf)), two value functions are learned by assigning experiences randomly to update one of the two value functions, resulting in two sets of weights, $\\theta$ and $\\theta'$. For each update, one set of weights is used to determine the greedy policy and the other to determine its value. For a clear comparison, we can untangle the selection and evaluation in Q-learning and rewrite DQN's target as\n",
        "\n",
        "$$\n",
        "Y_t^Q = R_{t+1} + \\gamma Q(S_{t+1}, \\arg\\max_a Q(S_{t+1}, a; \\theta_t); \\theta_t).\n",
        "$$\n",
        "\n",
        "The Double Q-learning error can then be written as\n",
        "\n",
        "$$\n",
        "Y_t^{DoubleQ} = R_{t+1} + \\gamma Q(S_{t+1}, \\arg\\max_a Q(S_{t+1}, a; \\theta_t); \\theta_t').\n",
        "$$\n",
        "\n",
        "The idea of Double Q-learning is to reduce overestimations by decomposing the max operation in the target into action selection and action evaluation. Although not fully decoupled, the target network in the DQN architecture provides a natural candidate for the second value function, without having to introduce additional networks. In conclusion, the weights of the second network $\\theta_t'$ are replaced with the weights of the target network for the evaluation of the current greedy policy. This makes just a small change in calculating the target value of DQN loss.\n",
        "\n",
        "##### DQN:\n",
        "\n",
        "```\n",
        "target = reward + gamma * dqn_target(next_state).max(dim=1, keepdim=True)[0]\n",
        "```\n",
        "\n",
        "##### DoubleDQN:\n",
        "\n",
        "```\n",
        "selected_action = dqn(next_state).argmax(dim=1, keepdim=True)\n",
        "target = reward + gamma * dqn_target(next_state).gather(1, selected_action)\n",
        "```\n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQpBpVuVZr5f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cHKkz-yZr5g"
      },
      "source": [
        "## Replay buffer\n",
        "\n",
        "Please see *01.dqn.ipynb* for detailed description."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUT6QteEZr5g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "273703ca-2dec-42e9-97dd-245d59c547a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "class ReplayBuffer:\n",
        "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
        "\n",
        "    def __init__(self, obs_dim: int, size: int, batch_size: int = 32):\n",
        "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
        "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
        "        self.acts_buf = np.zeros([size], dtype=np.float32)\n",
        "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
        "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
        "        self.max_size, self.batch_size = size, batch_size\n",
        "        self.ptr, self.size, = 0, 0\n",
        "\n",
        "    def store(\n",
        "        self,\n",
        "        obs: np.ndarray,\n",
        "        act: np.ndarray,\n",
        "        rew: float,\n",
        "        next_obs: np.ndarray,\n",
        "        done: bool,\n",
        "    ):\n",
        "        self.obs_buf[self.ptr] = obs\n",
        "        self.next_obs_buf[self.ptr] = next_obs\n",
        "        self.acts_buf[self.ptr] = act\n",
        "        self.rews_buf[self.ptr] = rew\n",
        "        self.done_buf[self.ptr] = done\n",
        "        self.ptr = (self.ptr + 1) % self.max_size\n",
        "        self.size = min(self.size + 1, self.max_size)\n",
        "\n",
        "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
        "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
        "        return dict(obs=self.obs_buf[idxs],\n",
        "                    next_obs=self.next_obs_buf[idxs],\n",
        "                    acts=self.acts_buf[idxs],\n",
        "                    rews=self.rews_buf[idxs],\n",
        "                    done=self.done_buf[idxs])\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uOfIie9Zr5h"
      },
      "source": [
        "## Network\n",
        "\n",
        "We are going to use a simple network architecture with three fully connected layers and two non-linearity functions (ReLU)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROzSYhkIZr5h"
      },
      "outputs": [],
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self, in_dim: int, out_dim: int):\n",
        "        \"\"\"Initialization.\"\"\"\n",
        "        super(Network, self).__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(in_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, out_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward method implementation.\"\"\"\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUGUe2Q7Zr5h"
      },
      "source": [
        "## Double DQN Agent\n",
        "\n",
        "Here is a summary of DQNAgent class.\n",
        "\n",
        "| Method           | Note                                                 |\n",
        "| ---              | ---                                                  |\n",
        "|select_action     | select an action from the input state.               |\n",
        "|step              | take an action and return the response of the env.   |\n",
        "|compute_dqn_loss  | return dqn loss.                                     |\n",
        "|update_model      | update the model by gradient descent.                |\n",
        "|target_hard_update| hard update from the local model to the target model.|\n",
        "|train             | train the agent during num_frames.                   |\n",
        "|test              | test the agent (1 episode).                          |\n",
        "|plot              | plot the training progresses.                        |\n",
        "\n",
        "We use `self.dqn` instead of `self.dqn_target` for action selection.\n",
        "\n",
        "```\n",
        "\n",
        "        next_q_value = self.dqn_target(next_state).gather(\n",
        "            1, self.dqn(next_state).argmax(dim=1, keepdim=True)  # Double DQN\n",
        "        ).detach()\n",
        "        mask = 1 - done\n",
        "        target = (reward + self.gamma * next_q_value * mask).to(self.device)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxkMaWKJZr5i"
      },
      "outputs": [],
      "source": [
        "class DQNAgent:\n",
        "    \"\"\"DQN Agent interacting with environment.\n",
        "\n",
        "    Attribute:\n",
        "        env (gym.Env): openAI Gym environment\n",
        "        memory (ReplayBuffer): replay memory to store transitions\n",
        "        batch_size (int): batch size for sampling\n",
        "        epsilon (float): parameter for epsilon greedy policy\n",
        "        epsilon_decay (float): step size to decrease epsilon\n",
        "        max_epsilon (float): max value of epsilon\n",
        "        min_epsilon (float): min value of epsilon\n",
        "        target_update (int): period for target model's hard update\n",
        "        gamma (float): discount factor\n",
        "        dqn (Network): model to train and select actions\n",
        "        dqn_target (Network): target model to update\n",
        "        optimizer (torch.optim): optimizer for training dqn\n",
        "        transition (list): transition information including\n",
        "                           state, action, reward, next_state, done\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        env: gym.Env,\n",
        "        memory_size: int,\n",
        "        batch_size: int,\n",
        "        target_update: int,\n",
        "        epsilon_decay: float,\n",
        "        seed: int,\n",
        "        max_epsilon: float = 1.0,\n",
        "        min_epsilon: float = 0.1,\n",
        "        gamma: float = 0.99,\n",
        "    ):\n",
        "        \"\"\"Initialization.\n",
        "\n",
        "        Args:\n",
        "            env (gym.Env): openAI Gym environment\n",
        "            memory_size (int): length of memory\n",
        "            batch_size (int): batch size for sampling\n",
        "            target_update (int): period for target model's hard update\n",
        "            epsilon_decay (float): step size to decrease epsilon\n",
        "            lr (float): learning rate\n",
        "            max_epsilon (float): max value of epsilon\n",
        "            min_epsilon (float): min value of epsilon\n",
        "            gamma (float): discount factor\n",
        "        \"\"\"\n",
        "        obs_dim = env.observation_space.shape[0]\n",
        "        action_dim = env.action_space.n\n",
        "\n",
        "        self.env = env\n",
        "        self.memory = ReplayBuffer(obs_dim, memory_size, batch_size)\n",
        "        self.batch_size = batch_size\n",
        "        self.epsilon = max_epsilon\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.seed = seed\n",
        "        self.max_epsilon = max_epsilon\n",
        "        self.min_epsilon = min_epsilon\n",
        "        self.target_update = target_update\n",
        "        self.gamma = gamma\n",
        "\n",
        "        # device: cpu / gpu\n",
        "        self.device = torch.device(\n",
        "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        )\n",
        "        print(self.device)\n",
        "\n",
        "        # networks: dqn, dqn_target\n",
        "        self.dqn = Network(obs_dim, action_dim).to(self.device)\n",
        "        self.dqn_target = Network(obs_dim, action_dim).to(self.device)\n",
        "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
        "        self.dqn_target.eval()\n",
        "\n",
        "        # optimizer\n",
        "        self.optimizer = optim.Adam(self.dqn.parameters())\n",
        "\n",
        "        # transition to store in memory\n",
        "        self.transition = list()\n",
        "\n",
        "        # mode: train / test\n",
        "        self.is_test = False\n",
        "\n",
        "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Select an action from the input state.\"\"\"\n",
        "        # epsilon greedy policy\n",
        "        if self.epsilon > np.random.random():\n",
        "            selected_action = self.env.action_space.sample()\n",
        "        else:\n",
        "            selected_action = self.dqn(\n",
        "                torch.FloatTensor(state).to(self.device)\n",
        "            ).argmax()\n",
        "            selected_action = selected_action.detach().cpu().numpy()\n",
        "\n",
        "        if not self.is_test:\n",
        "            self.transition = [state, selected_action]\n",
        "\n",
        "        return selected_action\n",
        "\n",
        "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
        "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
        "        next_state, reward, done = self.env.step(action)\n",
        "\n",
        "        if not self.is_test:\n",
        "            self.transition += [reward, next_state, done]\n",
        "            self.memory.store(*self.transition)\n",
        "\n",
        "        return next_state, reward, done\n",
        "\n",
        "    def update_model(self) -> torch.Tensor:\n",
        "        \"\"\"Update the model by gradient descent.\"\"\"\n",
        "        samples = self.memory.sample_batch()\n",
        "\n",
        "        loss = self._compute_dqn_loss(samples)\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "    def train(self, num_frames: int, plotting_interval: int = 200):\n",
        "        \"\"\"Train the agent.\"\"\"\n",
        "        self.is_test = False\n",
        "\n",
        "        state, _ = self.env.reset(seed=self.seed)\n",
        "        update_cnt = 0\n",
        "        epsilons = []\n",
        "        losses = []\n",
        "        scores = []\n",
        "        score = 0\n",
        "\n",
        "        for frame_idx in range(1, num_frames + 1):\n",
        "            action = self.select_action(state)\n",
        "            next_state, reward, done = self.step(action)\n",
        "\n",
        "            state = next_state\n",
        "            score += reward\n",
        "\n",
        "            # if episode ends\n",
        "            if done:\n",
        "                state, _ = self.env.reset(seed=self.seed)\n",
        "                scores.append(score)\n",
        "                score = 0\n",
        "\n",
        "            # if training is ready\n",
        "            if len(self.memory) >= self.batch_size:\n",
        "                loss = self.update_model()\n",
        "                losses.append(loss)\n",
        "                update_cnt += 1\n",
        "\n",
        "                # linearly decrease epsilon\n",
        "                self.epsilon = max(\n",
        "                    self.min_epsilon, self.epsilon - (\n",
        "                        self.max_epsilon - self.min_epsilon\n",
        "                    ) * self.epsilon_decay\n",
        "                )\n",
        "                epsilons.append(self.epsilon)\n",
        "\n",
        "                # if hard update is needed\n",
        "                if update_cnt % self.target_update == 0:\n",
        "                    self._target_hard_update()\n",
        "\n",
        "            # plotting\n",
        "            if frame_idx % plotting_interval == 0:\n",
        "                self._plot(frame_idx, scores, losses, epsilons)\n",
        "\n",
        "        self.env.close()\n",
        "\n",
        "    def test(self, video_folder: str) -> None:\n",
        "        \"\"\"Test the agent.\"\"\"\n",
        "        self.is_test = True\n",
        "\n",
        "        # for recording a video\n",
        "        naive_env = self.env\n",
        "        self.env = gym.wrappers.RecordVideo(self.env, video_folder=video_folder)\n",
        "\n",
        "        state, _ = self.env.reset(seed=self.seed)\n",
        "        done = False\n",
        "        score = 0\n",
        "\n",
        "        while not done:\n",
        "            action = self.select_action(state)\n",
        "            next_state, reward, done = self.step(action)\n",
        "\n",
        "            state = next_state\n",
        "            score += reward\n",
        "\n",
        "        print(\"score: \", score)\n",
        "        self.env.close()\n",
        "\n",
        "        # reset\n",
        "        self.env = naive_env\n",
        "\n",
        "    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray]) -> torch.Tensor:\n",
        "        \"\"\"Return dqn loss.\"\"\"\n",
        "        device = self.device  # for shortening the following lines\n",
        "        state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
        "        next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
        "        action = torch.LongTensor(samples[\"acts\"].reshape(-1, 1)).to(device)\n",
        "        reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
        "        done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
        "\n",
        "        # G_t   = r + gamma * v(s_{t+1})  if state != Terminal\n",
        "        #       = r                       otherwise\n",
        "        curr_q_value = self.dqn(state).gather(1, action)\n",
        "        next_q_value = self.dqn_target(next_state).gather(  # Double DQN\n",
        "            1, self.dqn(next_state).argmax(dim=1, keepdim=True)\n",
        "        ).detach()\n",
        "        mask = 1 - done\n",
        "        target = (reward + self.gamma * next_q_value * mask).to(self.device)\n",
        "\n",
        "        # calculate dqn loss\n",
        "        loss = F.smooth_l1_loss(curr_q_value, target)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def _target_hard_update(self):\n",
        "        \"\"\"Hard update: target <- local.\"\"\"\n",
        "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
        "\n",
        "    def _plot(\n",
        "        self,\n",
        "        frame_idx: int,\n",
        "        scores: List[float],\n",
        "        losses: List[float],\n",
        "        epsilons: List[float],\n",
        "    ):\n",
        "        \"\"\"Plot the training progresses.\"\"\"\n",
        "        clear_output(True)\n",
        "        plt.figure(figsize=(20, 5))\n",
        "        plt.subplot(131)\n",
        "        plt.title('frame %s. score: %s' % (frame_idx, np.mean(scores[-10:])))\n",
        "        plt.plot(scores)\n",
        "        plt.subplot(132)\n",
        "        plt.title('loss')\n",
        "        plt.plot(losses)\n",
        "        plt.subplot(133)\n",
        "        plt.title('epsilons')\n",
        "        plt.plot(epsilons)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHNK8UK6Zr5j"
      },
      "source": [
        "## Environment\n",
        "\n",
        "You can see the [code](https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/envs/classic_control/cartpole.py) and [configurations](https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/envs/classic_control/cartpole.py#L91) of CartPole-v1 from Farama Gymnasium's repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfVMakBeZr5j"
      },
      "outputs": [],
      "source": [
        "# 0: normal tile\n",
        "# 1: orange tile\n",
        "# 2: soft switch\n",
        "# 3: hard switch\n",
        "# 4: goal\n",
        "# 5: transport switch\n",
        "# 8: block\n",
        "# 9: none\n",
        "\n",
        "# Level 1:\n",
        "level_one_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 4, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Level 2:\n",
        "level_two_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 3, 0, 9, 9, 0, 4, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 2, 0, 9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "level_two_soft_switches = np.array(\n",
        "    [{\"switch_location\": (4, 4), \"toggle_tiles\": [(6, 6), (6, 7)], \"mode\": \"toggle\"}]\n",
        ")\n",
        "\n",
        "\n",
        "level_two_hard_switches = np.array(\n",
        "    [{\"switch_location\": (3, 10), \"toggle_tiles\": [(6, 12), (6, 13)]}]\n",
        ")\n",
        "\n",
        "# Level 3:\n",
        "level_three_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 9, 9, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 4, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Level 4:\n",
        "level_four_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 1, 1, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 1, 1, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 0, 0, 0, 0, 1, 1, 1, 1, 1, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 0, 0, 0, 0, 1, 1, 1, 1, 1, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 4, 0, 9, 9, 1, 1, 0, 1, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 1, 1, 1, 1, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Level 5:\n",
        "level_five_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 2, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 2, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "level_five_soft_switches = np.array(\n",
        "    [\n",
        "        {\n",
        "            \"switch_location\": (2, 10),\n",
        "            \"toggle_tiles\": [(2, 7), (2, 8)],\n",
        "            \"mode\": \"toggle\",\n",
        "        },\n",
        "        {\n",
        "            \"switch_location\": (7, 16),\n",
        "            \"toggle_tiles\": [(9, 7), (9, 8)],\n",
        "            \"mode\": \"toggle\",\n",
        "        },\n",
        "        {\"switch_location\": (6, 8), \"toggle_tiles\": [(9, 7), (9, 8)], \"mode\": \"off\"},\n",
        "        {\"switch_location\": (4, 5), \"toggle_tiles\": [(9, 7), (9, 8)], \"mode\": \"on\"},\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Level 6:\n",
        "level_six_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 0, 0, 0, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 0, 0, 4, 0, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Level 7:\n",
        "level_seven_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 0, 9, 9, 0, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 0, 4, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 0, 0, 3, 9, 9, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 0, 0, 0, 9, 9, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "level_seven_hard_switches = np.array(\n",
        "    [{\"switch_location\": (5, 12), \"toggle_tiles\": [(7, 6)]}]\n",
        ")\n",
        "\n",
        "\n",
        "# Level 8:\n",
        "level_eight_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 5, 0, 9, 9, 9, 0, 0, 0, 0, 4, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "level_eight_teleport_switches = np.array(\n",
        "    [{\"switch_location\": (6, 7), \"split_positions\": [(3, 13), (9, 13)]}]\n",
        ")\n",
        "\n",
        "\n",
        "# Level 9:\n",
        "level_nine_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 0, 9, 9, 9, 0, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 0, 9, 9, 9, 0, 0, 5, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 4, 0, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "level_nine_teleport_switches = np.array(\n",
        "    [{\"switch_location\": (4, 16), \"split_positions\": [(4, 15), (4, 5)]}]\n",
        ")\n",
        "\n",
        "\n",
        "# Level 10:\n",
        "level_ten_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 4, 0, 9, 9, 0, 9, 9, 0, 0, 0, 0, 5, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 9, 9, 0, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 0, 2, 9, 9, 0, 0, 0, 3, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "level_ten_teleport_switches = np.array(\n",
        "    [{\"switch_location\": (2, 15), \"split_positions\": [(2, 15), (2, 12)]}]\n",
        ")\n",
        "\n",
        "level_ten_hard_switches = np.array(\n",
        "    [{\"switch_location\": (10, 14), \"toggle_tiles\": [(2, 9), (2, 10),(3, 15), (4, 15)]}]\n",
        ")\n",
        "\n",
        "level_ten_soft_switches = np.array(\n",
        "    [{\"switch_location\": (10, 8), \"toggle_tiles\": [(2, 6), (2, 7)], \"mode\":\"toggle\"}]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Block:\n",
        "\n",
        "    def __init__(self, r1, c1, r2, c2):\n",
        "        self._r1 = r1\n",
        "        self._r2 = r2\n",
        "        self._c1 = c1\n",
        "        self._c2 = c2\n",
        "\n",
        "        self._focus_block = 0\n",
        "\n",
        "    def set_coords(self, r1, c1, r2, c2):\n",
        "        self._r1 = r1\n",
        "        self._r2 = r2\n",
        "        self._c1 = c1\n",
        "        self._c2 = c2\n",
        "\n",
        "    def get_coords(self):\n",
        "        return self._r1, self._c1, self._r2, self._c2\n",
        "\n",
        "    def is_upright(self):\n",
        "        return self._r1 == self._r2 and self._c1 == self._c2\n",
        "\n",
        "    def is_wide(self):\n",
        "        return self._r1 == self._r2 and self._c1 != self._c2\n",
        "\n",
        "    def move_up(self):\n",
        "        match self._focus_block:\n",
        "            case 0:\n",
        "                # vertical\n",
        "                if self.is_upright():\n",
        "                    self._r1 -= 1\n",
        "                    self._r2 -= 2\n",
        "\n",
        "                # flat and wide\n",
        "                elif self.is_wide():\n",
        "                    self._r1 -= 1\n",
        "                    self._r2 -= 1\n",
        "\n",
        "                # flat and long\n",
        "                else:\n",
        "                    min_r = min(self._r1, self._r2)\n",
        "                    self._r1 = min_r - 1\n",
        "                    self._r2 = min_r - 1\n",
        "\n",
        "            case 1:\n",
        "                self._r1 -= 1\n",
        "\n",
        "            case 2:\n",
        "                self._r2 -= 1\n",
        "\n",
        "    def move_down(self):\n",
        "        match self._focus_block:\n",
        "            case 0:\n",
        "                # vertical\n",
        "                if self.is_upright():\n",
        "                    self._r1 += 1\n",
        "                    self._r2 += 2\n",
        "\n",
        "                # flat and wide\n",
        "                elif self.is_wide():\n",
        "                    self._r1 += 1\n",
        "                    self._r2 += 1\n",
        "\n",
        "                # flat and long\n",
        "                else:\n",
        "                    max_r = max(self._r1, self._r2)\n",
        "                    self._r1 = max_r + 1\n",
        "                    self._r2 = max_r + 1\n",
        "\n",
        "            case 1:\n",
        "                self._r1 += 1\n",
        "            case 2:\n",
        "                self._r2 += 1\n",
        "\n",
        "    # edited\n",
        "    def move_right(self):\n",
        "        match self._focus_block:\n",
        "            case 0:\n",
        "                # vertical\n",
        "                if self.is_upright():\n",
        "                    self._c1 += 1\n",
        "                    self._c2 += 2\n",
        "\n",
        "                # flat and wide\n",
        "                elif self.is_wide():\n",
        "                    max_c = max(self._c1, self._c2)\n",
        "                    self._c1 = max_c + 1\n",
        "                    self._c2 = max_c + 1\n",
        "\n",
        "                # flat and long\n",
        "                else:\n",
        "                    self._c1 += 1\n",
        "                    self._c2 += 1\n",
        "\n",
        "            case 1:\n",
        "                self._c1 += 1\n",
        "            case 2:\n",
        "                self._c2 += 1\n",
        "\n",
        "    # edited\n",
        "    def move_left(self):\n",
        "        match self._focus_block:\n",
        "            case 0:\n",
        "                # vertical\n",
        "                if self.is_upright():\n",
        "                    self._c1 -= 1\n",
        "                    self._c2 -= 2\n",
        "\n",
        "                # flat and wide\n",
        "                elif self.is_wide():\n",
        "                    min_c = min(self._c1, self._c2)\n",
        "                    self._c1 = min_c - 1\n",
        "                    self._c2 = min_c - 1\n",
        "\n",
        "                # flat and long\n",
        "                else:\n",
        "                    self._c1 -= 1\n",
        "                    self._c2 -= 1\n",
        "            case 1:\n",
        "                self._c1 -= 1\n",
        "            case 2:\n",
        "                self._c2 -= 1\n",
        "\n",
        "    def toggle_focus(self):\n",
        "        if self._focus_block == 0:\n",
        "            self._focus_block = 0\n",
        "        elif self._focus_block == 1:\n",
        "            self._focus_block = 2\n",
        "        else:\n",
        "            self._focus_block = 1\n",
        "\n",
        "    def set_focus(self, focus):\n",
        "        self._focus_block = focus\n",
        "\n",
        "    def get_focus(self):\n",
        "        return self._focus_block\n",
        "\n",
        "    def join_single_blocks(self):\n",
        "        if self._focus_block == 1 or self._focus_block == 2:\n",
        "            if abs(self._r1 - self._r2) == 1 and (self._c1 == self._c2):\n",
        "                self.set_focus(0)\n",
        "            elif abs(self._c1 - self._c2) == 1 and (self._r1 == self._r2):\n",
        "                self.set_focus(0)"
      ],
      "metadata": {
        "id": "UBG0wb77Z_CY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Level(gym.Env):\n",
        "    metadata = {\"render_modes\": [], \"render_fps\": 0}\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        start_pos: tuple,\n",
        "        base_env: np.array([]),\n",
        "        soft_switches=np.array([]),\n",
        "        hard_switches=np.array([]),\n",
        "        teleport_switches=np.array([]),\n",
        "        render_mode=None,\n",
        "    ):\n",
        "        self._r_start = start_pos[0]\n",
        "        self._c_start = start_pos[1]\n",
        "\n",
        "        self._block = Block(self._r_start, self._c_start, self._r_start, self._c_start)\n",
        "\n",
        "        self._base_env = base_env\n",
        "\n",
        "        self._soft_switches = soft_switches\n",
        "        self._hard_switches = hard_switches\n",
        "        self._teleport_switches = teleport_switches\n",
        "\n",
        "        self._actions = {\n",
        "            0: self._block.move_right,\n",
        "            1: self._block.move_up,\n",
        "            2: self._block.move_left,\n",
        "            3: self._block.move_down,\n",
        "            4: self._block.toggle_focus,\n",
        "        }\n",
        "\n",
        "        self.observation_space = np.append(base_env.ravel(), 0)\n",
        "        self.action_space = gym.spaces.Discrete(5)\n",
        "\n",
        "    def step(self, action):\n",
        "        # if the block is split, check if single blocks are adjacent, and join together\n",
        "        self._block.join_single_blocks()\n",
        "\n",
        "        # update the agent's coords by passing it the action\n",
        "        self._perform_action(action)\n",
        "\n",
        "        # check if the agent is out of bounds -> reset to the start\n",
        "        r1, c1, r2, c2 = self._block.get_coords()\n",
        "\n",
        "        reward, done = self._is_done(r1, c1, r2, c2)\n",
        "\n",
        "        # only check for environment changes if the action is not \"Switch Focus\"\n",
        "        if action != 4:\n",
        "            self._move_to_start(r1, c1, r2, c2)\n",
        "            self._activate_teleport_switch(r1, c1, r2, c2)\n",
        "            self._toggle_soft_switches(r1, c1, r2, c2)\n",
        "            self._toggle_hard_switches(r1, c1, r2, c2)\n",
        "\n",
        "\n",
        "\n",
        "        state = self._format_environment()\n",
        "\n",
        "        return state, reward, done\n",
        "\n",
        "    def reset(self, seed):\n",
        "        # set both of the agent's coords to (self._r_start,self._c_start) and (self._r_start,self._c_start)\n",
        "        self._block.set_coords(\n",
        "            self._r_start, self._c_start, self._r_start, self._c_start\n",
        "        )\n",
        "        self._block.set_focus(0)\n",
        "\n",
        "        # reset the environment (important to undo any obstacle interactions)\n",
        "        self._current_env = np.copy(self._base_env)\n",
        "\n",
        "        # place the agent in the environment using its position\n",
        "        state = np.copy(self._current_env)\n",
        "        state[self._r_start, self._c_start] = 8\n",
        "        state = state.ravel()\n",
        "        state = np.append(state, self._block.get_focus())\n",
        "        # state = np.array2string(state, separator=\"\") + str(self._block.get_focus())\n",
        "\n",
        "        return state, False\n",
        "\n",
        "    def _move_to_start(self, r1, c1, r2, c2):\n",
        "        if self._current_env[r1, c1] == 9 or self._current_env[r2, c2] == 9:\n",
        "            self.reset(42)\n",
        "\n",
        "    def _is_done(self, r1, c1, r2, c2):\n",
        "        # check if the agent is on the goal -> set done to True and reward to 0\n",
        "\n",
        "        # reward is -1 and done is False unless the agent hit the goal\n",
        "        reward = -1\n",
        "        done = False\n",
        "\n",
        "        if self._current_env[r1, c1] == 4 and self._current_env[r2, c2] == 4:\n",
        "            reward = 0\n",
        "            done = True\n",
        "        # elif self._current_env[r1, c1] == 9 or self._current_env[r2, c2] == 9:\n",
        "        #   reward = -1000\n",
        "        #   done = True\n",
        "\n",
        "        return reward, done\n",
        "\n",
        "    def _format_environment(self):\n",
        "        # place the agent in the environment using its position\n",
        "        r1, c1, r2, c2 = self._block.get_coords()\n",
        "        state = np.copy(self._current_env)\n",
        "        state[r1, c1] = 8\n",
        "        state[r2, c2] = 8\n",
        "\n",
        "        state = state.ravel()\n",
        "        state = np.append(state, self._block.get_focus())\n",
        "        # state = np.array2string(state, separator=\"\") + str(self._block.get_focus())\n",
        "\n",
        "        return state\n",
        "\n",
        "    def _toggle_soft_switches(self, r1, c1, r2, c2):\n",
        "        # check if the agent is on a circle switch -> activate bridge\n",
        "        for c in self._soft_switches:\n",
        "            switch_location = c[\"switch_location\"]\n",
        "            toggle_tiles = c[\"toggle_tiles\"]\n",
        "            mode = c[\"mode\"]\n",
        "\n",
        "            if (r1 == switch_location[0] and c1 == switch_location[1]) or (\n",
        "                r2 == switch_location[0] and c2 == switch_location[1]\n",
        "            ):\n",
        "                if mode == \"toggle\":\n",
        "                    if self._current_env[toggle_tiles[0][0], toggle_tiles[0][1]] == 0:\n",
        "                        for t in toggle_tiles:\n",
        "                            self._current_env[t[0], t[1]] = 9\n",
        "                            self._current_env[t[0], t[1]] = 9\n",
        "\n",
        "                    else:\n",
        "                        for t in toggle_tiles:\n",
        "                            self._current_env[t[0], t[1]] = 0\n",
        "                            self._current_env[t[0], t[1]] = 0\n",
        "                elif mode == \"on\":\n",
        "                    for t in toggle_tiles:\n",
        "                        self._current_env[t[0], t[1]] = 0\n",
        "                        self._current_env[t[0], t[1]] = 0\n",
        "                elif mode == \"off\":\n",
        "                    for t in toggle_tiles:\n",
        "                        self._current_env[t[0], t[1]] = 9\n",
        "                        self._current_env[t[0], t[1]] = 9\n",
        "\n",
        "    def _toggle_hard_switches(self, r1, c1, r2, c2):\n",
        "        # check if the agent is on an x switch -> activate bridge\n",
        "        for c in self._hard_switches:\n",
        "            switch_location = c[\"switch_location\"]\n",
        "            toggle_tiles = c[\"toggle_tiles\"]\n",
        "\n",
        "            if (r1 == switch_location[0] and c1 == switch_location[1]) and (\n",
        "                r2 == switch_location[0] and c2 == switch_location[1]\n",
        "            ):\n",
        "                if self._current_env[toggle_tiles[0][0], toggle_tiles[0][1]] == 0:\n",
        "                    for t in toggle_tiles:\n",
        "                        self._current_env[t[0], t[1]] = 9\n",
        "                        self._current_env[t[0], t[1]] = 9\n",
        "\n",
        "                else:\n",
        "                    for t in toggle_tiles:\n",
        "                        self._current_env[t[0], t[1]] = 0\n",
        "                        self._current_env[t[0], t[1]] = 0\n",
        "\n",
        "    def _activate_teleport_switch(self, r1, c1, r2, c2):\n",
        "        # check if block is on teleport switch -> split block into two single blocks\n",
        "        for t in self._teleport_switches:\n",
        "            switch_location = t[\"switch_location\"]\n",
        "            split_positions = t[\"split_positions\"]\n",
        "\n",
        "\n",
        "            if (r1 == switch_location[0] and c1 == switch_location[1]) and (\n",
        "                r2 == switch_location[0] and c2 == switch_location[1]\n",
        "            ):\n",
        "\n",
        "                single_block_one = split_positions[0]\n",
        "                single_block_two = split_positions[1]\n",
        "\n",
        "                r1 = single_block_one[0]\n",
        "                c1 = single_block_one[1]\n",
        "\n",
        "                r2 = single_block_two[0]\n",
        "                c2 = single_block_two[1]\n",
        "\n",
        "                self._block.set_focus(1)\n",
        "                self._block.set_coords(r1, c1, r2, c2)\n",
        "\n",
        "    def _handle_orange_tile(self, r1, c1, r2, c2):\n",
        "        # check if block is vertical\n",
        "        if (r1, c1) == (r2, c2):\n",
        "            # check if tile is orange tile\n",
        "            if self._current_env[r1, c1] == 1:\n",
        "                # tile disappears/block falls through grid\n",
        "\n",
        "                self._block.set_coords(\n",
        "                    self._r_start, self._c_start, self._r_start, self._c_start\n",
        "                )\n",
        "\n",
        "        # nothing happens if block is not vertical on an orange tile\n",
        "\n",
        "    def _perform_action(self, action):\n",
        "        # Get the corresponding method from 'actions' and call it\n",
        "        action_method = self._actions.get(int(action))\n",
        "        if action_method:\n",
        "            action_method()\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid action\")\n",
        "\n",
        "    def get_state(self):\n",
        "        r1, c1, r2, c2 = self._block.get_coords()\n",
        "        print(r1, c1, r2, c2)\n",
        "        state = np.copy(self._current_env)\n",
        "        state[r1, c1] = 8\n",
        "        state[r2, c2] = 8\n",
        "\n",
        "        return state\n",
        "\n",
        "    def get_block(self):\n",
        "        return self._block"
      ],
      "metadata": {
        "id": "OAbnMvIUaAHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "level = 1\n",
        "\n",
        "if level == 1:\n",
        "        env = Level(start_pos=(3, 6), base_env=level_one_env)\n",
        "\n",
        "elif level == 2:\n",
        "    env = Level(\n",
        "        start_pos=(6, 3),\n",
        "        base_env=level_two_env,\n",
        "        soft_switches=level_two_soft_switches,\n",
        "        hard_switches=level_two_hard_switches,\n",
        "    )\n",
        "\n",
        "elif level == 3:\n",
        "    env = Level(start_pos=(4, 3), base_env=level_three_env)\n",
        "\n",
        "elif level == 4:\n",
        "    env = Level(start_pos=(6, 4), base_env=level_four_env)\n",
        "\n",
        "elif level == 5:\n",
        "    env = Level(\n",
        "        start_pos=(2, 15),\n",
        "        base_env=level_five_env,\n",
        "        soft_switches=level_five_soft_switches,\n",
        "    )\n",
        "elif level == 6:\n",
        "    env = Level(\n",
        "        start_pos=(4, 3),\n",
        "        base_env=level_six_env,\n",
        "    )\n",
        "\n",
        "elif level == 7:\n",
        "    env = Level(\n",
        "        start_pos=(4, 4),\n",
        "        base_env=level_seven_env,\n",
        "        hard_switches=level_seven_hard_switches,\n",
        "    )\n",
        "\n",
        "elif level == 8:\n",
        "    env = Level(\n",
        "        start_pos=(6, 4),\n",
        "        base_env=level_eight_env,\n",
        "        teleport_switches=level_eight_teleport_switches,\n",
        "    )\n",
        "elif level == 9:\n",
        "    env = Level(\n",
        "        start_pos=(4, 4),\n",
        "        base_env=level_nine_env,\n",
        "        teleport_switches=level_nine_teleport_switches\n",
        "    )\n",
        "\n",
        "elif level == 10:\n",
        "    env = Level(\n",
        "        start_pos=(2, 12),\n",
        "        base_env=level_ten_env,\n",
        "        soft_switches=level_ten_soft_switches,\n",
        "        hard_switches=level_ten_hard_switches,\n",
        "        teleport_switches=level_ten_teleport_switches,\n",
        "    )"
      ],
      "metadata": {
        "id": "aIgi_VGlaCXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLMPDxVOZr5j"
      },
      "source": [
        "## Set random seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlF7EpwPZr5j"
      },
      "outputs": [],
      "source": [
        "seed = 777\n",
        "\n",
        "def seed_torch(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.backends.cudnn.enabled:\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "\n",
        "np.random.seed(seed)\n",
        "seed_torch(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtWGLq1HZr5j"
      },
      "source": [
        "## Initialize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtSWBa3YZr5j",
        "outputId": "bf7b252c-9df5-4375-ac8d-c1367972e694",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# parameters\n",
        "num_frames = 500000\n",
        "memory_size = 1000\n",
        "batch_size = 128\n",
        "target_update = 100\n",
        "epsilon_decay = 1 / 100\n",
        "\n",
        "# train\n",
        "agent = DQNAgent(env, memory_size, batch_size, target_update, epsilon_decay, seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md3A8kZKZr5k"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eANOHgZnZr5k",
        "outputId": "9dc7f36c-1649-46a7-8f67-058da0c6ec94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x500 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-4326fee8443c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-bab1d652f11f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_frames, plotting_interval)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;31m# if training is ready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0mupdate_cnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-bab1d652f11f>\u001b[0m in \u001b[0;36mupdate_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dqn_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-bab1d652f11f>\u001b[0m in \u001b[0;36m_compute_dqn_loss\u001b[0;34m(self, samples)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m#       = r                       otherwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mcurr_q_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdqn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         next_q_value = self.dqn_target(next_state).gather(  # Double DQN\n\u001b[0m\u001b[1;32m    205\u001b[0m             \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdqn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         ).detach()\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-886fa7d7d67b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;34m\"\"\"Forward method implementation.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "agent.train(num_frames)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qfFP-YQNl7D-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rainbow-is-all-you-need",
      "language": "python",
      "name": "rainbow-is-all-you-need"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}