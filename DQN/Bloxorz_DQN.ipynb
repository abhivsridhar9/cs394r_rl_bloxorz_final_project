{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRg1yrjNUqb_"
      },
      "source": [
        "## Configurations for Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVIx7cLsUqcB",
        "outputId": "9632cad4-e71e-4261-9e61-3da6d0f9890f"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    !apt install python-opengl\n",
        "    !apt install ffmpeg\n",
        "    !apt install xvfb\n",
        "    !pip install PyVirtualDisplay==3.0\n",
        "    !pip install gym\n",
        "    from pyvirtualdisplay import Display\n",
        "\n",
        "    # Start virtual display\n",
        "    dis = Display(visible=0, size=(400, 400))\n",
        "    dis.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwhE_hhZUqcB"
      },
      "source": [
        "# 01. DQN\n",
        "\n",
        "[V. Mnih et al., \"Human-level control through deep reinforcement learning.\" Nature, 518\n",
        "(7540):529–533, 2015.](https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf)\n",
        "\n",
        "Reinforcement learning is known to be unstable or even to diverge when a nonlinear function approximator such as a neural network is used to represent the action-value (also known as $Q$) function. This instability has several causes: the correlations present in the sequence of observations, the fact that small updates to $Q$ may significantly change the policy and therefore change the data distribution, and the correlations between the action-values ($Q$) and the target values $r + \\gamma \\max_{a'} Q(s', a')$.\n",
        "\n",
        "The authors suggest two key ideas to address these instabilities with a novel variant of Q-learning: Replay buffer and Fixed Q-target.\n",
        "\n",
        "#### Uniformly random sampling from Experience Replay Memory\n",
        "\n",
        "Reinforcement learning agent stores the experiences consecutively in the buffer, so adjacent ($s, a, r, s'$) transitions stored are highly likely to have correlation. To remove this, the agent samples experiences uniformly at random from the pool of stored samples $\\big( (s, a, r, s') \\sim U(D) \\big)$. See sample_batch method of ReplayBuffer class for more details.\n",
        "\n",
        "#### Fixed Q-target\n",
        "\n",
        "DQN uses an iterative update that adjusts the action-values ($Q$) towards target values that are only periodically updated, thereby reducing correlations with the target; if not, it is easily divergy because the target continuously moves. The Q-learning update at iteration $i$ uses the following loss function:\n",
        "\n",
        "$$\n",
        "L_i(\\theta_i) = \\mathbb{E}_{(s,a,r,s') \\sim U(D)} \\big[ \\big( r + \\gamma \\max_{a'} Q(s',a';\\theta_i^-) - Q(s, a; \\theta_i) \\big)^2 \\big]\n",
        "$$\n",
        "\n",
        "in which $\\gamma$ is the discount factor determining the agent’s horizon, $\\theta_i$ are the parameters of the Q-network at iteration $i$ and $\\theta_i^-$ are the network parameters used to compute the target at iteration $i$. The target network parameters $\\theta_i^-$ are only updated with the Q-network parameters ($\\theta_i$) every C steps and are held fixed between individual updates. ($C = 200$ in CartPole-v0)\n",
        "\n",
        "#### For more stability: Gradient clipping\n",
        "\n",
        "The authors also found it helpful to clip the error term from the update $r + \\gamma \\max_{a'} Q(s', a'; \\theta_i^-) - Q(s,a,;\\theta_i)$ to be between -1 and 1. Because the absolute value loss function $|x|$ has a derivative of -1 for all negative values of x and a derivative of 1 for all positive values of x, clipping the squared error to be between -1 and 1 corresponds to using an absolute value loss function for errors outside of the (-1,1) interval. This form of error clipping further improved the stability of the algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6XArirxXUqcC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPwLoSYTUqcC"
      },
      "source": [
        "## Replay buffer\n",
        "\n",
        "Typically, people implement replay buffers with one of the following three data structures:\n",
        "\n",
        "  - collections.deque\n",
        "  - list\n",
        "  - numpy.ndarray\n",
        "  \n",
        "**deque** is very easy to handle once you initialize its maximum length (e.g. deque(maxlen=buffer_size)). However, the indexing operation of deque gets terribly slow as it grows up because it is [internally doubly linked list](https://wiki.python.org/moin/TimeComplexity#collections.deque). On the other hands, **list** is an array, so it is relatively faster than deque when you sample batches at every step. Its amortized cost of  *Get item* is [O(1)](https://wiki.python.org/moin/TimeComplexity#list).\n",
        "\n",
        "Last but not least, let's see **numpy.ndarray**. numpy.ndarray is even faster than list due to the fact that it is [a homogeneous array of fixed-size items](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray), so you can get the benefits of [locality of reference](https://en.wikipedia.org/wiki/Locality_of_reference). Whereas list is an array of pointers to objects, even when all of them are of the same type.\n",
        "\n",
        "Here, we are going to implement a replay buffer using numpy.ndarray.\n",
        "\n",
        "\n",
        "Reference: [OpenAI spinning-up](https://github.com/openai/spinningup/blob/master/spinup/algos/sac/sac.py#L10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "criq1JefUqcC",
        "outputId": "7a9b0563-4529-42f2-c353-3e6d658928bb"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer:\n",
        "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
        "\n",
        "    def __init__(self, obs_dim: int, size: int, batch_size: int = 32):\n",
        "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
        "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
        "        self.acts_buf = np.zeros([size], dtype=np.float32)\n",
        "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
        "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
        "        self.max_size, self.batch_size = size, batch_size\n",
        "        self.ptr, self.size, = 0, 0\n",
        "\n",
        "    def store(\n",
        "        self,\n",
        "        obs: np.ndarray,\n",
        "        act: np.ndarray,\n",
        "        rew: float,\n",
        "        next_obs: np.ndarray,\n",
        "        done: bool,\n",
        "    ):\n",
        "        self.obs_buf[self.ptr] = obs\n",
        "        self.next_obs_buf[self.ptr] = next_obs\n",
        "        self.acts_buf[self.ptr] = act\n",
        "        self.rews_buf[self.ptr] = rew\n",
        "        self.done_buf[self.ptr] = done\n",
        "        self.ptr = (self.ptr + 1) % self.max_size\n",
        "        self.size = min(self.size + 1, self.max_size)\n",
        "\n",
        "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
        "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
        "        return dict(obs=self.obs_buf[idxs],\n",
        "                    next_obs=self.next_obs_buf[idxs],\n",
        "                    acts=self.acts_buf[idxs],\n",
        "                    rews=self.rews_buf[idxs],\n",
        "                    done=self.done_buf[idxs])\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbkNIvZsUqcC"
      },
      "source": [
        "## Network\n",
        "\n",
        "We are going to use a simple network architecture with three fully connected layers and two non-linearity functions (ReLU)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "t7UF1k6zUqcD"
      },
      "outputs": [],
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self, in_dim: int, out_dim: int):\n",
        "        \"\"\"Initialization.\"\"\"\n",
        "        super(Network, self).__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(in_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, out_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward method implementation.\"\"\"\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epE2yWNlUqcD"
      },
      "source": [
        "## DQN Agent\n",
        "\n",
        "Here is a summary of DQNAgent class.\n",
        "\n",
        "| Method           | Note                                                 |\n",
        "| ---              | ---                                                  |\n",
        "|select_action     | select an action from the input state.               |\n",
        "|step              | take an action and return the response of the env.   |\n",
        "|compute_dqn_loss  | return dqn loss.                                     |\n",
        "|update_model      | update the model by gradient descent.                |\n",
        "|target_hard_update| hard update from the local model to the target model.|\n",
        "|train             | train the agent during num_frames.                   |\n",
        "|test              | test the agent (1 episode).                          |\n",
        "|plot              | plot the training progresses.                        |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6mow49AsUqcD"
      },
      "outputs": [],
      "source": [
        "class DQNAgent:\n",
        "    \"\"\"DQN Agent interacting with environment.\n",
        "\n",
        "    Attribute:\n",
        "        env (gym.Env): openAI Gym environment\n",
        "        memory (ReplayBuffer): replay memory to store transitions\n",
        "        batch_size (int): batch size for sampling\n",
        "        epsilon (float): parameter for epsilon greedy policy\n",
        "        epsilon_decay (float): step size to decrease epsilon\n",
        "        max_epsilon (float): max value of epsilon\n",
        "        min_epsilon (float): min value of epsilon\n",
        "        target_update (int): period for target model's hard update\n",
        "        gamma (float): discount factor\n",
        "        dqn (Network): model to train and select actions\n",
        "        dqn_target (Network): target model to update\n",
        "        optimizer (torch.optim): optimizer for training dqn\n",
        "        transition (list): transition information including\n",
        "                           state, action, reward, next_state, done\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        env: gym.Env,\n",
        "        memory_size: int,\n",
        "        batch_size: int,\n",
        "        target_update: int,\n",
        "        epsilon_decay: float,\n",
        "        seed: int,\n",
        "        max_epsilon: float = 1.0,\n",
        "        min_epsilon: float = 0.1,\n",
        "        gamma: float = 0.99,\n",
        "    ):\n",
        "        \"\"\"Initialization.\n",
        "\n",
        "        Args:\n",
        "            env (gym.Env): openAI Gym environment\n",
        "            memory_size (int): length of memory\n",
        "            batch_size (int): batch size for sampling\n",
        "            target_update (int): period for target model's hard update\n",
        "            epsilon_decay (float): step size to decrease epsilon\n",
        "            lr (float): learning rate\n",
        "            max_epsilon (float): max value of epsilon\n",
        "            min_epsilon (float): min value of epsilon\n",
        "            gamma (float): discount factor\n",
        "        \"\"\"\n",
        "        obs_dim = env.observation_space.shape[0]\n",
        "        action_dim = env.action_space.n\n",
        "\n",
        "        self.env = env\n",
        "        self.memory = ReplayBuffer(obs_dim, memory_size, batch_size)\n",
        "        self.batch_size = batch_size\n",
        "        self.epsilon = max_epsilon\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.seed = seed\n",
        "        self.max_epsilon = max_epsilon\n",
        "        self.min_epsilon = min_epsilon\n",
        "        self.target_update = target_update\n",
        "        self.gamma = gamma\n",
        "\n",
        "        # device: cpu / gpu\n",
        "        self.device = torch.device(\n",
        "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        )\n",
        "        print(self.device)\n",
        "\n",
        "        # networks: dqn, dqn_target\n",
        "        self.dqn = Network(obs_dim, action_dim).to(self.device)\n",
        "        self.dqn_target = Network(obs_dim, action_dim).to(self.device)\n",
        "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
        "        self.dqn_target.eval()\n",
        "\n",
        "        # optimizer\n",
        "        self.optimizer = optim.Adam(self.dqn.parameters())\n",
        "\n",
        "        # transition to store in memory\n",
        "        self.transition = list()\n",
        "\n",
        "        # mode: train / test\n",
        "        self.is_test = False\n",
        "\n",
        "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Select an action from the input state.\"\"\"\n",
        "        # epsilon greedy policy\n",
        "        if self.epsilon > np.random.random():\n",
        "            selected_action = self.env.action_space.sample()\n",
        "        else:\n",
        "            selected_action = self.dqn(\n",
        "                torch.FloatTensor(state).to(self.device)\n",
        "            ).argmax()\n",
        "            selected_action = selected_action.detach().cpu().numpy()\n",
        "\n",
        "        if not self.is_test:\n",
        "            self.transition = [state, selected_action]\n",
        "\n",
        "        return selected_action\n",
        "\n",
        "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
        "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
        "        next_state, reward, done = self.env.step(action)\n",
        "\n",
        "        if not self.is_test:\n",
        "            self.transition += [reward, next_state, done]\n",
        "            self.memory.store(*self.transition)\n",
        "\n",
        "        return next_state, reward, done\n",
        "\n",
        "    def update_model(self) -> torch.Tensor:\n",
        "        \"\"\"Update the model by gradient descent.\"\"\"\n",
        "        samples = self.memory.sample_batch()\n",
        "\n",
        "        loss = self._compute_dqn_loss(samples)\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "    def train(self, num_frames: int, plotting_interval: int = 200):\n",
        "        \"\"\"Train the agent.\"\"\"\n",
        "        self.is_test = False\n",
        "\n",
        "        state, _ = self.env.reset(seed=self.seed)\n",
        "        update_cnt = 0\n",
        "        epsilons = []\n",
        "        losses = []\n",
        "        scores = []\n",
        "        score = 0\n",
        "\n",
        "        for frame_idx in range(1, num_frames + 1):\n",
        "            action = self.select_action(state)\n",
        "            next_state, reward, done = self.step(action)\n",
        "\n",
        "            state = next_state\n",
        "            score += reward\n",
        "\n",
        "            # if episode ends\n",
        "            if done:\n",
        "                state, _ = self.env.reset(seed=self.seed)\n",
        "                scores.append(score)\n",
        "                score = 0\n",
        "\n",
        "            # if training is ready\n",
        "            if len(self.memory) >= self.batch_size:\n",
        "                loss = self.update_model()\n",
        "                losses.append(loss)\n",
        "                update_cnt += 1\n",
        "\n",
        "                # linearly decrease epsilon\n",
        "                self.epsilon = max(\n",
        "                    self.min_epsilon, self.epsilon - (\n",
        "                        self.max_epsilon - self.min_epsilon\n",
        "                    ) * self.epsilon_decay\n",
        "                )\n",
        "                epsilons.append(self.epsilon)\n",
        "\n",
        "                # if hard update is needed\n",
        "                if update_cnt % self.target_update == 0:\n",
        "                    self._target_hard_update()\n",
        "\n",
        "            # plotting\n",
        "            if frame_idx % plotting_interval == 0:\n",
        "                self._plot(frame_idx, scores, losses, epsilons)\n",
        "\n",
        "        self.env.close()\n",
        "\n",
        "    def test(self, video_folder: str) -> None:\n",
        "        \"\"\"Test the agent.\"\"\"\n",
        "        self.is_test = True\n",
        "\n",
        "        # for recording a video\n",
        "        naive_env = self.env\n",
        "        self.env = gym.wrappers.RecordVideo(self.env, video_folder=video_folder)\n",
        "\n",
        "        state, _ = self.env.reset(seed=self.seed)\n",
        "        done = False\n",
        "        score = 0\n",
        "\n",
        "        while not done:\n",
        "            action = self.select_action(state)\n",
        "            next_state, reward, done = self.step(action)\n",
        "\n",
        "            state = next_state\n",
        "            score += reward\n",
        "\n",
        "        print(\"score: \", score)\n",
        "        self.env.close()\n",
        "\n",
        "        # reset\n",
        "        self.env = naive_env\n",
        "\n",
        "    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray]) -> torch.Tensor:\n",
        "        \"\"\"Return dqn loss.\"\"\"\n",
        "        device = self.device  # for shortening the following lines\n",
        "        state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
        "        next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
        "        action = torch.LongTensor(samples[\"acts\"].reshape(-1, 1)).to(device)\n",
        "        reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
        "        done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
        "\n",
        "        # G_t   = r + gamma * v(s_{t+1})  if state != Terminal\n",
        "        #       = r                       otherwise\n",
        "        curr_q_value = self.dqn(state).gather(1, action)\n",
        "        next_q_value = self.dqn_target(\n",
        "            next_state\n",
        "        ).max(dim=1, keepdim=True)[0].detach()\n",
        "        mask = 1 - done\n",
        "        target = (reward + self.gamma * next_q_value * mask).to(self.device)\n",
        "\n",
        "        # calculate dqn loss\n",
        "        loss = F.smooth_l1_loss(curr_q_value, target)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def _target_hard_update(self):\n",
        "        \"\"\"Hard update: target <- local.\"\"\"\n",
        "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
        "\n",
        "    def _plot(\n",
        "        self,\n",
        "        frame_idx: int,\n",
        "        scores: List[float],\n",
        "        losses: List[float],\n",
        "        epsilons: List[float],\n",
        "    ):\n",
        "        \"\"\"Plot the training progresses.\"\"\"\n",
        "        clear_output(True)\n",
        "        plt.figure(figsize=(20, 5))\n",
        "        plt.subplot(131)\n",
        "        plt.title('frame %s. score: %s' % (frame_idx, np.mean(scores[-10:])))\n",
        "        plt.plot(scores)\n",
        "        plt.subplot(132)\n",
        "        plt.title('loss')\n",
        "        plt.plot(losses)\n",
        "        plt.subplot(133)\n",
        "        plt.title('epsilons')\n",
        "        plt.plot(epsilons)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8S2W-pJXUqcD"
      },
      "source": [
        "## Environment\n",
        "\n",
        "You can see the [code](https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/envs/classic_control/cartpole.py) and [configurations](https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/envs/classic_control/cartpole.py#L91) of CartPole-v1 from Farama Gymnasium's repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3CZJ2aiQUqcD"
      },
      "outputs": [],
      "source": [
        "# 0: normal tile\n",
        "# 1: orange tile\n",
        "# 2: soft switch\n",
        "# 3: hard switch\n",
        "# 4: goal\n",
        "# 5: transport switch\n",
        "# 8: block\n",
        "# 9: none\n",
        "\n",
        "# Level 1:\n",
        "level_one_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 4, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Level 2:\n",
        "level_two_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 3, 0, 9, 9, 0, 4, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 2, 0, 9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "level_two_soft_switches = np.array(\n",
        "    [{\"switch_location\": (4, 4), \"toggle_tiles\": [(6, 6), (6, 7)], \"mode\": \"toggle\"}]\n",
        ")\n",
        "\n",
        "\n",
        "level_two_hard_switches = np.array(\n",
        "    [{\"switch_location\": (3, 10), \"toggle_tiles\": [(6, 12), (6, 13)]}]\n",
        ")\n",
        "\n",
        "# Level 3:\n",
        "level_three_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 9, 9, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 4, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Level 4:\n",
        "level_four_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 1, 1, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 1, 1, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 0, 0, 0, 0, 1, 1, 1, 1, 1, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 0, 0, 0, 0, 1, 1, 1, 1, 1, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 4, 0, 9, 9, 1, 1, 0, 1, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 1, 1, 1, 1, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Level 5:\n",
        "level_five_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 2, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 2, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "level_five_soft_switches = np.array(\n",
        "    [\n",
        "        {\n",
        "            \"switch_location\": (2, 10),\n",
        "            \"toggle_tiles\": [(2, 7), (2, 8)],\n",
        "            \"mode\": \"toggle\",\n",
        "        },\n",
        "        {\n",
        "            \"switch_location\": (7, 16),\n",
        "            \"toggle_tiles\": [(9, 7), (9, 8)],\n",
        "            \"mode\": \"toggle\",\n",
        "        },\n",
        "        {\"switch_location\": (6, 8), \"toggle_tiles\": [(9, 7), (9, 8)], \"mode\": \"off\"},\n",
        "        {\"switch_location\": (4, 5), \"toggle_tiles\": [(9, 7), (9, 8)], \"mode\": \"on\"},\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Level 6:\n",
        "level_six_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 0, 0, 0, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 0, 0, 4, 0, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Level 7:\n",
        "level_seven_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 0, 9, 9, 0, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 0, 4, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 0, 0, 3, 9, 9, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 0, 0, 0, 9, 9, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "level_seven_hard_switches = np.array(\n",
        "    [{\"switch_location\": (5, 12), \"toggle_tiles\": [(7, 6)]}]\n",
        ")\n",
        "\n",
        "\n",
        "# Level 8:\n",
        "level_eight_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 5, 0, 9, 9, 9, 0, 0, 0, 0, 4, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "level_eight_teleport_switches = np.array(\n",
        "    [{\"switch_location\": (6, 7), \"split_positions\": [(3, 13), (9, 13)]}]\n",
        ")\n",
        "\n",
        "\n",
        "# Level 9:\n",
        "level_nine_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 0, 9, 9, 9, 0, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 0, 9, 9, 9, 0, 0, 5, 0, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 4, 0, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "level_nine_teleport_switches = np.array(\n",
        "    [{\"switch_location\": (4, 16), \"split_positions\": [(4, 15), (4, 5)]}]\n",
        ")\n",
        "\n",
        "\n",
        "# Level 10:\n",
        "level_ten_env = np.array(\n",
        "    [\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 4, 0, 9, 9, 0, 9, 9, 0, 0, 0, 0, 5, 0, 9, 9, 9],\n",
        "        [9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 9, 9, 0, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 0, 2, 9, 9, 0, 0, 0, 3, 0, 9, 9, 9, 9],\n",
        "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "    ]\n",
        ")\n",
        "\n",
        "level_ten_teleport_switches = np.array(\n",
        "    [{\"switch_location\": (2, 15), \"split_positions\": [(2, 15), (2, 12)]}]\n",
        ")\n",
        "\n",
        "level_ten_hard_switches = np.array(\n",
        "    [{\"switch_location\": (10, 14), \"toggle_tiles\": [(2, 9), (2, 10),(3, 15), (4, 15)]}]\n",
        ")\n",
        "\n",
        "level_ten_soft_switches = np.array(\n",
        "    [{\"switch_location\": (10, 8), \"toggle_tiles\": [(2, 6), (2, 7)], \"mode\":\"toggle\"}]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "usO3fAkCU3wD"
      },
      "outputs": [],
      "source": [
        "class Block:\n",
        "\n",
        "    def __init__(self, r1, c1, r2, c2):\n",
        "        self._r1 = r1\n",
        "        self._r2 = r2\n",
        "        self._c1 = c1\n",
        "        self._c2 = c2\n",
        "\n",
        "        self._focus_block = 0\n",
        "\n",
        "    def set_coords(self, r1, c1, r2, c2):\n",
        "        self._r1 = r1\n",
        "        self._r2 = r2\n",
        "        self._c1 = c1\n",
        "        self._c2 = c2\n",
        "\n",
        "    def get_coords(self):\n",
        "        return self._r1, self._c1, self._r2, self._c2\n",
        "\n",
        "    def is_upright(self):\n",
        "        return self._r1 == self._r2 and self._c1 == self._c2\n",
        "\n",
        "    def is_wide(self):\n",
        "        return self._r1 == self._r2 and self._c1 != self._c2\n",
        "\n",
        "    def move_up(self):\n",
        "        match self._focus_block:\n",
        "            case 0:\n",
        "                # vertical\n",
        "                if self.is_upright():\n",
        "                    self._r1 -= 1\n",
        "                    self._r2 -= 2\n",
        "\n",
        "                # flat and wide\n",
        "                elif self.is_wide():\n",
        "                    self._r1 -= 1\n",
        "                    self._r2 -= 1\n",
        "\n",
        "                # flat and long\n",
        "                else:\n",
        "                    min_r = min(self._r1, self._r2)\n",
        "                    self._r1 = min_r - 1\n",
        "                    self._r2 = min_r - 1\n",
        "\n",
        "            case 1:\n",
        "                self._r1 -= 1\n",
        "\n",
        "            case 2:\n",
        "                self._r2 -= 1\n",
        "\n",
        "    def move_down(self):\n",
        "        match self._focus_block:\n",
        "            case 0:\n",
        "                # vertical\n",
        "                if self.is_upright():\n",
        "                    self._r1 += 1\n",
        "                    self._r2 += 2\n",
        "\n",
        "                # flat and wide\n",
        "                elif self.is_wide():\n",
        "                    self._r1 += 1\n",
        "                    self._r2 += 1\n",
        "\n",
        "                # flat and long\n",
        "                else:\n",
        "                    max_r = max(self._r1, self._r2)\n",
        "                    self._r1 = max_r + 1\n",
        "                    self._r2 = max_r + 1\n",
        "\n",
        "            case 1:\n",
        "                self._r1 += 1\n",
        "            case 2:\n",
        "                self._r2 += 1\n",
        "\n",
        "    # edited\n",
        "    def move_right(self):\n",
        "        match self._focus_block:\n",
        "            case 0:\n",
        "                # vertical\n",
        "                if self.is_upright():\n",
        "                    self._c1 += 1\n",
        "                    self._c2 += 2\n",
        "\n",
        "                # flat and wide\n",
        "                elif self.is_wide():\n",
        "                    max_c = max(self._c1, self._c2)\n",
        "                    self._c1 = max_c + 1\n",
        "                    self._c2 = max_c + 1\n",
        "\n",
        "                # flat and long\n",
        "                else:\n",
        "                    self._c1 += 1\n",
        "                    self._c2 += 1\n",
        "\n",
        "            case 1:\n",
        "                self._c1 += 1\n",
        "            case 2:\n",
        "                self._c2 += 1\n",
        "\n",
        "    # edited\n",
        "    def move_left(self):\n",
        "        match self._focus_block:\n",
        "            case 0:\n",
        "                # vertical\n",
        "                if self.is_upright():\n",
        "                    self._c1 -= 1\n",
        "                    self._c2 -= 2\n",
        "\n",
        "                # flat and wide\n",
        "                elif self.is_wide():\n",
        "                    min_c = min(self._c1, self._c2)\n",
        "                    self._c1 = min_c - 1\n",
        "                    self._c2 = min_c - 1\n",
        "\n",
        "                # flat and long\n",
        "                else:\n",
        "                    self._c1 -= 1\n",
        "                    self._c2 -= 1\n",
        "            case 1:\n",
        "                self._c1 -= 1\n",
        "            case 2:\n",
        "                self._c2 -= 1\n",
        "\n",
        "    def toggle_focus(self):\n",
        "        if self._focus_block == 0:\n",
        "            self._focus_block = 0\n",
        "        elif self._focus_block == 1:\n",
        "            self._focus_block = 2\n",
        "        else:\n",
        "            self._focus_block = 1\n",
        "\n",
        "    def set_focus(self, focus):\n",
        "        self._focus_block = focus\n",
        "\n",
        "    def get_focus(self):\n",
        "        return self._focus_block\n",
        "\n",
        "    def join_single_blocks(self):\n",
        "        if self._focus_block == 1 or self._focus_block == 2:\n",
        "            if abs(self._r1 - self._r2) == 1 and (self._c1 == self._c2):\n",
        "                self.set_focus(0)\n",
        "            elif abs(self._c1 - self._c2) == 1 and (self._r1 == self._r2):\n",
        "                self.set_focus(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bXe_BBS-U555"
      },
      "outputs": [],
      "source": [
        "class Level(gym.Env):\n",
        "    metadata = {\"render_modes\": [], \"render_fps\": 0}\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        start_pos: tuple,\n",
        "        base_env: np.array([]),\n",
        "        soft_switches=np.array([]),\n",
        "        hard_switches=np.array([]),\n",
        "        teleport_switches=np.array([]),\n",
        "        render_mode=None,\n",
        "    ):\n",
        "        self._r_start = start_pos[0]\n",
        "        self._c_start = start_pos[1]\n",
        "\n",
        "        self._block = Block(self._r_start, self._c_start, self._r_start, self._c_start)\n",
        "\n",
        "        self._base_env = base_env\n",
        "\n",
        "        self._soft_switches = soft_switches\n",
        "        self._hard_switches = hard_switches\n",
        "        self._teleport_switches = teleport_switches\n",
        "\n",
        "        self._actions = {\n",
        "            0: self._block.move_right,\n",
        "            1: self._block.move_up,\n",
        "            2: self._block.move_left,\n",
        "            3: self._block.move_down,\n",
        "            4: self._block.toggle_focus,\n",
        "        }\n",
        "\n",
        "        self.observation_space = np.append(base_env.ravel(), 0)\n",
        "        self.action_space = gym.spaces.Discrete(5)\n",
        "\n",
        "    def step(self, action):\n",
        "        # if the block is split, check if single blocks are adjacent, and join together\n",
        "        self._block.join_single_blocks()\n",
        "\n",
        "        # update the agent's coords by passing it the action\n",
        "        self._perform_action(action)\n",
        "\n",
        "        # check if the agent is out of bounds -> reset to the start\n",
        "        r1, c1, r2, c2 = self._block.get_coords()\n",
        "\n",
        "        reward, done = self._is_done(r1, c1, r2, c2)\n",
        "\n",
        "        # only check for environment changes if the action is not \"Switch Focus\"\n",
        "        if action != 4:\n",
        "            self._move_to_start(r1, c1, r2, c2)\n",
        "            self._activate_teleport_switch(r1, c1, r2, c2)\n",
        "            self._toggle_soft_switches(r1, c1, r2, c2)\n",
        "            self._toggle_hard_switches(r1, c1, r2, c2)\n",
        "\n",
        "\n",
        "\n",
        "        state = self._format_environment()\n",
        "\n",
        "        return state, reward, done\n",
        "\n",
        "    def reset(self, seed):\n",
        "        # set both of the agent's coords to (self._r_start,self._c_start) and (self._r_start,self._c_start)\n",
        "        self._block.set_coords(\n",
        "            self._r_start, self._c_start, self._r_start, self._c_start\n",
        "        )\n",
        "        self._block.set_focus(0)\n",
        "\n",
        "        # reset the environment (important to undo any obstacle interactions)\n",
        "        self._current_env = np.copy(self._base_env)\n",
        "\n",
        "        # place the agent in the environment using its position\n",
        "        state = np.copy(self._current_env)\n",
        "        state[self._r_start, self._c_start] = 8\n",
        "        state = state.ravel()\n",
        "        state = np.append(state, self._block.get_focus())\n",
        "        # state = np.array2string(state, separator=\"\") + str(self._block.get_focus())\n",
        "\n",
        "        return state, False\n",
        "\n",
        "    def _move_to_start(self, r1, c1, r2, c2):\n",
        "        if self._current_env[r1, c1] == 9 or self._current_env[r2, c2] == 9:\n",
        "            self.reset(42)\n",
        "\n",
        "    def _is_done(self, r1, c1, r2, c2):\n",
        "        # check if the agent is on the goal -> set done to True and reward to 0\n",
        "\n",
        "        # reward is -1 and done is False unless the agent hit the goal\n",
        "        reward = -1\n",
        "        done = False\n",
        "\n",
        "        if self._current_env[r1, c1] == 4 and self._current_env[r2, c2] == 4:\n",
        "            reward = 0\n",
        "            done = True\n",
        "        # elif self._current_env[r1, c1] == 9 or self._current_env[r2, c2] == 9:\n",
        "        #   reward = -1000\n",
        "        #   done = True\n",
        "\n",
        "        return reward, done\n",
        "\n",
        "    def _format_environment(self):\n",
        "        # place the agent in the environment using its position\n",
        "        r1, c1, r2, c2 = self._block.get_coords()\n",
        "        state = np.copy(self._current_env)\n",
        "        state[r1, c1] = 8\n",
        "        state[r2, c2] = 8\n",
        "\n",
        "        state = state.ravel()\n",
        "        state = np.append(state, self._block.get_focus())\n",
        "        # state = np.array2string(state, separator=\"\") + str(self._block.get_focus())\n",
        "\n",
        "        return state\n",
        "\n",
        "    def _toggle_soft_switches(self, r1, c1, r2, c2):\n",
        "        # check if the agent is on a circle switch -> activate bridge\n",
        "        for c in self._soft_switches:\n",
        "            switch_location = c[\"switch_location\"]\n",
        "            toggle_tiles = c[\"toggle_tiles\"]\n",
        "            mode = c[\"mode\"]\n",
        "\n",
        "            if (r1 == switch_location[0] and c1 == switch_location[1]) or (\n",
        "                r2 == switch_location[0] and c2 == switch_location[1]\n",
        "            ):\n",
        "                if mode == \"toggle\":\n",
        "                    if self._current_env[toggle_tiles[0][0], toggle_tiles[0][1]] == 0:\n",
        "                        for t in toggle_tiles:\n",
        "                            self._current_env[t[0], t[1]] = 9\n",
        "                            self._current_env[t[0], t[1]] = 9\n",
        "\n",
        "                    else:\n",
        "                        for t in toggle_tiles:\n",
        "                            self._current_env[t[0], t[1]] = 0\n",
        "                            self._current_env[t[0], t[1]] = 0\n",
        "                elif mode == \"on\":\n",
        "                    for t in toggle_tiles:\n",
        "                        self._current_env[t[0], t[1]] = 0\n",
        "                        self._current_env[t[0], t[1]] = 0\n",
        "                elif mode == \"off\":\n",
        "                    for t in toggle_tiles:\n",
        "                        self._current_env[t[0], t[1]] = 9\n",
        "                        self._current_env[t[0], t[1]] = 9\n",
        "\n",
        "    def _toggle_hard_switches(self, r1, c1, r2, c2):\n",
        "        # check if the agent is on an x switch -> activate bridge\n",
        "        for c in self._hard_switches:\n",
        "            switch_location = c[\"switch_location\"]\n",
        "            toggle_tiles = c[\"toggle_tiles\"]\n",
        "\n",
        "            if (r1 == switch_location[0] and c1 == switch_location[1]) and (\n",
        "                r2 == switch_location[0] and c2 == switch_location[1]\n",
        "            ):\n",
        "                if self._current_env[toggle_tiles[0][0], toggle_tiles[0][1]] == 0:\n",
        "                    for t in toggle_tiles:\n",
        "                        self._current_env[t[0], t[1]] = 9\n",
        "                        self._current_env[t[0], t[1]] = 9\n",
        "\n",
        "                else:\n",
        "                    for t in toggle_tiles:\n",
        "                        self._current_env[t[0], t[1]] = 0\n",
        "                        self._current_env[t[0], t[1]] = 0\n",
        "\n",
        "    def _activate_teleport_switch(self, r1, c1, r2, c2):\n",
        "        # check if block is on teleport switch -> split block into two single blocks\n",
        "        for t in self._teleport_switches:\n",
        "            switch_location = t[\"switch_location\"]\n",
        "            split_positions = t[\"split_positions\"]\n",
        "\n",
        "\n",
        "            if (r1 == switch_location[0] and c1 == switch_location[1]) and (\n",
        "                r2 == switch_location[0] and c2 == switch_location[1]\n",
        "            ):\n",
        "\n",
        "                single_block_one = split_positions[0]\n",
        "                single_block_two = split_positions[1]\n",
        "\n",
        "                r1 = single_block_one[0]\n",
        "                c1 = single_block_one[1]\n",
        "\n",
        "                r2 = single_block_two[0]\n",
        "                c2 = single_block_two[1]\n",
        "\n",
        "                self._block.set_focus(1)\n",
        "                self._block.set_coords(r1, c1, r2, c2)\n",
        "\n",
        "    def _handle_orange_tile(self, r1, c1, r2, c2):\n",
        "        # check if block is vertical\n",
        "        if (r1, c1) == (r2, c2):\n",
        "            # check if tile is orange tile\n",
        "            if self._current_env[r1, c1] == 1:\n",
        "                # tile disappears/block falls through grid\n",
        "\n",
        "                self._block.set_coords(\n",
        "                    self._r_start, self._c_start, self._r_start, self._c_start\n",
        "                )\n",
        "\n",
        "        # nothing happens if block is not vertical on an orange tile\n",
        "\n",
        "    def _perform_action(self, action):\n",
        "        # Get the corresponding method from 'actions' and call it\n",
        "        action_method = self._actions.get(int(action))\n",
        "        if action_method:\n",
        "            action_method()\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid action\")\n",
        "\n",
        "    def get_state(self):\n",
        "        r1, c1, r2, c2 = self._block.get_coords()\n",
        "        print(r1, c1, r2, c2)\n",
        "        state = np.copy(self._current_env)\n",
        "        state[r1, c1] = 8\n",
        "        state[r2, c2] = 8\n",
        "\n",
        "        return state\n",
        "\n",
        "    def get_block(self):\n",
        "        return self._block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zmNA-cUHU8dC"
      },
      "outputs": [],
      "source": [
        "level = 1\n",
        "\n",
        "if level == 1:\n",
        "        env = Level(start_pos=(3, 6), base_env=level_one_env)\n",
        "\n",
        "elif level == 2:\n",
        "    env = Level(\n",
        "        start_pos=(6, 3),\n",
        "        base_env=level_two_env,\n",
        "        soft_switches=level_two_soft_switches,\n",
        "        hard_switches=level_two_hard_switches,\n",
        "    )\n",
        "\n",
        "elif level == 3:\n",
        "    env = Level(start_pos=(4, 3), base_env=level_three_env)\n",
        "\n",
        "elif level == 4:\n",
        "    env = Level(start_pos=(6, 4), base_env=level_four_env)\n",
        "\n",
        "elif level == 5:\n",
        "    env = Level(\n",
        "        start_pos=(2, 15),\n",
        "        base_env=level_five_env,\n",
        "        soft_switches=level_five_soft_switches,\n",
        "    )\n",
        "elif level == 6:\n",
        "    env = Level(\n",
        "        start_pos=(4, 3),\n",
        "        base_env=level_six_env,\n",
        "    )\n",
        "\n",
        "elif level == 7:\n",
        "    env = Level(\n",
        "        start_pos=(4, 4),\n",
        "        base_env=level_seven_env,\n",
        "        hard_switches=level_seven_hard_switches,\n",
        "    )\n",
        "\n",
        "elif level == 8:\n",
        "    env = Level(\n",
        "        start_pos=(6, 4),\n",
        "        base_env=level_eight_env,\n",
        "        teleport_switches=level_eight_teleport_switches,\n",
        "    )\n",
        "elif level == 9:\n",
        "    env = Level(\n",
        "        start_pos=(4, 4),\n",
        "        base_env=level_nine_env,\n",
        "        teleport_switches=level_nine_teleport_switches\n",
        "    )\n",
        "\n",
        "elif level == 10:\n",
        "    env = Level(\n",
        "        start_pos=(2, 12),\n",
        "        base_env=level_ten_env,\n",
        "        soft_switches=level_ten_soft_switches,\n",
        "        hard_switches=level_ten_hard_switches,\n",
        "        teleport_switches=level_ten_teleport_switches,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5hZj3FFUqcD"
      },
      "source": [
        "## Set random seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mFrsK0Y_UqcD"
      },
      "outputs": [],
      "source": [
        "seed = 777\n",
        "\n",
        "def seed_torch(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.backends.cudnn.enabled:\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "\n",
        "np.random.seed(seed)\n",
        "seed_torch(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxFb-S-OUqcE"
      },
      "source": [
        "## Initialize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0ITx-SkUqcE",
        "outputId": "7a91a385-f4d6-4bae-e809-97cf736fef0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# parameters\n",
        "num_frames = 500000\n",
        "memory_size = 1000\n",
        "batch_size = 128\n",
        "target_update = 100\n",
        "epsilon_decay = 1 / 100\n",
        "\n",
        "agent = DQNAgent(env, memory_size, batch_size, target_update, epsilon_decay, seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swjOlFMSUqcE"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "m7gffbUJUqcE",
        "outputId": "868b6b4d-e07f-487e-bbea-c3faa6facf8c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x500 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "agent.train(num_frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J863rxY0SsxL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
